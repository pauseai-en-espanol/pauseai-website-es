---
title: PauseAI in Australien
slug: australia
description: das australische Kapitel von PauseAI
---

**Eine Nachricht von PauseAI-Freiwilligen in Australien:**

Bis 2030 könnte künstliche Intelligenz (KI) vollständig automatisiert, selbstverbessernd und **in fast allen Bereichen intelligenter als Menschen sein**. Dies ist keine Science-Fiction – es ist die Einschätzung führender KI-Unternehmen und Forscher. Wenn dies passiert, wird sich jeder Aspekt des Lebens für immer ändern.

**[Treten Sie unserer Gemeinschaft bei](/join)** | [E-Mail an uns](mailto:australia@pauseai.info) | [Verbinden Sie sich auf Facebook](https://www.facebook.com/groups/571590459293618) | [YouTube-Kanal](https://www.youtube.com/channel/UCjjMieiOlSFf7jud0yhHQSg) | [LinkedIn](https://www.linkedin.com/company/pauseai-australia) | [Veranstaltungen](https://lu.ma/PauseAIAustralia)

### Welche Risiken stehen wir vor? {#what-risks-are-we-facing}

Künstliche Intelligenz entwickelt sich [mit atemberaubender Geschwindigkeit](/urgency). Einige Experten wie [Sam Altman](https://time.com/7205596/sam-altman-superintelligence-agi/), [Dario Amodei](https://arstechnica.com/ai/2025/01/anthropic-chief-says-ai-could-surpass-almost-all-humans-at-almost-everything-shortly-after-2027/) und [Geoffrey Hinton](https://en.wikipedia.org/wiki/Artificial_general_intelligence) warnen, dass **KI die menschliche Intelligenz innerhalb der nächsten fünf Jahre übertreffen könnte**. Ohne internationale Zusammenarbeit könnte dies zu wirtschaftlichem Chaos, Krieg und sogar [menschlichem Aussterben](/xrisk) führen.

> "Wenn allgemeine KI immer leistungsfähiger wird, treten allmählich weitere Risiken zutage. Dazu gehören Risiken wie groß angelegte Auswirkungen auf den Arbeitsmarkt, KI-gestützte Hackerangriffe oder biologische Angriffe und die Gesellschaft verliert die Kontrolle über allgemeine KI."
>
> – [Internationaler KI-Sicherheitsbericht (2025)](https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf), verfasst von 96 Experten aus 30 Ländern, darunter Australien.

### Wollen wir nicht die Vorteile von KI nutzen? {#dont-we-want-ais-benefits}

Natürlich. Künstliche Intelligenz hat bereits das Potenzial, ein leistungsfähiges Werkzeug zu sein. Wenn KI unter Kontrolle bleibt, könnte sie zur Heilung von Krankheiten, zum Vorantreiben wissenschaftlicher Durchbrüche und zur Verbreitung von Chancen und Wohlbefinden eingesetzt werden. Es wäre jedoch tragisch, diese Fortschritte zu erreichen, nur um dann [die Kontrolle zu verlieren](/ai-takeover) und katastrophale Verluste zu erleiden.

Neue Technologien haben immer Veränderungen gebracht, aber Menschen brauchen Zeit, um sich anzupassen, Sicherheitsmaßnahmen zu ergreifen und für die Zukunft zu planen. Bei jeder anderen Technologie – ob Flugzeuge, Wolkenkratzer oder neue Medikamente – bestehen wir darauf, dass Sicherheitsmaßnahmen von Experten entworfen werden, bevor die Öffentlichkeit Risiken ausgesetzt wird. Dies geschieht nicht bei KI.

KI-Unternehmen sind in einem Wettlauf, angetrieben von Milliarden von Dollar Investitionen, um als erste superintelligente KI zu entwickeln. Wenn ein Unternehmen Erfolg hat, wird Ihr Leben und das Ihrer Liebsten radikal anders werden, und Sie werden keine Kontrolle darüber haben, was diese Zukunft bringt. Dies ist nicht nur ein technisches Problem – es wird jeden betreffen.

### Was kann getan werden? {#what-can-be-done}

PauseAI [schlägt](/proposal) einen internationalen Vertrag vor, um die Entwicklung von intelligenteren als menschlichen allgemeinen KI zu pausieren, bis es einen glaubwürdigen Plan gibt, um sicherzustellen, dass sie sicher ist. Es liegt im Interesse Australiens, sich für diesen Vertrag einzusetzen.

> "Wer wird Führungsstärke bei der Verhandlung eines KI-Nichtverbreitungsvertrags zeigen? Es ist eine kollektive Verantwortung und sicherlich eine, zu der Australien beitragen kann."
>
> – Alan Finkel, Australiens Chef-Wissenschaftler (2016–2020)
>
> [Sydney Morning Herald](https://www.smh.com.au/technology/the-ai-horse-has-bolted-it-s-time-for-the-nuclear-option-20230807-p5duel.html)

Die Geschichte zeigt, dass kleinere Länder einen großen Unterschied bei der Lösung globaler Probleme machen können. Nehmen Sie das Verbot der Waljagd von 1982 und die Vereinbarung von 1987 zum Schutz der Ozonschicht. Australien, das selbst früher Wale jagte, wurde zu einem Vorreiter beim Schutz des Meereslebens, indem es das Verbot unterstützte und sogar Japan wegen seiner Walfangpraktiken vor Gericht brachte. Australien half auch, die Umwelt zu schützen, indem es dem Abkommen beitrat, um die Verwendung von Chemikalien zu stoppen, die die Ozonschicht schädigten. Diese Geschichten zeigen, dass Länder wie Australien durch ihr Handeln und ihre Zusammenarbeit mit anderen Nationen weltweit einen echten Wandel herbeiführen können.

### Gibt es nicht wichtigere Probleme? {#arent-there-more-important-issues}

Wir stimmen zu, dass es viele wichtige Probleme gibt, mit denen sich Australien konfrontiert sieht, aber wir werden sie in einer Welt mit unkontrollierter KI nicht lösen können. Australien sollte sich gleichzeitig für einen internationalen Vertrag einsetzen und an anderen Problemen arbeiten.

### Warum wird nichts unternommen? {#why-isnt-anything-being-done-already}

Australische Politiker haben sich mit einigen der kleineren Risiken von KI auseinandergesetzt, aber nicht mit den großen. Zum Zeitpunkt der letzten Wahl hatten [die großen Parteien keinen klaren Plan](https://www.australiansforaisafety.com.au/scorecard).

Wir erkennen an, dass nicht jeder über das Risiko einer KI-Katastrophe einverstanden ist. Wir gehen auf einige der häufigsten Einwände [hier](/faq) ein. Wir behaupten nicht, 100% sicher zu sein, aber wir denken, dass die Wahrscheinlichkeit sehr schlechter Ergebnisse hoch genug ist, um eine Pause zu rechtfertigen.

Es ist [psychologisch schwierig](/psychology-of-x-risk), über mögliche Katastrophen nachzudenken. Viele Menschen gehen davon aus, dass die Risiken außerhalb ihrer Kontrolle liegen und daher nicht wert sind, sich Sorgen zu machen. Doch jeder kann jetzt handeln, indem er sich äußert. Wir denken, dass es besser ist zu handeln, als sich einfach Sorgen zu machen.

### Wie kann ich in Australien helfen? {#how-can-i-help-in-australia}

Sie können einen Unterschied machen. Freiwillige in Australien machen auf die Risiken aufmerksam, protestieren, lobbyieren und unterstützen die globale PauseAI-Bewegung.

- [Treten Sie unserer Gemeinschaft bei](/join)
- [Besuchen Sie unsere nächste australische Online- oder Präsenzveranstaltung](https://lu.ma/PauseAIAustralia)
- Unterzeichnen Sie den offenen Brief von Australians for AI Safety [offener Brief](https://www.australiansforaisafety.com.au/letters)
- [Kontaktieren Sie Politiker](/writing-a-letter)
- Sprechen Sie mit Ihren Freunden und Ihrer Familie über das Risiko von KI

![Freiwilliger mit PauseAI-T-Shirt vor dem Flinders Street Station in Melbourne](/static/mark-melbourne.jpeg 'Mark (Freiwilliger aus Melbourne)')

![Freiwilliger vor dem Parlamentsgebäude in Canberra](/static/peter-canberra.png 'Peter (Freiwilliger in Canberra)')
