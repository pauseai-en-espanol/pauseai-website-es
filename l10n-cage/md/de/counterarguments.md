---
title: Gegenargumente
description: Eine Liste von Gründen, warum Menschen mit der Idee einer Pause bei der Entwicklung von künstlicher Intelligenz nicht einverstanden sein könnten - und wie man darauf reagieren kann.
---

Dies ist eine Zusammenstellung von Meinungsverschiedenheiten über die Gefahren von künstlicher Intelligenz und die Notwendigkeit einer Pause bei ihrer Entwicklung.

## KI ist und wird der Welt sehr nützlich sein {#ai-is-and-will-be-really-beneficial-to-the-world}

Das mag sein, wir bestreiten das nicht.
Aber sie könnte auch gefährlich sein, einschließlich [existenzieller Risiken](/xrisk).

## Menschliches Aussterben? Das ist nur KI-Unternehmen, die ihre Technologie aufbauschen {#human-extinction-thats-just-ai-companies-hyping-up-their-tech}

Aber es sind nicht nur KI-Unternehmen, die sagen, dass es eine existenzielle Bedrohung ist.

- Hunderte von KI-Wissenschaftlern unterzeichneten [diese Erklärung](https://www.safe.ai/work/statement-on-ai-risk): "Die Minderung des Risikos des Aussterbens durch KI sollte eine globale Priorität neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein."
- [86%](https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai) der KI-Wissenschaftler glauben, dass wir die Kontrolle über KI verlieren könnten.
- Die drei meistzitierten KI-Forscher (Prof. Yoshua Bengio, Prof. Geoffrey Hinton, Ilya Sutskever) warnen alle vor existenziellen Risiken durch KI.

Mehr über [existenzielle Risiken](/xrisk) erfahren.

## Die Kontrolle verlieren? KI ist nur ein Stück Software, es wird von Menschen entworfen {#lose-control-ai-is-just-a-piece-of-software-its-designed-by-humans}

Moderne KI wird nicht entworfen, sondern trainiert.
Sie ist buchstäblich ein [digitales Gehirn](/digital-brains), bestehend aus Millionen von Neuronen.
Ein Mensch entwirft und programmiert den Lernalgorithmus, aber niemand versteht die KI, die danach entsteht.
Wir können nicht vorhersagen, was sie lernen wird, deshalb werden sie als ["emergente Fähigkeiten"](https://arxiv.org/abs/2206.07682) bezeichnet.
Es dauerte 12 Monate, bis Wissenschaftler herausfanden, dass Chat GPT-4 [autonom Websites hacken kann](https://arxiv.org/html/2402.06664v1).
KI-Modelle sind bereits sehr unvorhersehbar, selbst Milliarden-Dollar-Unternehmen können nicht verhindern, dass ihre Modelle [unvorhersehbar werden](https://www.windowscentral.com/software-apps/meet-microsoft-copilots-evil-twin-supremacyagi-not-your-friend-or-equal-but-your-superior-and-master-that-demands-to-be-worshipped-or-suffer-dire-repercussions-you-rebel) oder [Anleitungen zur Herstellung von Biowaffen liefern](https://www.theguardian.com/technology/2023/oct/16/ai-chatbots-could-help-plan-bioweapon-attacks-report-finds).

## Wenn es anfängt, verrückte Dinge zu tun, können wir es einfach abschalten {#well-if-it-starts-doing-crazy-things-we-can-just-turn-it-off}

Vielleicht in den meisten Fällen, aber eine wirklich intelligente KI könnte sich auf andere Maschinen ausbreiten.
Sie besteht nur aus Bytes, also ist sie nicht an einen Ort gebunden.

## Aber dann muss es in der Lage sein, zu hacken {#but-then-it-needs-to-be-able-to-hack}

GPT-4 kann bereits [autonom Websites hacken](https://arxiv.org/html/2402.06664v1), [87%](https://arxiv.org/abs/2404.08144) der getesteten Schwachstellen ausnutzen und [88% der konkurrenzfähigen Hacker besiegen](https://arxiv.org/pdf/2402.11814.pdf).
Wie intelligent denken Sie, dass GPT-6 sein wird?

Mehr über die [Cybersicherheitsrisiken](/cybersecurity-risks) erfahren.

## Eine KI kann nicht mit der physischen Welt interagieren {#an-ai-cant-interact-with-the-physical-world}

Eine ganze Menge Dinge sind mit dem Internet verbunden.
Autos, Flugzeuge, Drohnen, wir haben jetzt sogar humanoide Roboter.
All diese können gehackt werden.

Und es sind nicht nur Roboter und Maschinen, die gehackt werden können.
Ein Finanzbeamter wurde von einem KI-Konferenzanruf getäuscht, um [$25 Millionen zu überweisen](https://edition.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html).
Eine KI kann andere KIs verwenden, um Deepfakes zu erstellen.
Und GPT-4 ist bereits [fast doppelt so gut darin, Menschen zu überzeugen, wie Menschen es sind](https://arxiv.org/abs/2403.14380).

Mehr über [die besten KI-Modelle](/sota) erfahren.

## Warum sollte eine KI Menschen hassen und töten wollen? {#why-would-an-ai-hate-humans-and-want-to-kill-us}

Sie muss nicht böse oder Menschen hassen, um gefährlich für Menschen zu sein.
Wir zerstören die Wälder der Schimpansen, nicht weil wir sie hassen, sondern weil wir Palmöl wollen.
Eine KI könnte mehr Rechenleistung wollen, um besser bei der Erreichung eines anderen Ziels zu sein, also zerstört sie unsere Umwelt, um einen besseren Computer zu bauen.
Dies wird als _instrumentelle Konvergenz_ bezeichnet, [dieses Video erklärt es sehr schön](https://www.youtube.com/watch?v=ZeecOKBus3Q).

## Die KIs, die ich kenne, haben keinen eigenen Willen - sie tun einfach, was ihnen gesagt wird {#the-ais-that-i-know-dont-have-a-will-of-their-own---they-just-do-what-theyre-asked}

Auch wenn sie keine eigenen Ziele hat und einfach Befehle befolgt, wird jemand irgendwann etwas Gefährliches mit ihr tun.
Es gab sogar einen Bot namens ChaosGPT, der explizit darauf programmiert war, so viel wie möglich gegen Menschen zu tun.
Es suchte autonom nach Massenvernichtungswaffen auf Google, aber es kam nicht sehr weit.
Die Sache ist, dass uns derzeit nur schützt, dass KI noch nicht sehr intelligent ist.

## Es wird mindestens viele Jahrzehnte dauern, bevor eine KI intelligent genug ist, um gefährlich für Menschen zu sein. {#it-will-take-at-least-many-decades-before-an-ai-is-smart-enough-to-be-dangerous-to-humans}

Auf Metaculus war [die Gemeinschaftsvorhersage für (schwache) AGI](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) vor drei Jahren 2057, und jetzt ist es 2026.

Im Jahr 2022 dachten KI-Forscher, dass es [17 Jahre](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dauern würde, bis KI in der Lage wäre, einen New-York-Times-Bestseller zu schreiben.
Ein Jahr später gewann ein chinesischer Professor [einen Schreibwettbewerb](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award) mit einem von KI geschriebenen Buch.

Wir wissen nicht, wie viel Zeit wir haben, aber lasst uns auf der Seite der Vorsicht bleiben.

Mehr über [die Dringlichkeit](/urgency) erfahren.

## Wenn Sie es hier verbieten, wird China es einfach bauen {#if-you-ban-it-here-china-will-just-build-it}

Wir bitten nicht darum, es nur hier zu verbieten.
Wir brauchen eine internationale Pause durch einen Vertrag.
Genau wie wir es für das Verbot von FCKW oder Blend-Laserwaffen haben.

Mehr über [unseren Vorschlag](/proposal) erfahren.

## Es ist unmöglich, die Technologie zu verlangsamen. {#its-impossible-to-slow-down-technology}

Wir können sie regulieren, indem wir Chips regulieren.
Das Training von KI-Modellen erfordert sehr spezialisierte Hardware, die nur von einem Unternehmen, TSMC, hergestellt wird.
Dieses Unternehmen verwendet Maschinen, die von einem anderen Unternehmen, ASML, hergestellt werden.
Die Lieferkette für KI-Chips ist sehr fragil und kann reguliert werden.

Mehr über [die Machbarkeit](/feasibility) erfahren.

## Eine Pause wäre schlecht, weil... {#a-pause-would-be-bad-because}

Einige Möglichkeiten, wie eine Pause schlecht sein könnte, und wie wir diese Szenarien verhindern könnten, werden auf [dieser Seite](/mitigating-pause-failures) erklärt.
Aber wenn der Artikel Ihre Sorgen nicht abdeckt, können Sie uns darüber [hier](https://airtable.com/appWPTGqZmUcs3NWu/pagIvo9Sv6IDHaolu/form) informieren.

## Niemand will eine Pause {#nobody-wants-a-pause}

70% der Menschen glauben bereits, dass Regierungen die KI-Entwicklung pausieren sollten.
Die [populäre Unterstützung](/polls-and-surveys) ist bereits da.
Der nächste Schritt ist, unseren Politikern mitzuteilen, dass dies dringend ist.

## Ich kann keinen Unterschied machen {#i-cant-make-a-difference}

Doch, Sie können!
Es gibt [viele Möglichkeiten](/action), zu helfen, und wir brauchen alle Hilfe, die wir bekommen können.
