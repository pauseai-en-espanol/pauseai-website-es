---
title: Kerzenlicht-Mahnwache von PauseAI vor dem UN-Hauptquartier in NYC, 3. Juni
---

- Kerzenlicht-Mahnwache, um auf die existenzielle Bedrohung durch künstliche Intelligenz aufmerksam zu machen.
- 3. Juni, 19:30 Uhr bis 21 Uhr. Sonnenuntergang ist hier um 20:15 Uhr.
- Vereinte Nationen, Hauptquartier in New York City.
- [Anmelden](https://forms.gle/hsVetUDx3R1w6yj59)

## Pressemitteilung {#press-release-2}

Am Samstag, dem 3. Juni, bei Sonnenuntergang, findet vor dem Hauptquartier der Vereinten Nationen eine Kerzenlicht-Mahnwache statt.
Die Mahnwache ist ein Zeichen der Hoffnung, damit Menschen zusammenkommen und gemeinsam gegen eine wachsende existenzielle Bedrohung handeln können.
Freiwillige der neuen Bewegung [PauseAI](http://pauseai.info) werden sich dort versammeln, um Regierungen aufzufordern, einen Gipfel zu organisieren, um die Entwicklung von künstlicher Intelligenz, die gefährlicher ist als GPT-4, zu stoppen.

Die Hälfte der KI-Forscher [glaubt](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/), dass es eine 10%ige oder höhere Wahrscheinlichkeit gibt, dass die Erfindung von übermenschlicher KI das Ende der Menschheit bedeutet. Würden Sie in ein Flugzeug steigen, wenn die Hälfte der Flugzeugingenieure dächte, dass es eine 10%ige Chance gibt, dass es abstürzt?

Bekannte Experten wie Prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) und Prof. [Yoshua Bengio](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/), beide Turing-Preisträger und Pioniere der erfolgreichsten KI-Methoden heute, warnen vor den Gefahren der KI. Auch Führungskräfte von KI-Unternehmen selbst äußern ihre Besorgnis:

- Sam Altman (CEO von OpenAI, dem Unternehmen hinter ChatGPT): ["Die Entwicklung von übermenschlicher Maschinenintelligenz ist wahrscheinlich die größte Bedrohung für die weitere Existenz der Menschheit."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (Mitgründer von OpenAI): ["KI hat das Potenzial, die Zivilisation zu zerstören."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (Mitgründer von Microsoft, Besitzer von 50% von OpenAI): ["KI könnte entscheiden, dass Menschen eine Bedrohung sind."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (Leadinvestor bei Anthropic, Entwickler von Claude): ["Ich habe niemanden in KI-Labors getroffen, der sagt, dass das Risiko [durch die Entwicklung eines nächsten Generation-Modells] weniger als 1% beträgt, die Welt zu zerstören. Es ist wichtig, dass die Menschen wissen, dass Leben riskiert werden."](https://twitter.com/liron/status/1656929936639430657)

Die Fortschritte im KI-Bereich haben die Erwartungen übertroffen. Im Jahr 2020 wurde geschätzt, dass ein KI-System erst 2050 Universitätsaufnahmeprüfungen bestehen würde. Dieses Ziel wurde im März 2023 von OpenAIs GPT-4 erreicht. Diese KI hat einen [verbaler IQ von 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), spricht 23 Sprachen, kann programmieren und [kann Menschen täuschen](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Glücklicherweise hat GPT-4 noch Einschränkungen. Zum Beispiel kann es nicht effektiv [hacken oder Computerviren schreiben](https://pauseai.info/cybersecurity-risks), aber es ist möglich, dass diese Fähigkeiten nur wenige Innovationen entfernt sind. Angesichts des aktuellen Tempos der KI-Investitionen nähert sich dieser Punkt [schnell](https://pauseai.info/urgency).

Diese massiven und unerwarteten Sprünge in den Fähigkeiten haben viele Experten dazu veranlasst, eine Pause in der Entwicklung von KI durch einen [offenen Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) an große KI-Unternehmen zu fordern. Der Brief wurde über 27.000 Mal unterzeichnet, hauptsächlich von KI-Forschern und Technologie-Experten. Eine Pause ist notwendig, um an KI-Gesetzen zu arbeiten, das KI-Alignment-Problem zu lösen und sich als Gesellschaft an diese neue Technologie anzupassen. Eine [aktuelle Umfrage](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) in den Vereinigten Staaten zeigt eine signifikante Unterstützung für eine Pause mit mehr als 60% der Öffentlichkeit. Leider scheint es, dass Unternehmen nicht bereit sind, ihre Wettbewerbspositionen freiwillig zu gefährden, indem sie stoppen. Diese KI-Unternehmen sind in einem Wettlauf nach unten gefangen, bei dem die Sicherheit zunehmend hinter die Verbesserung der Fähigkeiten zurücktritt. Daher muss die Pause von Regierungen auferlegt werden. Die Umsetzung einer nationalen Pause ist auch schwierig, da Länder Gründe haben, nicht die ersten zu sein, die pausieren. Daher ist eine internationale Lösung notwendig: ein Gipfel. PauseAI fordert unsere Regierungen auf, diesen Gipfel zu organisieren.

Für weitere Informationen besuchen Sie bitte [PauseAI.info](http://pauseai.info).
