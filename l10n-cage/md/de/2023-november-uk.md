---
title: PauseAI-Protest bei Bletchley Park - 1. November
description: Wir organisieren einen Protest bei Bletchley Park w√§hrend des AI Safety Summit
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- [Facebook-Event](https://www.facebook.com/events/347499967619516/347499967619516)
- [Anmelden](https://www.mixily.com/event/4419031774197158693)

![AI-Safety-Summit-Logo](https://github.com/joepio/pauseai/assets/47218308/4b8fe05f-3f8f-4f71-87a6-d273d67ae599)

Das Vereinigte K√∂nigreich ist auf dem richtigen Weg. Es anerkennt praktisch jedes Risiko, das von k√ºnstlicher Intelligenz ausgeht, investiert 100 Millionen Pfund in die Sicherheit von k√ºnstlicher Intelligenz, organisiert einen Gipfel und k√ºndigt ein Institut f√ºr KI-Sicherheit an.

Doch das ist noch nicht genug. Spitzenforscher auf dem Gebiet der k√ºnstlichen Intelligenz wie Geoffrey Hinton und Yoshua Bengio haben deutlich gemacht: Wir wissen nicht, wie man eine √ºbermenschliche KI kontrolliert. Wenn wir das falsch machen, ist das Aussterben der Menschheit eine sehr reale M√∂glichkeit. Deshalb fordern wir eine sofortige und unbefristete Pause bei der Forschung und Entwicklung von KI-Systemen an der Grenze des M√∂glichen.

Am 1. und 2. November findet im Vereinigten K√∂nigreich der erste AI Safety Summit statt.
Dies ist eine einmalige Gelegenheit, die ersten Schritte in Richtung einer vern√ºnftigen internationalen Regulierung der KI-Sicherheit zu unternehmen.

Es scheint jedoch, dass die Verantwortlichen nicht das Gef√ºhl haben, [wie wenig Zeit uns noch bleibt](/urgency).
Der Organisator und Vertreter des Premierministers f√ºr den AI Safety Summit, Matt Clifford, hat [erkl√§rt](https://twitter.com/PauseAI/status/1709845853668553065), dass "eine Pause bei der KI-Entwicklung jetzt verfr√ºht w√§re", und dass er [nicht damit rechnet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" bringt.
Das letzte Woche ver√∂ffentlichte KI-Sicherheitspapier [deutet darauf hin](https://twitter.com/PauseAI/status/1717474950557090151), dass das Vereinigte K√∂nigreich zuversichtlich ist, dass wir noch viele Jahre Zeit haben, uns auf die AGI vorzubereiten.
Aber das Vereinigte K√∂nigreich st√ºtzt sich auf Sch√§tzungen vom letzten Jahr, bevor ChatGPT ver√∂ffentlicht wurde.
Auf Metaculus ist die Vorhersage des Datums der ersten AGI [von 2047 auf 2026 gesunken](https://metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) in den letzten 18 Monaten!

**Wir brauchen unsere F√ºhrer, die auf der Seite der Vorsicht erraten und eine Pause einleiten.**

## Was wir fordern {#what-we-ask}

- **Politiker**: Erlauben Sie Unternehmen nicht, eine Superintelligenz zu entwickeln. Regulierungen und Hardware-Einschr√§nkungen sollten vor dem Training gelten, da es sehr schwierig ist, die Verbreitung zu kontrollieren, sobald eine neue F√§higkeit erreicht wurde. Wir k√∂nnen es nicht zulassen, dass Unternehmen potenziell weltweit gef√§hrliche KI-Modelle trainieren. Die Erstellung von Gesetzen ist schwierig und dauert lange, aber wir haben vielleicht nicht so viel Zeit, also arbeiten Sie, als ob Ihr Leben davon abh√§ngt. Denn das tut es.
- **Unternehmen**: Viele von Ihnen haben Angst vor dem, was KI tun kann, aber Sie sind in einem Wettlauf gefangen. Also seien Sie laut und unterst√ºtzen Sie eine Pause im Prinzip. Wenn Sie Erkl√§rungen unterzeichnen, dass diese Technologie uns alle t√∂ten k√∂nnte, zeigen Sie der Welt, dass Sie lieber nicht daran arbeiten w√ºrden, wenn es eine gangbare Option w√§re.
- **Gipfel-Teilnehmer**: Stellen Sie die Sicherheit √ºber das wirtschaftliche Wachstum. Wir wissen, dass KI unsere L√§nder reicher machen kann, aber das ist nicht der Grund, warum Sie hier sind. Seien Sie der Erwachsene im Raum.

F√ºr unseren gesamten Vorschlag siehe [hier](/proposal).

## Pressemitteilung {#press-release-4}

_ZUR VER√ñFFENTLICHUNG AM 1. NOVEMBER 2023_

### Protest w√§hrend des AI Safety Summit fordert ein Ende der gef√§hrlichen KI-Entwicklung {#protest-during-ai-safety-summit-calls-for-a-halt-to-dangerous-ai-development}

**1. November:** [**PauseAI**](https://pauseai.info/) **veranstaltet einen** [**Protest in Bletchley Park w√§hrend des AI Safety Summit**](https://pauseai.info/2023-oct) **und fordert Politiker und Teilnehmer des AI Safety Summit auf, die Schaffung einer superintelligenten KI sofort zu verbieten.**

Im M√§rz dieses Jahres unterzeichneten viele bekannte Pers√∂nlichkeiten [einen Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.), in dem sie eine sechsmonatige Pause bei der Entwicklung ihrer KI-Modelle an der Grenze des M√∂glichen forderten. Im Mai unterzeichneten Hunderte von KI-Wissenschaftlern [eine Erkl√§rung](https://www.safe.ai/statement-on-ai-risk), in der es hei√üt: "Die Milderung des Risikos des Aussterbens durch KI sollte eine globale Priorit√§t neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein."

Aktuelle Umfragen in [den USA](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) und [dem Vereinigten K√∂nigreich](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693) haben gezeigt, dass eine gro√üe Mehrheit der Menschen will, dass die Regierung eingreift und die Schaffung einer superintelligenten KI verhindert. Bisher werden [keine Gesetzesentw√ºrfe](https://twitter.com/PauseAI/status/1706605169608159458) vorgeschlagen, die dies tun w√ºrden.

Am 1. und 2. November findet in Bletchley Park, UK, der erste AI Safety Summit statt.
Der Gipfel wird von f√ºhrenden KI-Wissenschaftlern, Politikern und Industrie-Executives besucht.
Dies ist eine einmalige Gelegenheit, die ersten Schritte in Richtung einer internationalen Regulierung der KI-Sicherheit zu unternehmen.
Der Organisator und Vertreter des Premierministers f√ºr den AI Safety Summit, Matt Clifford, hat jedoch [erkl√§rt](https://twitter.com/PauseAI/status/1709845853668553065), dass "eine Pause bei der KI-Entwicklung jetzt verfr√ºht w√§re", und dass er [nicht damit rechnet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel "harte Kontrollen" bringt.

"Wir freuen uns, dass das Vereinigte K√∂nigreich die KI-Sicherheit vorantreibt und internationale F√ºhrung zeigt", sagt Joep Meindertsma, Direktor von PauseAI. "Aber wir sehen nicht das Ma√ü an Dringlichkeit, das es verdient. Im Jahr 2020 sagten Prognostiker [voraus](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/), dass die Ankunft von KI auf menschlichem Niveau im Jahr 2055 erfolgen w√ºrde. Heute ist die [durchschnittliche Prognose](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. Wir k√∂nnen es nicht riskieren, dass wir die Geschwindigkeit des Fortschritts untersch√§tzen. Wir brauchen unsere Politiker, die auf der Seite der Vorsicht erraten. Jedes einzelne Leben ist in Gefahr. Kein Unternehmen sollte in der Lage sein, eine Superintelligenz zu entwickeln."

### Medien {#media-1}

[Der Protest wurde in NewScientist besprochen.](https://www.newscientist.com/article/2400626-uk-ai-summit-is-a-photo-opportunity-not-an-open-debate-critics-say/)

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="de" dir="ltr">Wir haben w√§hrend des AI Safety Summit in Bletchley Park protestiert, um unsere F√ºhrer aufzufordern, die Entwicklung von superintelligenter KI zu stoppen. <br><br>üßµ <a href="https://t.co/WbH1GuKqAS">pic.twitter.com/WbH1GuKqAS</a></p>&mdash; PauseAI ‚è∏ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1719740149905400128?ref_src=twsrc%5Etfw">1. November 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>
