---
title: Die Machbarkeit einer Pause
description: Ist eine Pause bei der KI-Entwicklung möglich?
---

<!-- end of frontmatter metadata, dashes above need to stay -->
<!-- Ich habe fast keine Quellen verwendet, das sollte sich ändern -->

Eine Pause bei der KI-Entwicklung ist nicht unmöglich.
Die Festlegung einer roten Linie, die bestimmt, welche Art von Technologien und Aktionen entwickelt und durchgeführt werden dürfen, ist etwas, was wir ständig tun.

## Politische Machbarkeit einer Pause {#political-feasibility-of-a-pause}

Einige haben die Pause als "radikal" oder "extrem" bezeichnet, aber das ist nicht die Meinung der Öffentlichkeit.
Verschiedene [Umfragen und Studien](/polls-and-surveys) haben gezeigt, dass:

- Die Menschen sehr besorgt über KI sind (hauptsächlich wegen der Sicherheit)
- Die überwiegende Mehrheit (fast 70%) [eine Pause bei der KI-Entwicklung unterstützt](https://www.sentienceinstitute.org/aims-survey-supplement-2023)
- Die überwiegende Mehrheit (>60%) [einen internationalen Vertrag zum Verbot von AGI unterstützt](https://www.sentienceinstitute.org/aims-survey-supplement-2023)

## Technische Durchsetzbarkeit einer Pause {#technical-enforceability-of-a-pause}

Der einfachste Weg, um die Entwicklung von Spitzenmodellen zu regulieren, besteht darin, [die Rechenleistung zu steuern](https://www.governance.ai/post/computing-power-and-the-governance-of-ai).
Wir können [GPUs verfolgen](https://arxiv.org/abs/2303.11341), wie wir Elemente verfolgen, die bei der Entwicklung von Nuklearwaffen verwendet werden.
Glücklicherweise hat die Lieferkette für Rechenleistung verschiedene Engpässe.
Die Hardware, die für die Ausbildung der größten Modelle benötigt wird (spezialisierte GPUs), wird von [nur 1 oder 3 Unternehmen](https://assets-global.website-files.com/614b70a71b9f71c9c240c7a7/65cb86a0341180453f268f38_SpwF1cBT0AS-m_n20TBXzCF6YprIVM4YRb9PMYWURseU1KtVkSAZJ735esGxNenwVO4Q4wlSUP-_MV3E-SEKp4SIgo1-oNe14CeDHtrb3PLXpJMym5qpWEDbXcf3maEi4yQYfQ-3NP7XgUmkO_4Zekw.jpeg) produziert.

Es gibt mehrere Monopole in der Lieferkette für KI-Trainingshardware:

- ASML ist das einzige Unternehmen, das EUV-Lithographiemaschinen produziert
- TSMC ist das einzige Unternehmen, das die fortschrittlichsten Chips herstellen kann
- NVidia ist das einzige Unternehmen, das die fortschrittlichsten GPUs entwirft

## Macht über Unternehmen {#power-over-companies}

Wenn deine Hauptsorge Unternehmen oder Organisationen sind, können wir sie über 1) Gesetze, Vorschriften und Verträge oder 2) öffentliche Meinung, die sie dazu zwingt, sich selbst zu regulieren, kontrollieren.

Natürlich ist die erste Methode die bessere, aber der Ruf, der Kunden, Investoren, Mitarbeitermoral und Rekrutierung beeinflusst, ist ein Grund, warum wir Proteste vor einigen KI-Labors organisieren.
Außerdem ist es wichtig zu beachten, dass Vorschriften Unternehmen langfristig nützen können, da sie durch regulatorische Einnahmen, nicht durch den Verlust von Verbrauchern, wenn die Gefahren real werden, und durch die Benachteiligung von Konkurrenten profitieren können.
Wir müssen also vorsichtig sein, dass wir nicht nur eine Pause erreichen, sondern dass sie nicht aufgehoben wird, bis es tatsächlich sicher ist, die Entwicklung von Spitzen-KI fortzusetzen.

## Macht über Regierungen {#power-over-governments}

Wenn du befürchtest, dass Regierungen deine Sicherheit nicht ernst nehmen, ist das ein komplizierteres Problem.
Aber im Allgemeinen kümmern sich Politiker darum, nicht die politische Unterstützung zu verlieren.
Und wichtiger noch, sie können auch besorgt über die Risiken sein, ohne die enorme Voreingenommenheit und die rechtlichen Verpflichtungen, die einige Einzelpersonen aus Unternehmen haben, um Gewinne zu maximieren.

Wenn du denkst, dass wir die Regulierung einer einzelnen Regierung erreichen könnten, aber nicht einen multilateralen Vertrag, musst du erkennen, dass, wenn Regierungen erkennen, dass einige unkontrollierbare Technologien eine Gefahr für ihre Bevölkerung darstellen und aus anderen Nationen stammen können, die neuen Technologien zu einem nationalen Sicherheitsproblem werden und die Regierungen daran interessiert sind, andere Länder daran zu hindern, sie zu entwickeln.
Außerdem ist es wichtig zu erkennen, dass wir nicht wirklich viele Länder brauchen, um einer Pause zuzustimmen.
In Wirklichkeit kann man eine Pause in der Entwicklung von Spitzenmodellen erreichen, indem man sie nur in den USA (und sogar nur in Kalifornien) verbietet.
China und der Rest der Welt scheinen ziemlich weit zurückzuliegen, und wir sollten uns nicht zu sehr um ihre Zustimmung zu einem Vertrag kümmern, wenn sie etwas später erfolgt.

## Ähnliche historische Fälle {#similar-historical-cases}

Obwohl jeder Beweis für die Unfähigkeit oder Bosheit unserer Regierungen, Unternehmen und Systeme uns in eine defätistische Denkweise locken kann, in der Koordination zu schwierig ist, die Interessen der Menschen nicht gut vertreten sind und/oder vertreten werden, aber dumm sind, erkennen wir manchmal nicht die Siege, die wir als Zivilisation throughout Geschichte errungen haben.

Für empirische Beweise dafür, dass ein Vertrag wie dieser möglich ist, sollten wir uns historische globale Vereinbarungen ansehen.
Ob formell oder informell, sie waren ziemlich häufig throughout Geschichte, hauptsächlich um Streitigkeiten zu lösen und die Menschenrechte zu fördern.
Viele vergangene Siege, wie die Abschaffung der Sklaverei, hatten auch starke, kurzfristige wirtschaftliche Anreize gegen sie.
Aber das hat sie nicht aufgehalten.

Wenn wir nach ähnlichen modernen Beispielen für globale Vereinbarungen gegen neue Technologien suchen, können wir viele finden. Einige der wichtigsten waren:

- Das [Montreal-Protokoll](https://de.wikipedia.org/wiki/Montrealer_Protokoll), das die Produktion von FCKWs in allen 197 Ländern verbot und dazu führte, dass die globalen Emissionen von ozonschädigenden Substanzen seit 1986 um mehr als 99% zurückgegangen sind. Dank des Protokolls heilt das Ozonloch jetzt, und das ist der Grund, warum wir nicht mehr davon hören.
- Die [Biowaffenkonvention](https://de.wikipedia.org/wiki/Biowaffenkonvention), die biologische und Toxin-Waffen verbot und von 185 Staaten unterzeichnet wurde.
- Die [Chemiewaffenkonvention](https://de.wikipedia.org/wiki/Chemiewaffenkonvention), die chemische Waffen verbot und von 193 Staaten unterzeichnet wurde.
- Die [Umweltänderungskonvention](https://de.wikipedia.org/wiki/Umweltänderungskonvention), die Wetterkrieg verbot und von 78 Staaten unterzeichnet wurde.
- Der [Weltraumvertrag](https://de.wikipedia.org/wiki/Weltraumvertrag), der die Stationierung von Massenvernichtungswaffen im Weltraum verbot, militärische Aktivitäten auf Himmelskörpern verbot, die friedliche Erforschung und Nutzung des Weltraums rechtlich bindend machte und von 114 Ländern unterzeichnet wurde.
- Der [Nichtverbreitungsvertrag](https://de.wikipedia.org/wiki/Vertrag_über_die_Nichtverbreitung_von_Kernwaffen) und eine Reihe anderer internationaler Vereinbarungen, die entscheidend dazu beigetragen haben, die Verbreitung von Kernwaffen zu verhindern und das Ziel der nuklearen Abrüstung zu fördern. Dank ihnen haben wir viele Länder davon abgehalten, Kernwaffenprogramme zu verfolgen, die Menge an Kernwaffen seit den 90er Jahren reduziert und einen nuklearen Krieg über viele Jahrzehnte vermieden. Alle unglaublichen Errungenschaften.
- Die [Internationale Atomenergie-Organisation](https://de.wikipedia.org/wiki/Internationale_Atomenergie-Organisation), die eine zwischenstaatliche Organisation mit 178 Mitgliedstaaten ist, die sich für die friedliche Nutzung der Kernenergie einsetzt und ihre Nutzung für militärische Zwecke verhindern will. Unabhängig davon, ob du denkst, dass die Kernenergie überreguliert ist oder nicht, gilt die IAEO als gutes Beispiel für ein internationales Instrument, das wir haben könnten, um die Sicherheit der größten KI-Modelle zu bewerten.
- Und die [Erklärung der Vereinten Nationen über das Klonen von Menschen](https://de.wikipedia.org/wiki/Erklärung_der_Vereinten_Nationen_über_das_Klonen_von_Menschen), die die Mitgliedstaaten aufforderte, das Klonen von Menschen im Jahr 2005 zu verbieten und viele von ihnen dazu brachte, es zu tun. Es ist ein interessanter Fall, weil jetzt, fast 20 Jahre später und ohne eine formelle Vereinbarung, 60 Länder es entweder vollständig oder teilweise verboten haben und es keinen einzigen (verifizierten) Fall eines geklonten Menschen gegeben hat. Also suggeriert es die Möglichkeit, dass viele einseitige Regulierungen ausreichen könnten, um die Entwicklung anderer gefährlicher Technologien zu verhindern.

Wenn du denkst, dass KI tatsächlich ähnlich wie andere Fälle ist, in denen wir es nicht geschafft haben, gute Verträge international zu schließen: Alles, was jemals passiert ist, hatte ein erstes Mal.
Es gab Besonderheiten, die sie zum ersten Mal machten, und das ist ein Grund, die [Besonderheiten von KI](#ai-particular-case) anzusprechen.

### Auswirkungen von Protesten {#impact-of-protests}

Es ist ziemlich häufig, dass Menschen die Wirksamkeit von Protesten und sozialen Bewegungen im Allgemeinen in Frage stellen.
Natürlich gibt es viele Fälle, in denen Demonstrationen keine Ergebnisse liefern, aber es gibt auch Situationen, in denen die Forderungen der Demonstranten erfüllt werden und es wahrscheinlich ist, dass diese Ergebnisse [durch die Proteste verursacht wurden](https://www.socialchangelab.org/_files/ugd/503ba4_052959e2ee8d4924934b7efe3916981e.pdf).
Und [es gibt Gründe zu glauben, dass KI-Aktivismus ähnliche Ergebnisse erzielen könnte](https://forum.effectivealtruism.org/posts/WfodoyjePTTuaTjLe/efficacy-of-ai-activism-have-we-ever-said-no).

Wenn du die Idee von Protesten nicht magst, unternehmen wir auch [andere Aktionen](/action), wie zum Beispiel die direkte Kontaktaufnahme mit [Regierungen](/lobby-tips).

## Besonderheiten von KI {#ai-particular-case}

Wenn du denkst, dass KI unterschiedlich genug zu diesen Fällen ist (oder sogar wenn du es nicht denkst), ist es nützlich, ihre besondere Situation zu analysieren.
Die Dinge, die KI unterschiedlich machen, müssen nicht unbedingt dazu führen, dass sie weniger regulierbar ist.
Zum Beispiel [versuchen wir nicht, bestehende Produkte und Dienstleistungen zu regulieren, die Menschen bereits nutzen und regelmäßig verwenden](/proposal), und wir gehen nicht gegen viele Unternehmen vor, die lobbyieren oder Arbeiter, die ihre Jobs verlieren könnten, wenn wir erfolgreich sind. Ziemlich das Gegenteil.

Ein weiterer Punkt, der für uns spricht, ist, dass die Öffentlichkeit nicht parteiisch oder politisch gespalten ist, sondern [vereint in ihrer Unterstützung für Regulierungen](https://drive.google.com/file/d/1n0pXDBuIcb01tW4TQdP1Mb5aAiFDvWk0/view).
Dennoch müssen wir vorsichtig sein, sie nicht zu verprellen, ihre Perspektiven zu hören und zu sehen, auf welche Weise sie durch eine Pause unterstützt werden können, basierend auf dem, was ihnen wichtig ist. Da viele Menschen noch nicht entschieden haben, welche Art von Regulierung sie unterstützen.

Wenn es um KI-Risiken geht, scheinen die Öffentlichkeit und die Experten [besorgt über die Risiken und interessiert an Regulierungen](/polls-and-surveys) zu sein.
Die Politiker, basierend auf den [Politiken, die verabschiedet werden und in Arbeit sind](https://www.bloomberg.com/news/articles/2024-03-13/regulate-ai-how-us-eu-and-china-are-going-about-it), den [Gipfeln, die sie organisieren](/summit), und den [Erklärungen, die sie abgeben](/quotes), scheinen ziemlich besorgt zu sein.
Sogar ein aktueller [Bericht der US-Regierung](https://time.com/6898967/ai-extinction-national-security-risks-report/) empfiehlt unter mehreren Vorschlägen verschiedene Arten von Pausen in der KI-Entwicklung, um Risiken für die nationale Sicherheit und die Menschheit als Ganzes zu vermeiden.

All dies passiert, während PauseAI noch ziemlich jung ist und die meisten Menschen noch nicht von den meisten Risiken gehört haben.
Wenn wir das Bewusstsein und die Übereinstimmung über existenzielle Risiken erhöhen würden, hätten wir das Potenzial, mainstream zu werden, da praktisch niemand sterben oder die Welt untergehen sehen will.
Das ist nicht etwas, das im besten Interesse der egoistischsten Unternehmen, Regierungen und Menschen ist.

Auch wenn es Zeit braucht, werden die Manifestationen der Probleme, die KI in den nächsten Jahren bringen wird, das Bewusstsein für sie potenzieren und schließlich mehr und mehr Regulierungen auslösen.
Im Fall, dass wir keine Pause so schnell erreichen, wie wir es gerne hätten, könnten massive Arbeitslosigkeit und alle Arten von Zwischenfällen die meisten Menschen auf dieselbe Seite bringen, entweder schrittweise oder plötzlich, und die Menschen, die eine Pause nicht ernsthaft in Betracht gezogen hätten, dazu bringen, es tatsächlich zu tun.
Deswegen ist es wichtig, unser Potenzial zum Erfolg nicht auf kurzfristige Ergebnisse zu gründen, sondern immer auf neue Anhänger und Verbündete vorbereitet zu sein und bereit zu sein, Politiker zu führen, um unsere Vorschläge umzusetzen, falls ein Warnschuss passiert.

## Kollaterale Vorteile {#collateral-benefits}

Für eine Pause einzutreten hat andere positive Auswirkungen außerhalb ihrer Erreichung.
Die Information der Öffentlichkeit, der Techniker und der Politiker über die Risiken hilft anderen Interventionen, die darauf abzielen, sichere KI und KI-Sicherheit zu schaffen.
Sie veranlasst die Menschen, der technischen, politischen und kommunikativen Arbeit, die in KI-Sicherheit und KI-Ethik investiert wird, mehr Bedeutung beizumessen, was letztendlich bedeutet, dass mehr Mittel und Arbeitsplätze in sie investiert werden, mit dem Ziel, bessere Ergebnisse zu erzielen.

Sie würde nicht nur neue Menschen und Ressourcen für neue Interventionen bringen, sondern auch dazu beitragen, moderate technische und politische Initiativen als "vernünftiger" erscheinen zu lassen und ihre Chancen auf Unterstützung zu erhöhen.

Außerdem könnte sie die Menschen auf die Gefahren vorbereiten, ihnen beibringen, wie man KI ethischer verwendet, und sie sogar davon überzeugen, nicht in gefährliche und unsichere Projekte zu investieren oder daran zu arbeiten.

## Gib nicht dem Pessimismus nach {#dont-give-in-to-pessimism}

Wir verstehen, woher die pessimistischen Überzeugungen über starke Regulierungen kommen und dass es nicht einfach sein wird.
Aber es ist auch nicht einfach, die Zukunft vorherzusagen, und dieser Artikel versucht, gegen die Überzeugung unserer Machtlosigkeit zu argumentieren, da dies nur als eine sich selbst erfüllende Prophezeiung dienen kann.

Das einzige, was einfach ist, ist aufzugeben, [es ist der einfache Ausweg](/psychology-of-x-risk#difficult-to-act-on).
Denn wenn es nichts gibt, was wir tun können, gibt es nichts, was wir tun sollten.
Aber wir sollten nicht aufgeben, ohne es zu versuchen.
Dies ist tatsächlich unsere beste Chance, einen Einfluss auf die Welt und die Zukunft unserer Zivilisation zu haben.

## Die Entscheidungstheorie sagt: Versuche es trotzdem {#decision-theory-says-try-it-anyways}

Auch wenn du glaubst, dass eine Pause ziemlich unwahrscheinlich ist und du dich nicht um die anderen Vorteile kümmerst, empfehlen wir dir, [dich uns anzuschließen](/join). Vergrabe deinen Kopf nicht im Sand und warte darauf, zu sterben oder gerettet zu werden, du kannst uns helfen, dies zu erreichen!
