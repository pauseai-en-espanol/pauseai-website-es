---
title: PauseAI-Protest @ FCDO, London, 18. Juli
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We&#39;re not letting up in London! Today&#39;s protest took place during the first ever UN Security Council meeting on the threat from AI, chaired by UK Foreign Secretary <a href="https://twitter.com/JamesCleverly?ref_src=twsrc%5Etfw">@JamesCleverly</a>. A global pause is the only safe way forward.<br><br>More on UNSC meeting below: <a href="https://t.co/L9hONXogUl">https://t.co/L9hONXogUl</a> <a href="https://t.co/qp4A2fSSvb">pic.twitter.com/qp4A2fSSvb</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1681403296693534725?ref_src=twsrc%5Etfw">July 18, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI-Protest, um den Sicherheitsrat der Vereinten Nationen dazu aufzufordern, eine globale Pause bei den gr√∂√üten KI-Trainingsl√§ufen einzulegen.
- Ort: vor dem Foreign, Commonwealth and Development Office (FCDO), King Charles Street, Westminster, London, SW1A 2AH
- Zeit: 18. Juli, 16:30 - 17:30 Uhr
- [Anmelden](https://docs.google.com/forms/d/e/1FAIpQLSfLoAUfPEhp3bZyUbDnc8HigL_rYC7ykUmmPZvVWas-m2y5bQ/viewform?usp%253Dsf_link)
- [Facebook-Event](https://fb.me/e/1bawf1ZH1)

## Kontakt {#contact-2}

- Alistair Steward ([Twitter](https://twitter.com/alistair___s))

## Pressemitteilung: PauseAI protestiert vor dem Foreign Office vor dem UN-Sicherheitsratstreffen zu KI-Risiken {#press-release-pauseai-protests-foreign-office-ahead-of-un-security-council-meeting-on-ai-risk-1}

Am Dienstag, dem 18. Juli, werden Freiwillige der neuen Bewegung [PauseAI](http://pauseai.info/) vor dem Foreign Office in London zusammenkommen, um den UN-Sicherheitsrat dazu aufzufordern, eine Pause bei den Trainingsl√§ufen der leistungsf√§higsten KI-Systeme einzulegen. In einer [Pressekonferenz](https://youtu.be/USap-tFrTDc?t=3235) letzte Woche erkl√§rte die britische Botschafterin und Pr√§sidentin des Sicherheitsrates, Barbara Woodward: "K√ºnstliche Intelligenz ist kein eigenst√§ndiger Akteur", was einen Mangel an technischer Expertise zeigt, der typisch f√ºr Regierungsbeamte ist und dazu f√ºhrt, dass Risiken durch zuk√ºnftige KI-Systeme stark untersch√§tzt werden. Viele KI-Experten glauben, dass √ºbermenschliche KI der menschlichen Kontrolle entkommen k√∂nnte, mit katastrophalen Folgen, einschlie√ülich des Aussterbens der Menschheit. Der UN-Generalsekret√§r Ant√≥nio Guterres [hat diese Bedrohung k√ºrzlich anerkannt](https://press.un.org/en/2023/sgsm21832.doc.htm):

> "Die Alarmglocken √ºber die neueste Form der k√ºnstlichen Intelligenz - generative KI - sind ohrenbet√§ubend, und sie sind am lautesten von den Entwicklern, die sie entworfen haben. Diese Wissenschaftler und Experten haben die Welt aufgerufen, zu handeln, und erkl√§rt, dass KI eine existenzielle Bedrohung f√ºr die Menschheit darstellt, die mit dem Risiko eines Atomkriegs vergleichbar ist."

Der Sicherheitsrat der Vereinten Nationen wird am 18. Juli ein beispielloses Treffen abhalten, um √ºber diese KI-Risiken zu diskutieren. Unter dem Vorsitz des britischen Au√üenministers James Cleverly wird das Treffen des Sicherheitsrates eine Gelegenheit bieten, Expertenmeinungen zu KI zu h√∂ren und eine Diskussion unter den 15 Ratsmitgliedern √ºber ihre Auswirkungen zu beginnen. Ein [offener Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) (ver√∂ffentlicht im April), der KI-Unternehmen auffordert, ihre Trainingsl√§ufe zu pausieren, wurde von √ºber 33.000 Menschen unterzeichnet, darunter viele KI-Forscher und Tech-F√ºhrer. Bisher hat jedoch kein KI-Unternehmen nachgegeben.

> "Wir k√∂nnen nicht erwarten, dass KI-Unternehmen freiwillig aufh√∂ren, neue KI-Modelle zu trainieren - der Wettbewerbsdruck ist zu gro√ü. Nationale Regierungen haben ein √§hnliches Problem, da Nationen auch konkurrieren. Wir brauchen globale Ma√ünahmen. Der UN-Sicherheitsrat ist eines der wenigen Gremien, in denen ein solcher internationaler Vertrag gebildet werden k√∂nnte. Wir fordern unsere F√ºhrer auf, diese einzigartige Gelegenheit zu nutzen und die KI-Trainingsl√§ufe zu pausieren." - PauseAI-Mitglieder

Das Vereinigte K√∂nigreich √ºbernimmt derzeit die internationale F√ºhrung bei den KI-Sicherheitsvorschriften, da die Regierung [am 7. Juni bekannt gab](https://www.gov.uk/government/news/uk-to-host-first-global-summit-on-artificial-intelligence), dass sie den ersten KI-Sicherheitsgipfel in diesem Herbst ausrichten wird. Die Demonstranten bef√ºrchten jedoch, dass es zu wenig Aktionen geben wird, zu sp√§t:

> "Es ist extrem schwierig, vorherzusagen, wie schnell KI fortschreiten wird. Wir m√ºssen auf der Seite der Vorsicht erraten und uns auf ein Szenario vorbereiten, in dem wir gef√§hrliche Intelligenzniveaus in Monaten - nicht Jahren - erreichen. Das Treffen des UN-Sicherheitsrates ist der erste Moment, in dem eine globale Pause beschlossen werden k√∂nnte." - PauseAI-Mitglieder
