---
title: Warum wir KI-Sicherheitsgipfel benötigen
description: Warum wir den KI-Sicherheitsgipfel benötigen und was er erreichen sollte.
---

Künstliche Intelligenz (KI) birgt zahlreiche [Risiken](/risks) für die Menschheit, einschließlich des [Risikos des Aussterbens](/xrisk).
Die Entwicklung von KI beschleunigt sich in einem [atemberaubenden Tempo](/urgency), und wir sind nicht auf die Konsequenzen vorbereitet.
KI-Unternehmen sind in einem Wettlauf um die Vorherrschaft gefangen, bei dem Sicherheit nicht die höchste Priorität hat.
Wir benötigen Regierungen, die eingreifen und verhindern, dass KI ein superhumanes Level erreicht, bevor wir wissen, wie wir sie sicher machen können.
Diese [Pause](/proposal) muss auf internationaler Ebene stattfinden, da Länder in einem ähnlichen Wettlauf wie die Unternehmen gefangen sind.
Internationale Abkommen bedeuten _Verträge_, und das erfordert, dass Länder persönlich zusammenkommen und verhandeln.
**Der einzige Weg, eine wahre Pause zu erreichen, ist durch einen Gipfel.**

Es gab einige Beispiele für internationale Gipfel und daraus resultierende Verträge, die erfolgreich waren, um Risiken zu reduzieren:

- **Montreal-Protokoll** (1987): Das Montreal-Protokoll ist ein internationales Umweltabkommen, das darauf abzielt, die Ozonschicht durch die schrittweise Abschaffung der Produktion und des Verbrauchs von ozonabbauenden Substanzen zu schützen. Es war sehr erfolgreich bei der Reduzierung des Einsatzes von Substanzen wie Fluorchlorkohlenwasserstoffen (FCKW) und hat zum allmählichen Wiederherstellen der Ozonschicht beigetragen.
- **Stockholmer Übereinkommen über persistente organische Schadstoffe** (2001): Das Stockholmer Übereinkommen ist ein internationales Abkommen, das darauf abzielt, die menschliche Gesundheit und die Umwelt vor persistenten organischen Schadstoffen (POP) zu schützen. Diese sind giftige Chemikalien, die in der Umwelt persistieren, in lebenden Organismen bioakkumulieren und schwerwiegende negative Auswirkungen auf die menschliche Gesundheit und Ökosysteme haben können. Wissenschaftler haben Bedenken hinsichtlich der schädlichen Auswirkungen von POP geäußert, einschließlich ihrer Fähigkeit, über lange Strecken durch Luft- und Wasserströmungen zu reisen. Das Übereinkommen führte zu einem Verbot oder strengen Beschränkungen der Produktion und des Einsatzes mehrerer POP, einschließlich polychlorierter Biphenyle (PCB), Dichlordiphenyltrichlorethan (DDT) und Dioxine.

## Vergangene Gipfel {#past-summits}

### 2023 UK KI-Sicherheitsgipfel {#2023-uk-ai-safety-summit}

Das Hauptziel von PauseAI war es, eine Regierung davon zu überzeugen, einen solchen Gipfel zu organisieren.
Nur 5 Wochen nach dem ersten PauseAI-Protest kündigte die britische Regierung an, dass sie einen KI-Sicherheitsgipfel ausrichten würde, der am 1. und 2. November 2023 stattfand.
Der Gipfel war relativ klein (nur 100 Personen waren eingeladen) und fand in Bletchley Park statt.
Obwohl er nicht zu einem bindenden Vertrag führte, führte er zu der ["Bletchley-Erklärung"](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023), die von allen 28 teilnehmenden Ländern unterzeichnet wurde.
In dieser Erklärung anerkannten die Länder die KI-Risiken (einschließlich "Probleme der Kontrolle im Zusammenhang mit der Ausrichtung auf menschliche Absichten").
Dieser Gipfel führte auch zu zwei Folgegipfeln, die für 2024 in Seoul und Paris angekündigt wurden.

### 2024 Südkorea KI-Sicherheitsgipfel (21. und 22. Mai) {#2024-south-korea-ai-safety-summit-may-21st-22nd}

Monatelang war unklar, was der Umfang dieses Gipfels in Seoul sein würde.
Alles, was wir wussten, war, dass es ein ["virtuelles Minigipfeltreffen"](https://www.bracknellnews.co.uk/news/national/23898764.ai-safety-institute-will-make-uk-global-hub-rishi-sunak-says/) sein würde.
Eine eher unambitionierte Art, mit den hoch alarmierenden Aufrufen zur Regulierung umzugehen.
Im April 2024 wurde der zweite KI-Sicherheitsgipfel von der britischen Regierung [offiziell angekündigt](https://www.gov.uk/government/news/uk-and-republic-of-korea-to-build-on-legacy-of-bletchley-park).
Wir [organisierten einen Protest am 13. Mai](/2024-mai), um unsere Minister davon zu überzeugen, am Gipfel teilzunehmen (einige hatten [nicht einmal vor, teilzunehmen](https://www.reuters.com/technology/second-global-ai-safety-summit-faces-tough-questions-lower-turnout-2024-04-29/)) und Verhandlungen über einen Vertrag zur Pause aufzunehmen.

Der Gipfel führte zu folgenden Ergebnissen:

1. 16 Unternehmen (die meisten prominenten KI-Unternehmen) unterzeichneten die ["Frontier AI Safety Commitments"](https://www.gov.uk/government/news/historic-first-as-companies-spanning-north-america-asia-europe-and-middle-east-agree-safety-commitments-on-development-of-ai?utm_source=substack&utm_medium=email), was bedeutet, dass diese Unternehmen RSPs veröffentlichen werden. Frühere freiwillige Verpflichtungen [wurden ignoriert](https://www.politico.eu/article/rishi-sunak-ai-testing-tech-ai-safety-institute/).
2. Eine [neue Erklärung](https://www.gov.uk/government/publications/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024) wurde von 27 Ländern unterzeichnet.

### November 2024 San Francisco KI-Sicherheitskonferenz {#november-2024-san-francisco-ai-safety-conference}

Im September überraschten uns das AISI und die US-Regierung mit der Ankündigung eines neuen Gipfels.
Oder, genauer gesagt, zwei neue Zusammenkünfte in San Francisco.

Am **20. und 21. November** fand das erste internationale Treffen von [KI-Sicherheitsinstituten](https://www.commerce.gov/news/press-releases/2024/09/us-secretary-commerce-raimondo-and-us-secretary-state-blinken-announce) statt, das von der US-Regierung organisiert wurde und darauf abzielte, "die globale Zusammenarbeit und den Wissensaustausch über KI-Sicherheit voranzutreiben".
Die ursprünglichen Mitglieder des Internationalen Netzwerks von KI-Sicherheitsinstituten sind Australien, Kanada, die Europäische Union, Frankreich, Japan, Kenia, die Republik Korea, Singapur, das Vereinigte Königreich und die Vereinigten Staaten.
China ist auffällig in dieser Liste abwesend - obwohl [Chinas neues KI-Sicherheitsinstitut](https://x.com/yi_zeng/status/1831133250946838740) angekündigt wurde.

Am **21. und 22. November** veranstaltete das britische AISI eine [Konferenz in San Francisco](https://www.aisi.gov.uk/work/conference-on-frontier-ai-safety-frameworks).
Das Hauptziel war hier, "Experten von Unterzeichnerunternehmen und Forschungsorganisationen zusammenzubringen, um die dringendsten Herausforderungen bei der Gestaltung und Umsetzung von Frontier-KI-Sicherheitsrahmen zu diskutieren".

### ~~2024~~ 2025 Frankreich KI-~~Sicherheits~~Aktionsgipfel {#2024-2025-france-ai-safety-action-summit}

Während des Gipfels in Bletchley 2023 erklärte sich Frankreich bereit, den nächsten großen Gipfel im November 2024 auszurichten.
Frankreich verschob ihn auf Februar 2025.
Er wurde auch in "KI-\_Aktionsgipfel" umbenannt und der wichtige Fokus auf "Sicherheit" wurde fallen gelassen.
Er wurde von der KI-Skeptikerin Anne Bouverot geleitet, die [abweisend](https://legrandcontinent-eu.translate.goog/es/2023/12/08/la-ia-no-nos-sustituira-una-conversacion-con-anne-bouverot-yann-le-cun-y-alexandre-viros/?_x_tr_sl=es&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=sc) gegenüber "Alarmdiskursen" ist und KI mit Taschenrechnern vergleicht und KI-Sicherheitsbedenken mit Y2K-Bedenken vergleicht und sicher ist, dass "KI uns nicht ersetzen wird, sondern uns helfen wird".
Wir [protestierten](/2025-februar) gegen den fehlenden Sicherheitsfokus des Gipfels.

Der Gipfel wurde von der KI-Sicherheitsgemeinschaft weitgehend kritisiert.
Wir empfehlen, [den Artikel von Zvi](https://thezvi.substack.com/p/the-paris-ai-anti-safety-summit) über den ["Anti-KI-Sicherheitsgipfel"](https://thezvi.substack.com/p/the-paris-ai-anti-safety-summit) zu lesen.

## Kommende Gipfel {#coming-summits}

- Indien war Co-Gastgeber des Pariser Gipfels und wird den nächsten ausrichten. Leider erwarten wir, dass er keine sinnvollen Sicherheits- oder Regulierungsdiskussionen beinhalten wird.
- Die UNO organisiert den [KI für das Gute-Gipfel](https://aiforgood.itu.int/) in der Schweiz im Juli 2025.

## Was uns fehlt {#what-were-missing}

Keiner der geplanten Gipfel konzentriert sich auf Sicherheit oder internationale Regulierungen.
Wir benötigen ein Land, das einen Gipfel organisiert, der sich auf Sicherheit und internationale Regulierungen konzentriert.
Es ist unsere Aufgabe, einen Politiker zu finden, der dies tun wird.
