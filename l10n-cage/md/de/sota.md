---
title: Fähigkeiten moderner KI-Systeme im Vergleich zum Menschen
description: Wie intelligent sind die neuesten KI-Modelle im Vergleich zum Menschen?
---

Wie intelligent sind die neuesten KI-Modelle im Vergleich zum Menschen?
Lassen Sie uns einen Blick darauf werfen, wie die kompetentesten KI-Systeme im Vergleich zum Menschen in verschiedenen Bereichen abschneiden.
Die Liste unten wird regelmäßig aktualisiert, um die neuesten Entwicklungen widerzuspiegeln.

_Letzte Aktualisierung: 2024-09-16_

## Übermenschlich (Besser als alle Menschen) {#superhuman-better-than-all-humans}

- **Spiele**: Bei vielen Spielen (Schach, Go, Starcraft, Dota, Gran Turismo usw.) ist die beste KI besser als der beste Mensch.
- **Arbeitsgedächtnis**: Ein durchschnittlicher Mensch kann etwa 7 Elemente (wie Zahlen) gleichzeitig merken. Gemini 1.5 Pro kann 99% von 7 Millionen Wörtern lesen und merken.
- **Lesegeschwindigkeit**: Ein Modell wie Gemini 1.5 Pro kann ein ganzes Buch in 30 Sekunden lesen. Es kann eine völlig neue Sprache lernen und Texte in einer halben Minute übersetzen.
- **Schreibgeschwindigkeit**: KI-Modelle können mit Geschwindigkeiten schreiben, die weit über denen eines Menschen liegen, und ganze Computerprogramme in Sekunden schreiben.
- **Wissensumfang**: Moderne LLMs wissen weit mehr als jeder Mensch, ihr Wissen umfasst praktisch jeden Bereich. Es gibt keinen Menschen, dessen Wissensbreite auch nur annähernd kommt.

## Besser als die meisten Menschen {#better-than-most-humans}

- **Programmierung**: o3 schlägt 99,9% der menschlichen Programmierer im sehr anspruchsvollen Codeforces-Wettbewerb. Es schafft es, 71,7% der Programmierprobleme im SWE-Benchmark zu lösen, was zeigt, dass es auch reale Software-Engineering-Probleme sehr effektiv lösen kann.
- **Schreiben**: Im Dezember 2023 gewann ein von einer KI geschriebener Roman einen Preis bei einem nationalen Science-Fiction-Wettbewerb. Der Professor, der die KI verwendete, erstellte die Erzählung aus einem Entwurf von 43.000 Zeichen, der in nur drei Stunden mit 66 Eingaben generiert wurde. Die besten Sprachmodelle haben ein übermenschliches Vokabular und können in vielen verschiedenen Stilen schreiben.
- **Übersetzen**: Und sie können auf alle wichtigen Sprachen fließend antworten und übersetzen.
- **Kreativität**: Besser als 99% der Menschen bei den Torrance-Tests für kreatives Denken, bei denen relevante und nützliche Ideen generiert werden müssen. Allerdings waren die Tests relativ klein und für größere Projekte (z.B. die Gründung eines neuen Unternehmens) ist die KI noch nicht autonom genug.
- **Fachwissen**: o3 beantwortet 87,7% der GPQA-Diamantenfragen richtig, was besser ist als menschliche Fachexperten (PhDs), die nur 69,7% erreichen.
- **Visuelle Argumentation**: o3 erreichte eine Punktzahl von 87,5% im ARC-AGI-Benchmark (menschlicher Durchschnitt ist 60%), der speziell dafür entwickelt wurde, um für große Sprachmodelle schwierig zu sein.
- **Mathematik**: o3 gehört zu den besten 500 Schülern in den USA in einem Qualifikationstest für die USA-Mathematik-Olympiade (AIME).
- **Überzeugungskraft**: GPT-4 konnte mit Zugang zu persönlichen Informationen die Zustimmung der Teilnehmer zu den Argumenten ihrer Gegner um 81,7% erhöhen, verglichen mit Debatten zwischen Menschen - fast doppelt so überzeugend wie die menschlichen Debattierer.
- **IQ-Tests**: Bei verbalen IQ-Tests haben LLMs seit einiger Zeit 95 bis 99% der Menschen übertroffen (Punktzahl zwischen 125 und 155). Bei nonverbalen (Mustererkennungs-) IQ-Tests erreichte das 2024 o1-Preview-Modell 120 Punkte im Mensa-Test, womit es 91% der Menschen übertraf.
- **Spezialwissen**: GPT-4 erreicht 75% im Medical Knowledge Self-Assessment Program, Menschen im Durchschnitt zwischen 65 und 75%. Es schneidet besser ab als 68 bis 90% der Jurastudenten bei der Anwaltsprüfung.
- **Kunst**: Bildgenerierungsmodelle haben Kunst- und sogar Fotowettbewerbe gewonnen.
- **Forschung**: GPT-4 kann autonome chemische Forschung betreiben und DeepMind hat eine KI entwickelt, die eine Lösung für ein offenes mathematisches Problem gefunden hat. Allerdings erfordern diese Architekturen viel menschliches Engineering und sind nicht allgemein einsetzbar.
- **Hacking**: GPT-4 kann autonom Websites hacken und schlägt 89% der Hacker in einem Capture-the-Flag-Wettbewerb.

## Schlechter als die meisten Menschen {#worse-than-most-humans}

- **"Ich weiß nicht" sagen**. Praktisch alle großen Sprachmodelle haben dieses Problem der "Halluzination", also das Erfinden von Informationen, anstatt zu sagen, dass sie es nicht wissen. Dies mag wie ein relativ kleiner Mangel erscheinen, aber es ist ein sehr wichtiger. Es macht LLMs unzuverlässig und limitiert ihre Anwendbarkeit stark. Allerdings zeigen Studien, dass größere Modelle weit weniger halluzinieren als kleinere.
- **Ein überzeugender Mensch sein**. GPT-4 kann 54% der Menschen davon überzeugen, dass es ein Mensch ist, aber Menschen können dies 67% der Zeit schaffen. Mit anderen Worten, GPT-4 besteht den Turing-Test noch nicht konsequent.
- **Geschickte Bewegung**. Kein Roboter kann sich wie ein Mensch bewegen, aber wir kommen näher. Der Atlas-Roboter kann gehen, Objekte werfen und Saltos schlagen. Googles RT-2 kann Ziele in die Tat umsetzen, wie "den Becher zum Weinflasche bewegen". Teslas Optimus-Roboter kann Kleidung falten und Figures Biped kann Kaffee kochen.
- **Selbstreplikation**. Alle Lebewesen auf der Erde können sich selbst replizieren. KI-Modelle könnten sich von Computer zu Computer durch das Internet verbreiten, aber dies erfordert eine Reihe von Fähigkeiten, die KI-Modelle noch nicht besitzen. Eine Studie aus dem Jahr 2023 listet eine Reihe von 12 Aufgaben für die Selbstreplikation auf, von denen getestete Modelle 4 erfüllten. Im Dezember 2024 zeigte eine Studie, dass verschiedene Open-Source-Modelle sich auf einem Computer selbst replizieren können, wenn sie entsprechendes Werkzeug erhalten. Eine KI, die erfolgreich selbst repliziert, könnte zu einem KI-Übernahme führen.
- **Kontinuierliches Lernen**. Aktuelle SOTA-LLMs trennen Lernen ("Training") von Tun ("Inferenz"). Obwohl LLMs mit ihrem Kontext lernen können, können sie ihre Gewichte nicht aktualisieren, während sie verwendet werden. Menschen lernen und tun gleichzeitig. Allerdings gibt es mehrere potenzielle Ansätze für kontinuierliches Lernen in LLMs.
- **Ziele erreichen**, für die sie nicht trainiert wurden und die nicht darin bestehen, Text, Bilder oder Audio auszugeben. Wenn Sie ein LLM mit Kontrolle über einen Computer oder einen Roboter bitten, nicht-super-einfache Aktionen auszuführen oder Ziele in virtuellen oder realen Umgebungen zu erreichen, die weit von seiner Trainingsverteilung entfernt sind, wird es wahrscheinlich scheitern.
- **Planung**. LLMs sind noch nicht sehr gut bei der Planung (z.B. beim Nachdenken darüber, wie man Blöcke auf einem Tisch stapelt). Allerdings performen größere Modelle wesentlich besser als kleinere.

## Der Endpunkt {#the-endpoint}

Mit fortschreitender Zeit und verbesserten Fähigkeiten verschieben wir Elemente von den unteren Abschnitten in den oberen Abschnitt.
Wenn bestimmte gefährliche Fähigkeiten erreicht werden, wird die KI neue Risiken darstellen.
Irgendwann wird die KI jeden Menschen in jeder vorstellbaren Metrik überbieten.
Wenn wir diese Superintelligenz gebaut haben, werden wir wahrscheinlich bald tot sein.
Lasst uns eine Pause einlegen, um sicherzustellen, dass wir nicht dorthin kommen.
