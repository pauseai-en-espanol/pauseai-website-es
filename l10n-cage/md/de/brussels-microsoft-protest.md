---
title: PauseAI-Protest bei Microsoft in Brüssel - 23. Mai 2023
description: Wir organisieren einen Protest bei Microsoft, um eine Gipfelkonferenz zur Pause der KI-Entwicklung zu fordern.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- 23. Mai 2023, 11:45 - 13:00
- [Microsoft Innovation Center, Rue Montoyer 51, Brüssel, Belgien](https://goo.gl/maps/bvLbHDt61eSfpZV28?coh=178571&entry=tt)
- [Anmeldung auf Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592)

## Mitmachen {#join}

- Komm zu uns auf [Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592), um dich anzumelden und den Protest zu diskutieren.
- Lies den [Verhaltenskodex für Demonstranten](/protesters-code-of-conduct).

## Was wollen wir? {#what-do-we-want-2}

Wir fordern unsere Regierungen (und die EU insbesondere) auf, einen [Gipfel](/summit) über die [Risiken](/risks) von KI zu organisieren.
Wir fordern sie auf, die [KI-Entwicklung zu pausieren](/proposal), bis wir ausreichend vorbereitet sind.

## Warum bei Microsoft? {#why-at-microsoft}

Microsoft hat 13 Milliarden Dollar in OpenAI investiert, das derzeit die leistungsfähigsten KI-Modelle entwickelt.
Microsoft ist in einem Wettlauf mit anderen KI-Unternehmen (wie Google und Anthropic) um die Entwicklung der leistungsfähigsten KI-Systeme so schnell wie möglich.
Diese Marktdynamik ist gefährlich, da sie Unternehmen dazu anregt, sich auf Fähigkeiten zu konzentrieren und Sicherheitsbemühungen zu minimieren.
Diese Dynamik birgt [verschiedene Risiken](/risks), einschließlich [existenzieller Risiken](/xrisk).

Wir glauben, dass Microsoft in einer guten Position ist, Verantwortung zu übernehmen und eine Pause bei den gigantischen KI-Experimenten zu unterstützen.

## Pressemitteilung (Englisch) {#press-release-nederlands}

Am Dienstag, dem 23. Mai, um 12 Uhr, findet ein Protest vor dem Microsoft Innovation Center in Brüssel statt. Freiwillige der neuen [PauseAI](http://pauseai.info)-Bewegung werden sich dort versammeln, um die Regierungen aufzufordern, die Gefahren von KI auf einem Gipfeltreffen zu diskutieren.

Die Hälfte der KI-Forscher [glaubt](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/), dass es eine 10%ige oder höhere Chance gibt, dass die Erfindung von superintelligenter KI das Ende der Menschheit bedeutet. Würden Sie in ein Flugzeug steigen, wenn die Hälfte der Flugzeugingenieure dächte, dass die Chance eines Absturzes 10% beträgt?

Bekannte Beispiele von Menschen, die vor den Gefahren von KI warnen, sind Prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) und Prof. Yoshua Bengio, beide Turing-Preisträger und Pioniere der erfolgreichsten KI-Methoden heute. Nicht nur Wissenschaftler, sondern auch die Führungskräfte von KI-Unternehmen selbst sind besorgt über diese Gefahr:

- Sam Altman (CEO von OpenAI, dem Unternehmen hinter ChatGPT): ["Die Entwicklung von superintelligenter Maschinenintelligenz ist wahrscheinlich die größte Bedrohung für die weitere Existenz der Menschheit."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (Mitgründer von OpenAI): ["KI hat das Potenzial, die Zivilisation zu zerstören."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (Mitgründer von Microsoft, das 50% von OpenAI besitzt): ["KI könnte entscheiden, dass Menschen eine Bedrohung sind."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (Hauptinvestor bei Anthropic, Entwickler von Claude): ["Ich habe niemanden in KI-Labors getroffen, der sagt, dass das Risiko [durch die Schulung eines nächsten Generationen-Modells] weniger als 1% beträgt, die Welt zu zerstören. Es ist wichtig, dass die Menschen wissen, dass Leben riskiert werden."](https://twitter.com/liron/status/1656929936639430657)

Die Fortschritte im KI-Bereich haben die Erwartungen übertroffen. Im Jahr 2020 wurde geschätzt, dass ein KI-System die universitären Aufnahmeprüfungen bis 2050 bestehen würde. Dieses Ziel wurde im März 2023 von OpenAIs GPT-4 erreicht. Diese KI hat einen [verbaler IQ von 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), spricht 23 Sprachen, kann programmieren und [kann Menschen täuschen](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Glücklicherweise hat GPT-4 noch Einschränkungen. Zum Beispiel kann es nicht effektiv [hacken oder Computerviren schreiben](https://pauseai.info/cybersecurity-risks), aber es ist möglich, dass diese Fähigkeiten nur wenige Innovationen entfernt sind. Angesichts des aktuellen Tempos der KI-Investitionen nähert sich dieser Punkt [schnell](https://pauseai.info/urgency).

Diese massiven und unerwarteten Sprünge in den Fähigkeiten haben viele Experten dazu veranlasst, eine Pause in der Entwicklung von KI durch einen [offenen Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) an die großen KI-Unternehmen zu fordern. Der Brief wurde über 27.000 Mal unterzeichnet, hauptsächlich von KI-Forschern und Tech-Prominenten. Eine Pause ist notwendig, um KI-Gesetze zu entwickeln, an der KI-Alignment-Problematik zu arbeiten und sich als Gesellschaft an diese neue Technologie anzupassen. Eine [aktuelle Umfrage](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) in den Vereinigten Staaten zeigt eine signifikante Unterstützung für eine Pause mit mehr als 60% der Öffentlichkeit. Leider scheint es, dass Unternehmen nicht bereit sind, ihre Wettbewerbspositionen freiwillig zu gefährden, indem sie stoppen. Diese KI-Unternehmen sind in einem Wettlauf nach unten gefangen, bei dem die Sicherheit immer mehr hinter die Verbesserung der Fähigkeiten zurücktritt. Daher muss die Pause von den Regierungen auferlegt werden. Die Umsetzung einer nationalen Pause ist auch schwierig, da Länder Gründe haben, nicht als erste zu pausieren. Daher ist eine internationale Lösung notwendig: ein Gipfeltreffen. PauseAI ruft unsere Regierungen auf, dieses Gipfeltreffen zu organisieren.

Für weitere Informationen besuchen Sie bitte [PauseAI.info](http://pauseai.info).

## Medien {#press-release-english}

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Heute haben wir uns in Brüssel versammelt. Wir fordern unsere Regierungen auf, einen Gipfel zu organisieren, um die Risiken von KI zu diskutieren und die Entwicklung von superintelligenter KI zu verhindern. <a href="https://twitter.com/hashtag/pauseai?src=hash&amp;ref_src=twsrc%5Etfw">#pauseai</a> (1/5) <a href="https://t.co/tXdeftTNAp">pic.twitter.com/tXdeftTNAp</a></p>&mdash; Joep Meindertsma (@joepmeindertsma) <a href="https://twitter.com/joepmeindertsma/status/1661047436905725953?ref_src=twsrc%5Etfw">23. Mai 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>
