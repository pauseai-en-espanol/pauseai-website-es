---
title: Internationaler PauseAI-Protest am 21. Oktober 2023
description: Wir organisieren einen internationalen Protest, um eine Pause bei der Entwicklung gef√§hrlicher k√ºnstlicher Intelligenz zu fordern.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

## 21. Oktober (Samstag), in mehreren L√§ndern {#october-21st-saturday-in-multiple-countries}

- USA, Kalifornien, San Francisco ([Facebook](https://fb.me/1RbYq9H2hOFQ4yi))
- USA, Massachusetts, Boston ([Facebook](https://facebook.com/events/s/pauseai-protest-boston-make-th/6647554948613714/?mibextid=RQdjqZ))
- UK, Parliament Square, London ([Anmelden](https://www.mixily.com/event/4774799330762010477), [Facebook](https://www.facebook.com/events/644748401084077))
- Niederlande, Den Haag ([Anmelden](https://www.mixily.com/event/8536294863402363208))
- Australien, Melbourne ([Anmelden](https://www.mixily.com/event/8471341506387452508))
- Kanada, Ottawa (Organisiert von Align the World, anmelden auf [Facebook](https://www.facebook.com/events/243643008241929/) oder [Eventbrite](https://www.eventbrite.com/e/ai-safety-and-ethics-rally-tickets-725729686027))
- D√§nemark, Kopenhagen ([Facebook](https://www.facebook.com/events/869443424535827))
- Dein Land hier? [Diskutiere auf Discord!](https://discord.gg/anXWYCCdH5)

## Warum wir protestieren {#why-we-protest-1}

Die k√ºnstliche Intelligenz entwickelt sich rasant und wird immer leistungsf√§higer ‚Äì viel schneller als fast jeder KI-Wissenschaftler vorhergesagt hat.
Milliarden werden in KI-F√§higkeiten investiert, und die Ergebnisse sind beeindruckend.
Neue Modelle √ºberbieten Menschen in vielen Bereichen.
Mit zunehmender Leistungsf√§higkeit steigen auch die Risiken.
Wissenschaftler warnen sogar davor, dass KI m√∂glicherweise die Menschheit zerst√∂ren k√∂nnte.
Dieses katastrophale Ergebnis scheint nicht nur m√∂glich, sondern auch wahrscheinlich, da die durchschnittlichen Wahrscheinlichkeitssch√§tzungen f√ºr diese Ergebnisse zwischen 14% und 40% liegen.

Wir brauchen unsere F√ºhrer, die diese Warnungen ernst nehmen, aber sie nehmen dieses Thema nicht ann√§hernd so ernst, wie sie sollten.
Es gibt KI-Sicherheitsgesetze, die entworfen werden, aber keine einzige Ma√ünahme w√ºrde tats√§chlich die Entwicklung von superintelligenter KI verhindern oder verz√∂gern.
√úber 70% der Menschen wollen die KI-Entwicklung verlangsamen, und √ºber 60% wollen eine Regulierung, um die Entwicklung von superintelligenter KI aktiv zu verhindern.
Warum gibt es keinen Gesetzentwurf, der dies tats√§chlich tut?
Die Antwort ist Lobbyarbeit: Unsere Politiker treffen sich haupts√§chlich mit KI-Unternehmens-CEOs, und sie werden politische Ma√ünahmen durchsetzen, die in ihrem Interesse sind.

Am 1. und 2. November findet der erste KI-Sicherheitsgipfel im Vereinigten K√∂nigreich statt.
Dies ist eine einzigartige Chance, die ersten Schritte hin zu einer sinnvollen internationalen KI-Sicherheitsregulierung zu unternehmen.

## Was wir fordern {#what-we-ask-1}

- **Politiker**: Erlauben Sie Unternehmen nicht, eine Superintelligenz zu entwickeln. Regulierungen und Hardware-Einschr√§nkungen sollten vor dem Training gelten, da es sehr schwierig ist, die Verbreitung einer neuen F√§higkeit zu kontrollieren, sobald sie erreicht wurde. Wir k√∂nnen es uns nicht leisten, Unternehmen zu erlauben, potenziell weltzerst√∂rende KI-Modelle zu trainieren. Die Erstellung von Gesetzen ist schwierig und dauert lange, aber wir haben m√∂glicherweise nicht so viel Zeit, also arbeiten Sie, als ob Ihr Leben davon abh√§ngt. Denn das tut es.
- **Unternehmen**: Viele von Ihnen haben Angst vor dem, was KI tun kann, aber Sie sind in einem Wettlauf gefangen. Also seien Sie laut und unterst√ºtzen Sie eine Pause im Prinzip. Wenn Sie Erkl√§rungen unterzeichnen, dass diese Technologie uns alle t√∂ten k√∂nnte, zeigen Sie der Welt, dass Sie lieber nicht daran arbeiten w√ºrden, wenn es eine gangbare Option w√§re.
- **Gipfeltreffen-Teilnehmer**: Stellen Sie Sicherheit √ºber wirtschaftliches Wachstum. Wir wissen, dass KI unsere L√§nder reicher machen kann, aber das ist nicht der Grund, warum Sie hier sind. Seien Sie der Erwachsene im Raum.

F√ºr unseren gesamten Vorschlag siehe [hier](/proposal).

## Pressemitteilung {#press-release-5}

_SOFORTIGE VER√ñFFENTLICHUNG_

### Internationaler Protest fordert Stopp der gef√§hrlichen KI-Entwicklung {#international-protest-calls-for-a-halt-to-dangerous-ai-development}

**21. Oktober:** [**PauseAI**](https://pauseai.info/) **veranstaltet einen internationalen** [**Protest**](https://pauseai.info/2023-oct) **und fordert Politiker und Teilnehmer des KI-Sicherheitsgipfels auf, an einem Verbot der Entwicklung von superintelligenter KI zu arbeiten. Der Protest findet in** [**8 L√§ndern**](https://pauseai.info/2023-oct) **gleichzeitig statt und wird voraussichtlich der gr√∂√üte Protest f√ºr ein KI-Moratorium aller Zeiten sein.**

Orte:

- USA, Kalifornien, San Francisco
- UK, Parliament Square, London
- Niederlande, Den Haag
- Israel, Jerusalem
- Australien, Melbourne
- Kanada, Ottawa
- Deutschland, Berlin
- D√§nemark, Kopenhagen

Im M√§rz dieses Jahres unterzeichneten viele namhafte Experten [einen Brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.), in dem sie einen sechsmonatigen Stopp der Entwicklung ihrer Spitzen-KI-Modelle forderten. Im Mai unterzeichneten Hunderte von KI-Wissenschaftlern [eine Erkl√§rung](https://www.safe.ai/statement-on-ai-risk), in der es hei√üt: ‚ÄûDie Minderung des Risikos des Aussterbens durch KI sollte eine globale Priorit√§t neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein.‚Äú

Aktuelle [Umfragen](https://pauseai.info/polls-and-surveys) haben gezeigt, dass [√ºber 70%](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) der Menschen die KI-Entwicklung verlangsamen wollen und [√ºber 60%](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) wollen, dass die Regierung eingreift und die Entwicklung von superintelligenter KI verhindert. Bisher gibt es [keine Entw√ºrfe](https://twitter.com/PauseAI/status/1706605169608159458), die dies tun w√ºrden.

In zwei Wochen, am 1. und 2. November, findet der erste KI-Sicherheitsgipfel im Vereinigten K√∂nigreich statt. Der Gipfel wird von f√ºhrenden KI-Wissenschaftlern, Politikern und Industrief√ºhrern besucht. Dies ist eine einzigartige Chance, die ersten Schritte hin zu einer internationalen KI-Sicherheitsregulierung zu unternehmen. Allerdings plant das Vereinigte K√∂nigreich nicht, diese Gelegenheit zu nutzen, um starke KI-Regulierungen umzusetzen. Der Organisator und Vertreter des Premierministers f√ºr den KI-Sicherheitsgipfel, Matt Clifford, hat [erkl√§rt](https://twitter.com/PauseAI/status/1709845853668553065), dass ‚Äûein Stopp der KI-Entwicklung jetzt verfr√ºht w√§re‚Äú und dass er [nicht erwartet](https://twitter.com/matthewclifford/status/1708819574739587356), dass der Gipfel ‚Äûharte Kontrollen‚Äú bringt.

‚ÄûWir freuen uns, dass das Vereinigte K√∂nigreich die KI-Sicherheit anf√ºhrt und internationale F√ºhrung zeigt‚Äú, sagt Joep Meindertsma, Direktor von PauseAI. ‚ÄûAber wir sehen nicht das Ma√ü an Dringlichkeit, das es verdient. Im Jahr 2020 sagten Prognostiker [voraus](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/), dass die Ankunft von menschen√§hnlicher KI im Jahr 2055 erfolgen w√ºrde. Heute ist die [durchschnittliche Prognose](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. Wir k√∂nnen es uns nicht leisten, die Katastrophe zu riskieren, indem wir den Fortschritt untersch√§tzen. Wir brauchen unsere Politiker, die auf der Seite der Vorsicht erraten. Jedes einzelne Leben ist in Gefahr. Kein Unternehmen sollte in der Lage sein, eine Superintelligenz zu entwickeln.‚Äú

### Twitter {#twitter}

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Mehr aus London nach dem ersten international koordinierten <a href="https://twitter.com/PauseAI?ref_src=twsrc%5Etfw">@PauseAI</a> Protest! Am Samstag kamen Demonstranten in sieben St√§dten zusammen, um ein Verbot der Schaffung k√ºnstlicher Superintelligenz zu fordern, eine Woche vor <a href="https://twitter.com/RishiSunak?ref_src=twsrc%5Etfw">@RishiSunak</a>&#39;s KI-Sicherheitsgipfel. Lies weiter ‚¨áÔ∏è <a href="https://t.co/W2vYv4nVIl">pic.twitter.com/W2vYv4nVIl</a></p>&mdash; Alistair Stewart V ‚è∏Ô∏è (@alistair___s) <a href="https://twitter.com/alistair___s/status/1716566914242121768?ref_src=twsrc%5Etfw">23. Oktober 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Der PauseAI-Protest in San Francisco war ein gro√üer Erfolg. Dies war der gr√∂√üte KI-Sicherheitsprotest aller Zeiten in den Vereinigten Staaten und Teil des ersten und gr√∂√üten globalen KI-Sicherheitsprotests in der Geschichte! <br><br>Vielen Dank an alle, die ihn m√∂glich gemacht haben ü©∑ <a href="https://t.co/Yttdpgnrfa">pic.twitter.com/Yttdpgnrfa</a></p>&mdash; Holly ‚è∏Ô∏è Elmore (@ilex_ulmus) <a href="https://twitter.com/ilex_ulmus/status/1715954127954751932?ref_src=twsrc%5Etfw">22. Oktober 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>
