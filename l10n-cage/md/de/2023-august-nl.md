---
title: PauseAI-Protest in Den Haag, Niederlande - 11. August
description: Wir organisieren einen Protest, um eine Pause bei der Entwicklung gef√§hrlicher KI zu fordern.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Wir haben in Den Haag, Niederlande, protestiert, um unsere Regierung aufzufordern, die Milderung von KI-Risiken zu priorisieren. Wir hatten einige Reden, sprachen mit Menschen auf der Stra√üe, verteilten Flyer und hatten eine gute Zeit!<br><br>Siehe die Pressemitteilung (EN + NL) f√ºr weitere Informationen: <a href="https://t.co/Dd7CXHlajc">https://t.co/Dd7CXHlajc</a> <a href="https://t.co/T306vZD974">pic.twitter.com/T306vZD974</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1690290512643719168?ref_src=twsrc%5Etfw">12. August 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI-Protest
- Wo: Wijnhaven, Den Haag
- Wann: 11. August 2023, 16:00 - 17:00

## Warum wir protestieren {#why-we-protest}

Die Entwicklung von KI schreitet rasant voran, viel schneller als die meisten KI-Forscher vorhergesagt haben.
Milliarden werden in KI-F√§higkeiten investiert, und die Ergebnisse sind beeindruckend.
Neue Modelle √ºberbieten Menschen in vielen Bereichen.
Mit zunehmender Leistungsf√§higkeit steigen auch die Risiken.
Wissenschaftler warnen sogar davor, dass KI m√∂glicherweise die Menschheit gef√§hrden k√∂nnte.

Unsere Politiker nehmen dieses Thema nicht ernst genug.
Wir brauchen unsere F√ºhrer, die auf diese Warnungen h√∂ren.
Wir brauchen sie, um Ma√ünahmen zu ergreifen und eine Pause einzulegen, um dieses gef√§hrliche Wettr√ºsten zu stoppen.

Wir fordern die niederl√§ndische Regierung auf:

- KI-Sicherheitsexperten einzuladen, um das Parlament √ºber diese Risiken zu informieren
- Ein Debatt √ºber die existenziellen Risiken von KI zu f√ºhren
- Die Vorbereitungen f√ºr den KI-Sicherheitsgipfel sp√§ter dieses Jahres zu priorisieren und eine f√ºhrende Rolle bei der Ausarbeitung effektiver Politik zu √ºbernehmen
- International zusammenzuarbeiten, um ausreichende Sicherheitsma√ünahmen auf globaler Ebene umzusetzen

## Agenda {#agenda}

- 12:00 - 16:00 Vorbereitung von Schildern im Workshop (nur f√ºr die echten Enthusiasten, kontaktieren Sie uns, wenn Sie dabei sein m√∂chten!)
- 16:00 Reden + Protest + Flyerverteilung
- 17:00 Getr√§nke in einer nahegelegenen Kneipe

## Kontakt {#contact-7}

- Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io))

## Pressemitteilung (EN): PauseAI fordert die niederl√§ndische Regierung auf, menschheitsbedrohende KI-Katastrophen zu verhindern {#press-release-en-pauseai-calls-on-dutch-government-to-prevent-human-threatening-ai-related-disasters}

Am Freitag, dem 11. August, um 16:00 Uhr, wird eine Gruppe besorgter B√ºrger unter dem Namen [PauseAI](http://pauseai.info) vor dem Innenministerium zusammenkommen, um die Entwicklungen im Bereich der (generativen) KI anzusprechen. Sie fordern die Regierung auf, Ma√ünahmen zu ergreifen, um die Entwicklung leistungsf√§higer und m√∂glicherweise gef√§hrlicher k√ºnstlicher Intelligenz zu pausieren.

Bisher hat die niederl√§ndische Regierung keine Schritte unternommen, um die existenzielle Bedrohung durch KI zu adressieren. Es gab keine Reaktion auf Warnungen und Stellungnahmen von Organisationen wie den [UN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), dem Premierminister des [Vereinigten K√∂nigreichs](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (wo ein Gipfel zu diesem Thema f√ºr den Herbst geplant ist) und [KI-Experten](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie), selbst nachdem eine [Motion](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) im Parlament zuvor dieses Jahr zu solchen Ma√ünahmen aufgerufen hatte.

"Wissenschaftler schlagen Alarm: KI k√∂nnte das Ende der Menschheit bedeuten. Experten sch√§tzen die Wahrscheinlichkeit daf√ºr auf 30%. KI-Unternehmen rasen vorw√§rts und riskieren unser aller Leben, w√§hrend die Regulierung hoffnungslos hinterherhinkt." - Joep Meindertsma, CEO von Ontola und Gr√ºnder von PauseAI.

Die Sorgen √ºber die Risiken, die mit KI verbunden sind, wachsen weltweit rasant. Diese Woche ver√∂ffentlichte das Forschungsinstitut Axios die Ergebnisse einer Meinungsumfrage unter Einwohnern der Vereinigten Staaten, die ergab, dass 86% der Befragten besorgt √ºber katastrophale KI-Risiken sind.

"Die USA haben Senatsanh√∂rungen, bei denen KI-Experten dar√ºber sprechen, wie KI das Ende der Menschheit bedeuten k√∂nnte. Warum wird dieses Thema in der niederl√§ndischen Politik ignoriert? Insbesondere, da die Niederlande eine Schl√ºsselrolle in der Chip-Lieferkette spielen, dank ASML. Deshalb k√∂nnen sie auch eine Schl√ºsselrolle bei der KI-Regulierung spielen. Alle Leben stehen auf dem Spiel!" - Joep Meindertsma

PauseAI fordert die niederl√§ndische Regierung auf:

- KI-Sicherheitsexperten einzuladen, um das Parlament √ºber diese Risiken zu informieren
- Ein Debatt √ºber die existenziellen Risiken von KI zu f√ºhren
- Die Vorbereitungen f√ºr den vorgeschlagenen KI-Gipfel im Vereinigten K√∂nigreich sp√§ter dieses Jahres zu priorisieren und eine f√ºhrende Rolle bei der Ausarbeitung effektiver Politik zu √ºbernehmen
- International zusammenzuarbeiten, um ausreichende Sicherheitsma√ünahmen auf globaler Ebene umzusetzen, einschlie√ülich einer sogenannten KI-Pause.

F√ºr weitere Informationen besuchen Sie [PauseAI.info](http://pauseai.info). Kontakt: Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io)) & Ruben Dieleman ([E-Mail](mailto:ruben@existentialriskobservatory.org))

## Pressemitteilung (NL): PauseAI roept overheid op tot het voorkomen van mensbedreigende, AI-gerelateerde rampen {#press-release-nl-pauseai-roept-overheid-op-tot-het-voorkomen-van-mensbedreigende-ai-gerelateerde-rampen}

Op vrijdag 11 augustus om 16.00 komt een groep mensen samen die zich zorgen maken over de ontwikkelingen op het gebied van (generatieve) AI bij het Ministerie van Binnenlandse Zaken onder de naam [PauseAI](http://pauseai.info). Zij roepen de regering op zich in te spannen voor een pauze van de ontwikkeling van krachtige en mogelijk gevaarlijke kunstmatige intelligentie.

Tot nu toe heeft de Nederlandse regering echter geen actie ondernomen tegen de existenti√´le bedreiging van AI. Er is nog niet gereageerd op waarschuwingen en uitspraken van onder meer de [VN](https://www.linkedin.com/feed/update/urn:li:activity:7075088560508284928), de premier van het [Verenigd Koninkrijk](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (waar in het najaar een top wordt georganiseerd over dit onderwerp) en [experts op het gebied van AI](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie). Ook niet nadat eerder dit jaar een [motie](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) in de Tweede Kamer daartoe aanspoorde.

"Wetenschappers trekken aan de bel: AI kan het einde betekenen van de mensheid. Experts geven dit gemiddeld zelfs 30% kans. AI bedrijven racen vooruit en gokken met al onze levens, terwijl regulering hopeloos achter blijft." - Joep Meindertsma, directeur van softwarebedrijf Ontola en oprichter van PauseAI.

De zorgen over de risico's die kleven aan AI zijn mondiaal snel aan het groeien. Deze week nog publiceerde onderzoeksbureau Axios de resultaten van een opiniepeiling onder inwoners van de Verenigde Staten, waaruit bleek dat 86% zich zorgen maakt over catastrofale risico's van AI.

"De VS heeft senaatshoorzittingen waarbij AI experts vertellen over hoe AI het einde kan vormen van de mensheid. Waarom wordt dit onderwerp genegeerd in de Nederlandse politiek? En dat terwijl Nederland een sleutelrol speelt in de chip supply chain, dankzij ASML. Hierom kan het √≥√≥k een sleutelrol spelen in AI compute governance. Alle levens staan op het spel!" - Joep Meindertsma

PauseAI wil dat de Nederlandse regering:

- AI safety-experts uitnodigt om het parlement te informeren over deze risico's
- Een parlementair debat inroostert over de existenti√´le risico's van geavanceerde kunstmatige intelligentie
- Voorbereidingen op de voorgestelde AI-top in het Verenigd Koninkrijk van later dit jaar voorrang geeft en een leidende rol neemt inzake effectief beleid. De actievoerders hebben concrete voorstellen en beleidsidee√´n voor de te houden AI-top.
- Internationaal samenwerkt om een toereikende set maatregelen op mondiale schaal toegepast te krijgen, waaronder een zogenoemde AI-pauze.

Voor meer info, bezoek [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([Twitter](https://twitter.com/joepmeindertsma), [E-Mail](mailto:joep@ontola.io)) & Ruben Dieleman ([E-Mail](mailto:ruben@existentialriskobservatory.org))
