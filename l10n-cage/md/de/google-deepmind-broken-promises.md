---
title: Googles DeepMind bricht seine Versprechen
slug: google-deepmind-gebrochene-versprechen
description: Das KI-Unternehmen Google DeepMind hat die Versprechen gebrochen, die es der Öffentlichkeit gegeben hat.
date: 2025-06-30T12:36:00.000Z
---

Das KI-Unternehmen Google DeepMind hat mit der Veröffentlichung von Gemini 2.5 Pro seine Verpflichtungen gegenüber Regierungen und der Öffentlichkeit verletzt, wie sie im Rahmen der [Frontier AI Safety Commitments](https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024) festgelegt wurden.

### KI-Sicherheitsgipfel {#ai-safety-summits}

- Im Jahr 2023 fand im Bletchley Park der [erste KI-Sicherheitsgipfel](https://www.gov.uk/government/topical-events/ai-safety-summit-2023) statt, bei dem Regierungen und KI-Entwickler zum ersten Mal zusammenkamen, um über KI-Sicherheit zu diskutieren.
- Im Jahr 2024 co-organisierte das Vereinigte Königreich den [KI-Seoul-Gipfel](https://www.gov.uk/government/topical-events/ai-seoul-summit-2024). Technologieunternehmen, darunter Google, unterzeichneten die [Frontier AI Safety Commitments](https://www.gov.uk/government/publications/frontier-ai-safety-commitments-ai-seoul-summit-2024/frontier-ai-safety-commitments-ai-seoul-summit-2024), um einen Rahmen für die Entwicklung sichererer KI-Systeme zu schaffen.

### Die Frontier AI Safety Commitments {#the-frontier-ai-safety-commitments}

Die Verpflichtungen legen einen ersten Rahmen für KI-Entwickler fest, um grundlegende Vorsichtsmaßnahmen gegen die zunehmenden Risiken von KI-Modellen zu treffen. Es handelte sich um freiwillige Verpflichtungen, die in keinem Rechtsraum durchgesetzt wurden.

Zwei der Verpflichtungen lauten wie folgt:

- "I: Die Risiken, die ihre KI-Modelle darstellen, vor deren Einsatz bewerten und dabei auch Ergebnisse von externen Bewertungen berücksichtigen, wenn dies angebracht ist."
- "VIII: Erklären, wie externe Akteure, wie Regierungen, an der Bewertung der Risiken ihrer KI-Modelle beteiligt sind."

Google hat diese Verpflichtungen bei der Veröffentlichung von Gemini 2.5 Pro nicht eingehalten und damit einen gefährlichen Präzedenzfall für zukünftige Modelle geschaffen.

Wir sind der Meinung, dass Google für dieses Versagen zur Rechenschaft gezogen werden sollte, um die Legitimität der internationalen KI-Sicherheitsgipfel aufrechtzuerhalten und die Verabschiedung zukünftiger KI-Regulierungen zu erleichtern.

### Zeitplan und Details von Googles Verstoß {#timeline-and-details-of-googles-violation}

#### 25. März 2025 {#25-march-2025}

- [Gemini 2.5 Pro Experimental](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/) wurde für jeden kostenlos zugänglich gemacht. Es ist wahrscheinlich das leistungsfähigste KI-Modell, das bisher von einem Unternehmen veröffentlicht wurde.
- [Keine Informationen](https://fortune.com/2025/04/09/google-gemini-2-5-pro-missing-model-card-in-apparent-violation-of-ai-safety-promises-to-us-government-international-bodies/) über Sicherheitstests wurden veröffentlicht.

#### 3. April 2025 {#3-april-2025}

- Googles Produktchef für Gemini [erklärte gegenüber TechCrunch](https://techcrunch.com/2025/04/03/google-is-shipping-gemini-models-faster-than-its-ai-safety-reports/), das Unternehmen habe keinen "Model Card" (Sicherheitsbericht) für Gemini 2.5 Pro veröffentlicht, "da es das Modell als 'experimentell' betrachtet".

#### 9. April 2025 {#9-april-2025}

- [In Korrespondenz mit dem Fortune-Magazin](https://fortune.com/2025/04/09/google-gemini-2-5-pro-missing-model-card-in-apparent-violation-of-ai-safety-promises-to-us-government-international-bodies) beantwortete Google keine "direkten Fragen" über die Beteiligung des UK AI Security Institute am Testprozess für Gemini 2.5 Pro. Ein Sprecher von Google sagte jedoch, dass das Modell vor der Veröffentlichung getestet wurde.

#### 16. April 2025 {#16-april-2025}

- Gemini 2.5 Pro Preview wurde verfügbar gemacht (im Wesentlichen das gleiche wie das Experimental-Modell).
- Google veröffentlichte seinen ['Model Card'](https://web.archive.org/web/20250417044145/https://storage.googleapis.com/model-cards/documents/gemini-2.5-pro-preview.pdf) (Sicherheitsbericht) für Gemini 2.5 Pro Preview.
- Der Testbericht erwähnt keine externen Tests.

#### 28. April 2025 {#28-april-2025}

- Google [aktualisierte](https://web.archive.org/web/20250502190015/https://storage.googleapis.com/model-cards/documents/gemini-2.5-pro-preview.pdf) seinen Model Card, um die Erwähnung von "externen Testern" aufzunehmen, aber ohne Details über ihre Identität.

#### April - Juni 2025 {#april---june-2025}

- [Weitere technische Berichte](https://storage.googleapis.com/deepmind-media/gemini/gemini_v2_5_report.pdf) wurden seitdem veröffentlicht. Keiner von ihnen nennt die externen Tester oder sagt, ob Regierungen an den Tests beteiligt waren.

## Fazit {#conclusion}

- Google hat den Geist der Verpflichtung I verletzt, indem es seinen ersten Sicherheitsbericht fast einen Monat nach der öffentlichen Verfügbarkeit veröffentlichte und externe Tests in seinem ersten Bericht nicht erwähnte.
- Google hat die Verpflichtung VIII explizit verletzt, indem es nicht angab, ob Regierungen an Sicherheitstests beteiligt waren, auch nachdem es direkt von Reportern gefragt wurde.

## Protest {#protest}

Als Reaktion darauf wird PauseAI am Montag, dem 30. Juni, unseren größten Protest bisher mit über 100 Teilnehmern durchführen.

Melde dich [hier](https://pauseai.info/deepmind-protest-2025) an.
