---
title: PauseAI / Keine AGI-Proteste @ OpenAI San Francisco - 12. Februar 2024
description: Wir organisieren eine Protestaktion, um eine Pause bei der Entwicklung gefährlicher KI zu fordern.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- PauseAI-Protest
- Wo: San Francisco, OpenAI-Hauptquartier
- Wann: 12. Februar 2024, 16:30 - 18:00 Uhr
- [Facebook-Event](https://fb.me/e/78BzWmaaj)
- [Website](https://openaiprotest.com/)

Andere internationale Orte / Zeiten:
UK (genauer Ort noch nicht bekannt) / 16:00 Uhr GMT

## Warum wir gegen OpenAI protestieren {#why-we-are-protesting-openai}

OpenAI strebt danach, eine KI zu entwickeln, die intelligenter ist als Menschen.
Hunderte von Wissenschaftlern warnen davor, dass dies das Ende der Menschheit bedeuten könnte.
Deshalb haben über 33.000 Menschen den Pause-Brief unterzeichnet, in dem sie KI-Unternehmen wie OpenAI auffordern, ihre Forschung zu stoppen.
Sogar Sam Altman, der CEO von OpenAI, hat gesagt, dass wir auf die Bremse treten sollten, wenn KI-Modelle sich auf Weise verbessern, die wir nicht vollständig verstehen.
In einem anderen Interview bezeichnete Sam die Vorhersage von Fähigkeiten als ein "unterhaltsames Ratespiel" für OpenAI-Mitarbeiter.
Mit anderen Worten: Selbst OpenAI versteht nicht, wie ihre Modelle verbessert werden.
Es ist Zeit, auf die Bremse zu treten.

## Schließ dich uns an und sage OpenAI: "Hört auf, mit dem Pentagon zusammenzuarbeiten!" {#join-us-and-tell-openai-stop-working-with-the-pentagon}

Am 10. Januar hat OpenAI ohne Ankündigung die entsprechenden Passagen aus seiner Nutzungsrichtlinie gestrichen, die besagten, dass OpenAI die Verwendung seiner Modelle für "Aktivitäten, die ein hohes Risiko von Schäden bergen", wie "Militär und Krieg", nicht zulässt. Dann berichtete TIME am 17. Januar, dass OpenAI das Pentagon als Kunden aufnehmen würde. Am 12. Februar werden wir von OpenAI fordern, seine Beziehung zum Pentagon zu beenden und keine militärischen Kunden anzunehmen. Wenn ihre ethischen und Sicherheitsgrenzen aus Bequemlichkeit revidiert werden können, können sie nicht vertrauenswürdig sein.

KI wird rapide immer leistungsfähiger, viel schneller als fast jeder KI-Wissenschaftler vorhergesagt hat. Milliarden werden in KI-Fähigkeiten investiert, und die Ergebnisse sind atemberaubend. Neue Modelle überbieten Menschen in vielen Bereichen. Mit zunehmenden Fähigkeiten steigen auch die Risiken. Wissenschaftler warnen sogar, dass KI die Menschheit zerstören könnte.

Laut ihrer Satzung ist OpenAIs Mission, sicherzustellen, dass künstliche allgemeine Intelligenz (AGI) allen Menschen zugutekommt. Doch viele Menschen schätzen ihre Arbeit und finden Sinn darin, und daher wollen sie nicht, dass ihre Jobs von einer AGI übernommen werden. Der Protest-Mitorganisator Sam Kirchner von No AGI bezeichnet dies als die "psychologische Bedrohung", die auch dann gilt, wenn AGI uns nicht tötet.

## Kontakt {#contact-3}

- Holly Elmore ([Twitter](https://twitter.com/ilex_ulmus))
- Sam Kirchner ([Twitter](https://twitter.com/No_AGI_))

## Medienberichterstattung {#media-coverage}

- [Bloomberg](https://www.bloomberg.com/news/newsletters/2024-02-13/ai-protest-at-openai-hq-in-san-francisco-focuses-on-military-work)
- [ReadWrite](https://readwrite.com/stop-working-with-pentagon-openai-staff-face-protests/)
- [VentureBeat](https://venturebeat.com/ai/protesters-gather-outside-openai-office-opposing-military-ai-and-agi/)

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">From the protest yesterday at OpenAI HQ, covered in Bloomberg: <a href="https://t.co/sgp1KFoFPs">https://t.co/sgp1KFoFPs</a> <a href="https://t.co/N6fHGIlOYm">pic.twitter.com/N6fHGIlOYm</a></p>&mdash; PauseAI US (@pauseaius) <a href="https://twitter.com/pauseaius/status/1757604719047114786?ref_src=twsrc%5Etfw">February 14, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>
