---
title: Waarom we AI-veiligheidstoppen nodig hebben
description: Waarom we de AI-veiligheidstop nodig hebben en wat deze moet bereiken.
---

AI vormt tal van [risico's](/risks) voor de mensheid, waaronder het [risico van uitsterven](/xrisk).
De vooruitgang in AI-capaciteiten versnelt in een [razend tempo](/urgency), en wij zijn niet voorbereid op de gevolgen.
AI-bedrijven zijn verwikkeld in een wedloop naar de bodem, waarbij veiligheid niet de hoogste prioriteit heeft.
We hebben overheden nodig om in te grijpen en te voorkomen dat AI supermenselijke niveaus bereikt voordat we weten hoe we het veilig kunnen maken.
Deze [pauze](/proposal) moet op internationaal niveau plaatsvinden, omdat landen verwikkeld zijn in een wedloop die vergelijkbaar is met die van de bedrijven.
Internationale overeenkomsten betekenen _verdragen_, en dat vereist dat landen elkaar ontmoeten en onderhandelen.
**De enige manier om een echte pauze te bereiken is via een topconferentie.**

Er zijn enkele voorbeelden van internationale toppen en resulterende verdragen die succesvol zijn geweest in het verminderen van risico's:

- **Montreal-protocol** (1987): Het Montreal-protocol is een internationaal milieuvredrag dat bedoeld is om de ozonlaag te beschermen door de productie en consumptie van ozonafbrekende stoffen af te bouwen. Het is zeer succesvol geweest in het verminderen van het gebruik van stoffen als chloorfluorkoolwaterstoffen (CFK's) en heeft bijgedragen aan het geleidelijke herstel van de ozonlaag.
- **Verdrag van Stockholm over persistente organische verontreinigende stoffen** (2001): Het Verdrag van Stockholm is een internationaal verdrag dat bedoeld is om de menselijke gezondheid en het milieu te beschermen tegen persistente organische verontreinigende stoffen (POP's). Deze zijn giftige chemicaliën die in het milieu blijven bestaan, zich ophopen in levende organismen en ernstige nadelige effecten kunnen hebben op de menselijke gezondheid en ecosystemen. Wetenschappers hebben hun bezorgdheid geuit over de schadelijke effecten van POP's, waaronder hun vermogen om over lange afstanden te reizen via lucht- en waterstromen. Het verdrag leidde tot het verbieden of streng beperken van de productie en het gebruik van verschillende POP's, waaronder polychloorbifenylen (PCB's), dichloordifenyltrichloorethaan (DDT) en dioxinen.

## Eerdere toppen {#past-summits-1}

### 2023 UK AI-veiligheidstop {#2023-uk-ai-safety-summit-1}

Het primaire doel van PauseAI was om één regering te overtuigen om zo'n top te organiseren.
Slechts 5 weken na de eerste PauseAI-protesten kondigde de Britse regering aan dat ze een AI-veiligheidstop zouden organiseren, die op 1 en 2 november 2023 plaatsvond.
De top was relatief klein (slechts 100 mensen waren uitgenodigd) en vond plaats in Bletchley Park.
Hoewel het niet leidde tot een bindend verdrag, leidde het wel tot de ["Bletchley-verklaring"](https://www.gov.uk/government/publications/ai-safety-summit-2023-the-bletchley-declaration/the-bletchley-declaration-by-countries-attending-the-ai-safety-summit-1-2-november-2023), die door alle 28 deelnemende landen werd ondertekend.
In deze verklaring erkenden de landen de risico's van AI (waaronder 'problemen met controle in verband met afstemming op menselijke intentie').
Deze top leidde ook tot de aankondiging van twee vervolgtopen in 2024, in Seoul en Parijs.

### 2024 Zuid-Korea AI-veiligheidstop (21 en 22 mei) {#2024-south-korea-ai-safety-summit-may-21st-22nd-1}

Maandenlang was het onduidelijk wat de reikwijdte van deze top in Seoul zou zijn.
Alles wat we wisten, was dat het een ["virtuele minitop"](https://www.bracknellnews.co.uk/news/national/23898764.ai-safety-institute-will-make-uk-global-hub-rishi-sunak-says/) zou zijn.
Een nogal weinig ambitieuze manier om om te gaan met de zeer alarmerende oproepen tot regulering.
In april 2024 werd de tweede AI-veiligheidstop [officieel aangekondigd](https://www.gov.uk/government/news/uk-and-republic-of-korea-to-build-on-legacy-of-bletchley-park) door de Britse regering.
We [organiseerden een protest op 13 mei](/2024-may) om onze ministers te overtuigen om de top bij te wonen (sommigen hadden [niet eens de bedoeling om te komen](https://www.reuters.com/technology/second-global-ai-safety-summit-faces-tough-questions-lower-turnout-2024-04-29/)) en onderhandelingen over een verdrag op te starten met als doel een pauze.

De top leidde tot de volgende zaken:

1. 16 bedrijven (de meeste prominente AI-bedrijven) ondertekenden de ["Frontier AI Safety Commitments"](https://www.gov.uk/government/news/historic-first-as-companies-spanning-north-america-asia-europe-and-middle-east-agree-safety-commitments-on-development-of-ai?utm_source=substack&utm_medium=email), wat betekent dat deze bedrijven RSP's zullen publiceren. Eerdere vrijwillige toezeggingen [werden genegeerd](https://www.politico.eu/article/rishi-sunak-ai-testing-tech-ai-safety-institute/).
2. Een [nieuwe verklaring](https://www.gov.uk/government/publications/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024/seoul-ministerial-statement-for-advancing-ai-safety-innovation-and-inclusivity-ai-seoul-summit-2024) werd ondertekend door 27 landen.

### November 2024 San Francisco AI-veiligheidsconferentie {#november-2024-san-francisco-ai-safety-conference-1}

In september verrasten het AISI en de Amerikaanse regering ons met de aankondiging van een nieuwe top.
Of, meer precies, twee nieuwe bijeenkomsten in San Francisco.

Op **20 en 21 november** vond de eerste internationale bijeenkomst van [AI-veiligheidsinstituten](https://www.commerce.gov/news/press-releases/2024/09/us-secretary-commerce-raimondo-and-us-secretary-state-blinken-announce) plaats, georganiseerd door de Amerikaanse regering, met als doel "het bevorderen van mondiale samenwerking en kennisdeling op het gebied van AI-veiligheid".
De eerste leden van het Internationale Netwerk van AI-veiligheidsinstituten zijn Australië, Canada, de Europese Unie, Frankrijk, Japan, Kenia, de Republiek Korea, Singapore, het Verenigd Koninkrijk en de Verenigde Staten.
China is opvallend afwezig in deze lijst - zelfs al is [China's nieuwe AI-veiligheidsinstituut](https://x.com/yi_zeng/status/1831133250946838740) aangekondigd.

Op **21 en 22 november** organiseerde het Britse AISI een [conferentie in San Francisco](https://www.aisi.gov.uk/work/conference-on-frontier-ai-safety-frameworks).
Het hoofddoel hier was om "experts van ondertekenende bedrijven en onderzoeksorganisaties bijeen te brengen om de meest urgente uitdagingen in het ontwerp en de implementatie van grensverleggende AI-veiligheidskaders te bespreken".

### ~~2024~~ 2025 Frankrijk AI ~~Veiligheid~~ Actie-top {#2024-2025-france-ai-safety-action-summit-1}

Tijdens de Bletchley-top van 2023 koos Frankrijk ervoor om de volgende grote top in november 2024 te organiseren.
Frankrijk stelde het uit tot februari 2025.
Het werd ook omgedoopt tot "AI _Actie_-top", waarbij de belangrijke focus op "Veiligheid" werd laten vallen.
Het werd geleid door AI-scepticus Anne Bouverot, die [afwijzend](https://legrandcontinent-eu.translate.goog/es/2023/12/08/la-ia-no-nos-sustituira-una-conversacion-con-anne-bouverot-yann-le-cun-y-alexandre-viros/?_x_tr_sl=es&_x_tr_tl=en&_x_tr_hl=en&_x_tr_pto=sc) staat tegenover "alarmistische discours", waarbij AI wordt vergeleken met rekenmachines en AI-veiligheidszorgen worden vergeleken met Y2K-zorgen, en waarbij ze ervan overtuigd is dat "AI ons niet zal vervangen, maar ons zal helpen".
We [protesteerden](/2025-february) tegen het ontbreken van een veiligheidsfocus op de top.

De top is breed bekritiseerd door de AI-veiligheidsgemeenschap.
We raden aan om [het artikel van Zvi](https://thezvi.substack.com/p/the-paris-ai-anti-safety-summit) te lezen over de ["Anti-AI-veiligheidstop"](https://thezvi.substack.com/p/the-paris-ai-anti-safety-summit).

## Aankomende toppen {#coming-summits-1}

- India was mede-organisator van de Parijse top en zal de volgende organiseren. Helaas verwachten we dat het geen zinvolle veiligheids- of reguleringsdiscussies zal bevatten.
- De VN organiseert de [AI For Good-top](https://aiforgood.itu.int/) in Zwitserland, juli 2025.

## Wat we missen {#what-were-missing-1}

Geen van de geplande toppen is gericht op veiligheid of internationale regelgeving.
We hebben één land nodig dat een top organiseert die gericht is op veiligheid en internationale regelgeving.
Het is onze taak om een politicus te vinden die dit zal doen.
