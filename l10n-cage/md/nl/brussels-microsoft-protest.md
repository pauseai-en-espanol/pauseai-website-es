---
title: PauseAI protest @ Microsoft Brussel - 23 mei 2023
description: We organiseren een protest bij Microsoft om een topconferentie te eisen om de ontwikkeling van AI te pauzeren.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- 23 mei 2023, 11:45 - 13:00
- [Microsoft Innovation Center, Rue Montoyer 51, Brussel, België](https://goo.gl/maps/bvLbHDt61eSfpZV28?coh=178571&entry=tt)
- [Meld je aan op Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592)

## Doe mee {#join}

- Doe mee op [Discord](https://discord.gg/2XXWXvErfA?event=1105793166927470592) om je aan te melden en de protesten te bespreken.
- Lees de [gedragscode voor demonstranten](/protesters-code-of-conduct).

## Wat willen we? {#what-do-we-want}

We willen dat onze overheden (en de EU in het bijzonder) een [topconferentie](/summit) organiseren over de [risico's](/risks) van AI.
We willen dat ze de ontwikkeling van AI [pauzeren](/proposal) totdat we voldoende voorbereid zijn op de gevolgen.

## Waarom bij Microsoft? {#why-at-microsoft}

Microsoft heeft 13 miljard dollar geïnvesteerd in OpenAI, dat momenteel de krachtigste AI-modellen ontwikkelt.
Microsoft is verwikkeld in een wedloop met andere AI-bedrijven (zoals Google en Anthropic) om zo snel mogelijk de krachtigste AI-systemen te bouwen.
Deze marktdynamiek is gevaarlijk omdat het bedrijven aanzet om zich te concentreren op capaciteiten en veiligheidsinspanningen te minimaliseren.
Deze dynamiek brengt [verschillende risico's](/risks) met zich mee, waaronder [existentieel risico](/xrisk).

We denken dat Microsoft in een goede positie is om verantwoordelijkheid te nemen en een pauze in gigantische AI-experimenten te ondersteunen.

## Persbericht {#press-release-nederlands}

Op dinsdag 23 mei om 12 uur vindt er een protest plaats voor het Microsoft Innovation Center in Brussel. Vrijwilligers van de nieuwe [PauseAI](http://pauseai.info)-beweging komen daar samen om overheden op te roepen om de gevaren van AI te bespreken op een topconferentie.

De helft van de AI-onderzoekers [denkt](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dat er 10% of meer kans is dat de uitvinding van bovenmenselijke AI het einde van de mensheid betekent. Zou u in een vliegtuig stappen waarvan de helft van de vliegtuigbouwers denken dat de kans op neerstorten 10% is?

Opvallende voorbeelden van mensen die waarschuwen voor het gevaar van AI zijn prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) en prof. Yoshua Bengio, beiden winnaars van de Turing Award en pioniers van de meest succesvolle AI-methoden. Niet alleen wetenschappers, maar ook de leiders van AI-bedrijven zelf zijn bezorgd over dit gevaar:

- Sam Altman (CEO van OpenAI, het bedrijf achter ChatGPT): ["De ontwikkeling van bovenmenselijke machine-intelligentie is waarschijnlijk de grootste bedreiging voor het voortbestaan van de mensheid."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (co-oprichter van OpenAI): ["AI heeft het potentieel om de beschaving te vernietigen."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (co-oprichter van Microsoft, eigenaar van 50% van OpenAI): ["AI kan besluiten dat mensen een bedreiging vormen."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (hoofdinvesteerder van Anthropic, ontwikkelaars van Claude): ["Ik heb nog nooit iemand in AI-labs ontmoet die zegt dat het risico [van het trainen van een next-gen model] minder dan 1% is om de planeet op te blazen. Het is belangrijk dat mensen weten dat levens op het spel staan."](https://twitter.com/liron/status/1656929936639430657)

De ontwikkelingen in het AI-landschap zijn veel sneller gegaan dan verwacht. In 2020 werd [ingeschat](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) dat een AI de universitaire toelatingsexamens zou halen in 2050. Dit doel is gehaald in maart 2023, door het systeem GPT-4 van OpenAI. Deze AI heeft een [verbaal IQ van 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), spreekt 23 talen, kan programmeren en [kan mensen misleiden](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Gelukkig kan GPT-4 nog niet alles. Het kan bijvoorbeeld nog niet effectief [hacken of computervirussen schrijven](https://pauseai.info/cybersecurity-risks), maar het is mogelijk dat deze vaardigheden slechts enkele innovaties van ons zijn verwijderd. Door het huidige tempo waarop er in AI wordt geïnvesteerd komt dit punt [snel dichterbij](https://pauseai.info/urgency).

Deze gigantische, onverwachte sprongen in capaciteiten hebben veel experts ertoe aangezet om middels een [open brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) de grote AI-bedrijven te vragen om hun ontwikkelingen te pauzeren. Deze is inmiddels meer dan 27.000 keer ondertekend - veelal door AI-onderzoekers en tech-prominenten. De pauze is nodig om AI-beleid uit te werken, AI-safety onderzoek te doen en om als maatschappij te reageren op de snelle veranderingen. Uit een [recent onderzoek](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) uit de VS lijkt er ook veel steun voor een pauze, meer dan 60%. Helaas lijkt het er niet op dat bedrijven bereid zijn hun concurrentiepositie in gevaar te brengen door vrijwillig te stoppen. Deze AI-bedrijven zitten vast in een race naar de bodem, waarbij de veiligheid steeds meer ondergeschikt wordt aan het verbeteren van capaciteiten. De pauze moet dus door overheden worden opgelegd. Op nationaal niveau is een pauze eveneens lastig, gezien landen onderling ook redenen hebben om niet als eerste te pauzeren. We hebben daarom een internationaal middel nodig: een topconferentie. PauseAI roept onze overheden op om die topconferentie te organiseren.

Meer informatie is te vinden op [PauseAI.info](http://pauseai.info).

## Media {#press-release-english}

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="nl" dir="ltr">Vandaag verzamelden we ons in Brussel. We vragen onze overheden om een topconferentie te organiseren om AI-risico's te bespreken en de ontwikkeling van superintelligente AI te voorkomen. <a href="https://twitter.com/hashtag/pauseai?src=hash&amp;ref_src=twsrc%5Etfw">#pauseai</a> (1/5) <a href="https://t.co/tXdeftTNAp">pic.twitter.com/tXdeftTNAp</a></p>&mdash; Joep Meindertsma (@joepmeindertsma) <a href="https://twitter.com/joepmeindertsma/status/1661047436905725953?ref_src=twsrc%5Etfw">23 mei 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>
