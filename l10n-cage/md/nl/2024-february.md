---
title: PauseAI / Geen AGI Protest @ OpenAI San Francisco - 12 februari 2024
description: Wij organiseren een protest om een pauze te eisen in de ontwikkeling van gevaarlijke AI.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

- PauseAI protest
- Waar: San Francisco, OpenAI HQ
- Wanneer: 12 februari 2024, 16:30 - 18:00
- [Facebook-evenement](https://fb.me/e/78BzWmaaj)
- [Website](https://openaiprotest.com/)

Andere internationale locaties / tijden:
VK (exacte locatie nog niet bekend) / 16:00 GMT

## Waarom wij OpenAI protesteren {#why-we-are-protesting-openai}

OpenAI probeert een AI te ontwikkelen die slimmer is dan mensen.
Honderden wetenschappers waarschuwen dat dit het einde van de mensheid kan betekenen.
Dit is waarom meer dan 33.000 mensen de Pause-brief hebben ondertekend, waarin zij AI-bedrijven als OpenAI oproepen om hun ontwikkelingen te stoppen.
Zelfs Sam Altman, de CEO van OpenAI, heeft gezegd dat we moeten afremmen ["als AI-modellen op manieren verbeteren die wij niet volledig begrijpen"](https://time.com/6288584/openai-sam-altman-full-interview/).
In een ander interview noemde Sam het voorspellen van capaciteiten een ["gokspel"](https://www.ft.com/content/dd9ba2f6-f509-42f0-8e97-4271c7b84ded) voor OpenAI-medewerkers.
Met andere woorden: zelfs OpenAI begrijpt niet hoe hun modellen verbeteren.
Het is nu tijd om af te remmen.

## Doe mee en zeg tegen OpenAI "Stop met werken voor het Pentagon!" {#join-us-and-tell-openai-stop-working-with-the-pentagon}

Op 10 januari heeft OpenAI zonder enige aankondiging de tekst in hun gebruiksbeleid verwijderd die stelde dat OpenAI niet toestaat dat hun modellen worden gebruikt voor "activiteiten die een hoge kans hebben om schade te veroorzaken", zoals "militaire en oorlogsdoeleinden". Vervolgens berichtte TIME op 17 januari dat OpenAI het Pentagon als klant zou aannemen. Op 12 februari zullen wij eisen dat OpenAI hun relatie met het Pentagon beëindigt en geen militaire klanten aanneemt. Als hun ethische en veiligheidsgrenzen naar believen kunnen worden herzien, kunnen zij niet worden vertrouwd.

AI wordt snel steeds krachtiger, veel sneller dan vrijwel elke AI-wetenschapper heeft voorspeld. Miljarden worden in AI-capaciteiten gestoken, en de resultaten zijn verbluffend. Nieuwe modellen presteren beter dan mensen in veel domeinen. Naarmate de capaciteiten toenemen, nemen ook de risico's toe. Wetenschappers waarschuwen zelfs dat AI de mensheid kan vernietigen.

Volgens hun charter is "OpenAI's missie om ervoor te zorgen dat kunstmatige algemene intelligentie (AGI) - waarmee wij bedoelen: zeer autonome systemen die mensen overtreffen in alle economisch waardevolle werk - ten goede komt aan de hele mensheid". Maar veel mensen waarderen hun werk en vinden er betekenis in, en willen dus niet dat hun banen door een AGI worden overgenomen. Wat protestcoördinator Sam Kirchner van No AGI "de psychologische dreiging" noemt, geldt zelfs als AGI ons niet doodt.

## Contact {#contact-1}

- Holly Elmore ([Twitter](https://twitter.com/ilex_ulmus))
- Sam Kirchner ([Twitter](https://twitter.com/No_AGI_))

## Media-aandacht {#media-coverage}

- [Bloomberg](https://www.bloomberg.com/news/newsletters/2024-02-13/ai-protest-at-openai-hq-in-san-francisco-focuses-on-military-work)
- [ReadWrite](https://readwrite.com/stop-working-with-pentagon-openai-staff-face-protests/)
- [VentureBeat](https://venturebeat.com/ai/protesters-gather-outside-openai-office-opposing-military-ai-and-agi/)

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">Van de protest gisteren bij OpenAI HQ, besproken in Bloomberg: <a href="https://t.co/sgp1KFoFPs">https://t.co/sgp1KFoFPs</a> <a href="https://t.co/N6fHGIlOYm">pic.twitter.com/N6fHGIlOYm</a></p>&mdash; PauseAI US (@pauseaius) <a href="https://twitter.com/pauseaius/status/1757604719047114786?ref_src=twsrc%5Etfw">14 februari 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>
