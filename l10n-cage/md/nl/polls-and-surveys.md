---
title: Enquêtes en peilingen
description: Hoeveel zorgen maken gewone mensen en experts zich over de risico's en governance van AI?
---

## Deskundigen over catastrofale risico's {#expert-opinion-on-catastrophic-risks}

- **[AI-onderzoekers, AIImpacts 2022](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/)**: schatten de kans op "echt slechte uitkomsten (zoals menselijke uitsterving)" op 14%, met een mediaan van 5%. 82% vindt het controleprobleem belangrijk.
- **[AI-onderzoekers, AIImpacts 2023](https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai)**: De gemiddelde kans op een catastrofaal scenario (p(doom)) ligt tussen 14 en 19,4%, afhankelijk van hoe de vraag wordt gesteld. 86% vindt het controleprobleem belangrijk.
- **[AI-ingenieurs / startup-oprichters, State of AI Engineering](https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135#694f89e86f9148cb855220ec05e9c631)**: meer dan 60% schat de kans op een catastrofaal scenario (p(doom)) op meer dan 25%. Slechts 12% schat de kans op 0%.
- **[AI-veiligheidsonderzoekers, AlignmentForum](https://web.archive.org/web/20221013014859/https://www.alignmentforum.org/posts/QvwSr5LsxyDeaPK5s/existential-risk-from-ai-survey-results)**: respondenten schatten de mediaankans op een existentieel risico veroorzaakt door een gebrek aan voldoende technisch onderzoek op 20%, en op 30% voor een existentieel risico veroorzaakt door een falen van AI-systemen om te doen wat de mensen die ze inzetten bedoelen, met enorme variatie (bijvoorbeeld, er zijn gegevenspunten bij zowel ~1% als ~99%).

## Publieke opinie over catastrofale risico's {#public-opinion-on-catastrophic-risks}

- **[Britse burgers, PublicFirst](https://publicfirst.co.uk/ai/)**: denken dat er een kans van 9% is dat de mensheid zal uitsterven door AI. Ongeveer 50% zegt dat ze erg of enigszins bezorgd zijn over dit onderwerp.
- **[Duitse burgers, Kira](https://www.zeit.de/digital/2023-04/ki-risiken-angst-umfrage-forschung-kira)**: Slechts 14% gelooft dat AI een positieve invloed op de wereld zal hebben, 40% is gemengd, 40% negatief.
- **[Amerikaanse burgers, RethinkPriorities](https://rethinkpriorities.org/publications/us-public-perception-of-cais-statement-and-the-risk-of-extinction)**: gaat akkoord met (59%) en steunt (58%) de verklaring over existentiële risico's. Afwijzing (26%) en verzet (22%) waren relatief laag, en aanzienlijke aantallen mensen bleven neutraal (12% en 18% voor akkoord- en steunformaten, respectievelijk).
- **[Australische burgers, Ready Research](https://theconversation.com/80-of-australians-think-ai-risk-is-a-global-priority-the-government-needs-to-step-up-225175)**: 80% denkt dat AI-risico een wereldwijde prioriteit is, 64% wil dat de regering zich richt op catastrofale uitkomsten (in vergelijking met slechts 25% op baanverlies, of 5% op vooroordelen).

## Publieke opinie over regelgeving en governance {#public-opinion-on-regulations--governance}

- **[Britse burgers, YouGov](https://time.com/7213096/uk-public-ai-law-poll/)**: 87% van de Britten zou een wet steunen die AI-ontwikkelaars verplicht om te bewijzen dat hun systemen veilig zijn voordat ze worden vrijgegeven, met 60% voorstander van het verbieden van de ontwikkeling van "slimme-dan-menselijke" AI-modellen.
- **[Amerikaanse burgers, RethinkPriorities](https://forum.effectivealtruism.org/posts/ConFiY9cRmg37fs2p/us-public-opinion-of-ai-policy-and-risk)**: 50% steunt een pauze, 25% verzet zich tegen een pauze.
- **[Amerikaanse burgers, YouGov](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation)**: 72% wil dat AI vertraagt, 8% wil versnellen. 83% van de kiezers gelooft dat AI per ongeluk een catastrofaal evenement kan veroorzaken
- **[Amerikaanse burgers, YouGov](https://theaipi.org/poll-shows-voters-oppose-open-sourcing-ai-models-support-regulatory-representation-on-boards-and-say-ai-risks-outweigh-benefits-2/)**: 73% gelooft dat AI-bedrijven aansprakelijk moeten worden gesteld voor schade veroorzaakt door technologie die ze creëren, 67% denkt dat de macht van AI-modellen moet worden beperkt, en 65% gelooft dat het voorkomen dat AI in handen van slechte actoren valt belangrijker is dan het bieden van de voordelen van AI aan iedereen.
- **[Amerikaanse burgers, AIPI](https://www.politico.com/newsletters/digital-future-daily/2023/11/29/exclusive-what-people-actually-think-about-ai-00129147)**: 49:20 steun voor "een internationaal verdrag om elke 'slimme-dan-menselijke' kunstmatige intelligentie (AI) te verbieden?", 70:14 steun voor "Voorkomen dat AI snel supermenselijke capaciteiten bereikt"
- **[Amerikaanse informatica-professoren, Axios Generation Lab](https://www.axios.com/2023/09/05/ai-regulations-expert-survey)**: Ongeveer 1 op 5 voorspelde dat AI "zeker" onder menselijke controle zal blijven. De rest was verdeeld tussen degenen die zeiden dat AI "waarschijnlijk" of "zeker" uit de menselijke controle zal raken en degenen die zeiden "waarschijnlijk niet".
  Slechts 1 op 6 zei dat AI niet of niet kan worden gereguleerd. Slechts een handvol vertrouwt op de private sector om zichzelf te reguleren.
- **[Amerikaanse burgers, Sentience Institute](https://www.sentienceinstitute.org/aims-survey-supplement-2023)**: Er was brede steun voor stappen die kunnen worden genomen om de ontwikkeling te vertragen. Mensen steunden publieke campagnes om de ontwikkeling van AI te vertragen (71,3%), overheidsregulering die de ontwikkeling vertraagt (71,0%), en een pauze van zes maanden op sommige soorten AI-ontwikkelingen (69,1%). Steun voor een verbod op kunstmatige algemene intelligentie (AGI) die slimmer is dan mensen was 62,9%.
- **[Britse burgers, YouGov](https://inews.co.uk/news/politics/voters-deepfakes-ban-ai-intelligent-humans-2708693)**: 74% gelooft dat de regering moet voorkomen dat supermenselijke AI snel wordt gecreëerd. Meer dan 60% steunt een verdrag met een wereldwijd verbod op superintelligentie.
- **[Britse burgers, AISCC](https://aiscc.org/2023/11/01/yougov-poll-83-of-brits-demand-companies-prove-ai-systems-are-safe-before-release/)**: 83% van de mensen zei dat regeringen AI-bedrijven moeten verplichten om te bewijzen dat hun AI-modellen veilig zijn voordat ze worden vrijgegeven.
- **[NL, VS, VK burgers, Existential Risk Observatory](https://www.existentialriskobservatory.org/papers_and_reports/Trends%20in%20Public%20Attitude%20Towards%20Existential%20Risk%20And%20Artificial%20Intelligence.pdf)**: het publieke bewustzijn van existentiële risico's groeide in de VS van 7% tot 15%, en in Nederland en het VK 19%. Steun voor een door de regering opgelegde AI-pauze is gestegen in de VS van 56% tot 66%.

## [Tijdlijnen](/timelines) {#timelines}

- **[Metaculus Weak AGI](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/)** voor 2026: 25% kans, AGI in 2027: 50% kans (bijgewerkt op 2024-11-05).
- **[Metaculus full AGI](https://www.metaculus.com/questions/5121/date-of-artificial-general-intelligence/)** voor 2028: 25% kans, volledige AGI in 2032: 50% kans (bijgewerkt op 2024-11-05).
