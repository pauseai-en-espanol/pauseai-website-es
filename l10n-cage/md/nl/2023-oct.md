---
title: Internationale PauseAI-protest 21 oktober 2023
description: We organiseren een internationale protest om een pauze te eisen in de ontwikkeling van gevaarlijke AI.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

## 21 oktober (zaterdag), in meerdere landen {#october-21st-saturday-in-multiple-countries}

- VS, Californi√´, San Francisco ([Facebook](https://fb.me/1RbYq9H2hOFQ4yi))
- VS, Massachusetts, Boston ([Facebook](https://facebook.com/events/s/pauseai-protest-boston-make-th/6647554948613714/?mibextid=RQdjqZ))
- VK, Parliament Square, Londen ([Meld je aan](https://www.mixily.com/event/4774799330762010477), [Facebook](https://www.facebook.com/events/644748401084077))
- Nederland, Den Haag ([Meld je aan](https://www.mixily.com/event/8536294863402363208))
- Australi√´, Melbourne ([Meld je aan](https://www.mixily.com/event/8471341506387452508))
- Canada, Ottawa (Georganiseerd door Align the World, meld je aan op [Facebook](https://www.facebook.com/events/243643008241929/) of [Eventbrite](https://www.eventbrite.com/e/ai-safety-and-ethics-rally-tickets-725729686027))
- Denemarken, Kopenhagen ([Facebook](https://www.facebook.com/events/869443424535827))
- Jouw land hier? [Discussieer op Discord!](https://discord.gg/anXWYCCdH5)

## Waarom we protesteren {#why-we-protest-1}

Kunstmatige intelligentie (AI) wordt snel steeds krachtiger, veel sneller dan de meeste AI-wetenschappers hadden voorspeld.
Miljarden worden ge√Ønvesteerd in AI-capaciteiten, en de resultaten zijn verbluffend.
Nieuwe modellen presteren [beter dan mensen](/sota) in veel domeinen.
Naarmate de capaciteiten toenemen, nemen ook de [risico's](/risks) toe.
Wetenschappers waarschuwen zelfs dat AI [de mensheid zou kunnen vernietigen](/xrisk).
Deze sombere uitkomst lijkt niet alleen mogelijk, maar ook waarschijnlijk, aangezien de gemiddelde waarschijnlijkheidsschattingen voor deze uitkomsten [vari√´ren van 14% tot 40%](/polls-and-surveys).

We hebben onze leiders nodig om naar deze waarschuwingen te luisteren, maar ze nemen dit onderwerp niet serieus genoeg.
Er wordt AI-veiligheidswetgeving opgesteld, maar [geen enkele maatregel zou daadwerkelijk superintelligente AI voorkomen of vertragen](https://twitter.com/PauseAI/status/1704998018322141496).
[Meer dan 70%](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) van de mensen wil dat AI-vooruitgang wordt vertraagd, en [meer dan 60%](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) wil dat de overheid ingrijpt en superintelligente AI voorkomt.
Waarom is er geen wetsontwerp dat dit daadwerkelijk doet?
Het antwoord is lobbyen: onze politici ontmoeten voornamelijk AI-bedrijfsleiders, en zij zullen beleidsmaatregelen pushen die in hun belang zijn.

Op 1 en 2 november zal de allereerste AI Safety Summit in het VK plaatsvinden.
Deze top biedt een unieke kans om de eerste stappen te zetten naar internationale AI-veiligheidsregelgeving.

## Wat we vragen {#what-we-ask-1}

- **Beleidsmakers**: Laat bedrijven geen superintelligente AI ontwikkelen. Regulering en hardwarebeperkingen moeten van toepassing zijn voordat de training is begonnen, omdat het zeer moeilijk is om de verspreiding te controleren zodra een nieuwe capaciteit is bereikt. We kunnen niet toestaan dat bedrijven potentieel wereldvernietigende AI-modellen trainen. Het opstellen van wetgeving is moeilijk en kost tijd, maar we hebben misschien niet zoveel tijd, dus werk alsof je leven ervan afhangt. Want dat is zo.
- **Bedrijven**: Velen van jullie zijn bang voor wat AI kan doen, maar jullie zitten vast in een race. Wees dus openhartig over het steunen van een pauze in principe. Als jullie verklaringen ondertekenen dat deze technologie ons allemaal kan doden, laat de wereld dan zien dat jullie liever niet bouwen als het een haalbare optie was.
- **Topgasten**: Geef prioriteit aan veiligheid boven economische groei. We weten dat AI onze landen rijker kan maken, maar dat is niet waarom jullie hier zijn. Wees de volwassene in de kamer.

Voor ons volledige voorstel, zie [hier](/proposal).

## Persbericht {#press-release-5}

_ONMIDDELLIJK VERSPREIDEN_

### Internationale protest roept op tot een halt aan gevaarlijke AI-ontwikkeling {#international-protest-calls-for-a-halt-to-dangerous-ai-development}

**21 oktober:** [**PauseAI**](https://pauseai.info/) **houdt een internationale** [**protest**](https://pauseai.info/2023-oct) **om beleidsmakers en AI Safety Summit-deelnemers op te roepen om te werken aan een verbod op de creatie van superintelligente AI. De protest zal plaatsvinden in** [**8 landen**](https://pauseai.info/2023-oct) **tegelijkertijd en zal naar verwachting de grootste protest ooit zijn voor een AI-moratorium met een ruime marge.**

Locaties:

- VS, Californi√´, San Francisco
- VK, Parliament Square, Londen
- Nederland, Den Haag
- Isra√´l, Jeruzalem
- Australi√´, Melbourne
- Canada, Ottawa
- Duitsland, Berlijn
- Denemarken, Kopenhagen

In maart dit jaar ondertekenden veel vooraanstaande experts [een brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/#:~:text=We%20call%20on%20all%20AI,more%20powerful%20than%20GPT%2D4.&text=AI%20systems%20with%20human%2Dcompetitive,acknowledged%20by%20top%20AI%20labs.) waarin werd opgeroepen tot een pauze van zes maanden in de ontwikkeling van hun grensverleggende AI-modellen. In mei ondertekenden honderden AI-wetenschappers [een verklaring](https://www.safe.ai/statement-on-ai-risk) waarin stond ‚ÄúHet mitigeren van het risico van uitsterven door AI moet een wereldwijde prioriteit zijn, naast andere maatschappelijke risico's zoals pandemie√´n en nucleaire oorlog.‚Äù

Recente [peilingen](https://pauseai.info/polls-and-surveys) hebben aangetoond dat [meer dan 70%](https://www.vox.com/future-perfect/2023/8/18/23836362/ai-slow-down-poll-regulation) van de mensen wil dat AI-vooruitgang wordt vertraagd, en [meer dan 60%](https://www.vox.com/future-perfect/2023/9/19/23879648/americans-artificial-general-intelligence-ai-policy-poll) wil dat de overheid ingrijpt en superintelligente AI voorkomt. Tot nu toe zijn [geen ontwerpen](https://twitter.com/PauseAI/status/1706605169608159458) voorgesteld die dit zouden doen.

Over twee weken, op 1 en 2 november, zal de allereerste AI Safety Summit plaatsvinden in Bletchley Park, VK. De top zal worden bijgewoond door vooraanstaande AI-wetenschappers, beleidsmakers en industrieleiders. Dit is een unieke kans om de eerste stappen te zetten naar internationale AI-veiligheidsregelgeving. Echter, het VK is niet van plan om deze gelegenheid te gebruiken om sterke AI-regelgeving in te voeren. De organisator en de vertegenwoordiger van de premier voor de AI Safety Summit, Matt Clifford, heeft [verklaard](https://twitter.com/PauseAI/status/1709845853668553065) dat ‚ÄúHet pauzeren van AI-ontwikkeling nu te vroeg zou zijn‚Äù, en dat hij [niet verwacht](https://twitter.com/matthewclifford/status/1708819574739587356) ‚Äúharde controles‚Äù van de top.

‚ÄúWe zijn blij dat het VK de leiding neemt in AI-veiligheid en internationaal leiderschap toont‚Äù, zegt Joep Meindertsma, directeur van PauseAI. ‚ÄúMaar we zien niet het niveau van urgentie dat het verdient. In 2020 voorspelden voorspellers [de aankomst van menselijke AI](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) in 2055. Vandaag is de [gemiddelde voorspelling](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) 2026. We kunnen niet riskeren dat we de vooruitgang onderschatten. We hebben onze politici nodig om aan de veilige kant te blijven. Elk leven is in gevaar. Geen enkel bedrijf mag superintelligente AI bouwen.‚Äù

### Twitter {#twitter}

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Meer uit Londen na de eerste internationaal geco√∂rdineerde <a href="https://twitter.com/PauseAI?ref_src=twsrc%5Etfw">@PauseAI</a> protest! Op zaterdag kwamen demonstranten samen in zeven steden om een verbod te eisen op de creatie van kunstmatige superintelligentie, een week voor <a href="https://twitter.com/RishiSunak?ref_src=twsrc%5Etfw">@RishiSunak</a>&#39;s AI Safety Summit. Lees verder ‚¨áÔ∏è <a href="https://t.co/W2vYv4nVIl">pic.twitter.com/W2vYv4nVIl</a></p>&mdash; Alistair Stewart V ‚è∏Ô∏è (@alistair___s) <a href="https://twitter.com/alistair___s/status/1716566914242121768?ref_src=twsrc%5Etfw">23 oktober 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>

<WidgetConsent>
<div><blockquote class="twitter-tweet"><p lang="en" dir="ltr">De PauseAI SF-protest was een groot succes. Dit was de grootste AI Safety-protest ooit in de Verenigde Staten, en het was onderdeel van de eerste en grootste wereldwijde AI Safety-protest in de geschiedenis! <br><br>Bedankt aan iedereen die het mogelijk heeft gemaakt ü©∑ <a href="https://t.co/Yttdpgnrfa">pic.twitter.com/Yttdpgnrfa</a></p>&mdash; Holly ‚è∏Ô∏è Elmore (@ilex_ulmus) <a href="https://twitter.com/ilex_ulmus/status/1715954127954751932?ref_src=twsrc%5Etfw">22 oktober 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</WidgetConsent>
