---
title: De moeilijke psychologie van existentiële risico's
description: Nadenken over het einde van de wereld is moeilijk.
---

De meeste mensen reageren aanvankelijk op het onderwerp van AI-existentiële risico's met een mengeling van spot, ontkenning en ongeloof.
De angst komt vaak pas na lang nadenken over het onderwerp.

De psychologie van existentiële risico's is een onderwerp dat niet vaak wordt besproken, in vergelijking met de technische aspecten van AI-veiligheid.
Echter, men zou kunnen argumenteren dat het misschien net zo belangrijk is.
Per slot van rekening, als we mensen niet serieus kunnen nemen en hen niet kunnen overtuigen om actie te ondernemen, zullen we niets kunnen doen om het probleem aan te pakken.

Het is moeilijk om het onderwerp ter sprake te brengen, moeilijk om te geloven, moeilijk om te begrijpen en moeilijk om actie te ondernemen.
Een beter begrip van waarom deze dingen zo moeilijk zijn, kan ons helpen om meer overtuigend, effectief en empathisch te zijn.

## Moeilijk om ter sprake te brengen {#difficult-to-bring-up}

X-risico is een moeilijk onderwerp om ter sprake te brengen in een gesprek, vooral als je een politicus bent.
Mensen kunnen denken dat je gek bent, en je kunt je niet comfortabel voelen om over dit technisch complexe onderwerp te praten.

### Angst om belachelijk gemaakt te worden {#fear-of-being-ridiculed}

De eerste reactie op existentiële risico's is vaak om het af te doen met een lach.
We hebben dit ook zien gebeuren op camera in het Witte Huis, de eerste keer dat x-risico ter sprake werd gebracht.
Dit maakt het op zijn beurt moeilijker om het onderwerp opnieuw ter sprake te brengen, omdat anderen bang zijn om belachelijk gemaakt te worden.

Professionals kunnen vrezen dat hun reputatie wordt beschadigd als ze hun bezorgdheid uiten.

> "Het was bijna gevaarlijk vanuit een carrièreperspectief om toe te geven dat je je zorgen maakte," - [Jeff Clune zei](https://www.theglobeandmail.com/business/article-i-hope-im-wrong-why-some-experts-see-doom-in-ai/)

Het voorstellen van verstandige beleidsmaatregelen (zoals pauzeren) kan worden beschouwd als "extremistisch" of "alarmistisch", wat beide je geloofwaardigheid of reputatie kan schaden.

### Angst om racistisch/cultistisch/complottheoretisch genoemd te worden {#fear-of-being-called-racistcultistconspiracy-theorist}

In de afgelopen maanden zijn verschillende complottheorieën ontstaan.
Sommige individuen hebben verklaard dat [alle AI-veiligheidsexperts racistisch zijn](https://medium.com/%2540emilymenonbender/talking-about-a-schism-is-ahistorical-3c454a77220f) en dat [AI-veiligheid een cult is](https://www.cnbc.com/2023/06/06/ai-doomers-are-a-cult-heres-the-real-threat-says-marc-andreessen.html).
Sommigen hebben verklaard dat AI-'doomers' deel uitmaken van een [complot van big tech om AI te "hypen"](https://www.latimes.com/business/technology/story/2023-03-31/column-afraid-of-ai-the-startups-selling-it-want-you-to-be).
Deze belachelijke beschuldigingen kunnen bezorgde mensen ervan weerhouden om hun bezorgdheid te uiten.

Echter, voordat je boos wordt op de mensen die deze beschuldigingen maken, houd in gedachten dat ze het resultaat kunnen zijn van angst en ontkenning (zie hieronder).
Het erkennen van de gevaren van AI is eng, en het kan gemakkelijker zijn om de boodschapper af te wijzen dan om de boodschap te internaliseren.

### Een complex onderwerp om over te discussiëren {#a-complex-topic-to-argue-about}

Mensen praten graag over dingen waar ze verstand van hebben.
De technische moeilijkheid van AI-veiligheid maakt het een ontmoedigend onderwerp voor de meeste mensen.
Het kost tijd en moeite om de argumenten te begrijpen.
Als politicus wil je niet betrapt worden op het zeggen van iets dat verkeerd is, dus je kunt het onderwerp helemaal vermijden.

## Moeilijk om te geloven {#difficult-to-believe}

Zelfs als er een discussie is over existentiële risico's, is het moeilijk om mensen te overtuigen dat het een reëel probleem is.
Er zijn verschillende redenen waarom de meeste mensen het idee direct afwijzen.

### Normaliteitbias {#normalcy-bias}

We kennen allemaal de beelden van rampen in films, toch?
Mensen schreeuwen en rennen in paniek.
Blijkt dat het tegenovergestelde vaak waar is: ongeveer 80% van de mensen vertoont symptomen van [_normaliteitbias_](https://nl.wikipedia.org/wiki/Normaliteitbias) tijdens rampen: geen onderdak zoeken tijdens een tornado, waarschuwingen van de overheid negeren, blijven handen schudden in de vroege dagen van COVID.
De normaliteitbias beschrijft onze neiging om de mogelijkheid van een ramp te onderschatten en te geloven dat het leven normaal zal blijven, zelfs in het gezicht van significante bedreigingen of crises.
Dit gebeurt [momenteel met AI](https://lethalintelligence.ai/post/category/warning-signs/).

> Mensen dralen, vragen om meningen, omdat ze _willen_ dat alles in orde is. Ze zullen blijven vragen en uitstellen totdat ze het antwoord krijgen dat ze willen.

> Tijdens 9/11, bijvoorbeeld, was de gemiddelde wachttijd onder overlevenden om de torens te evacueren 6 minuten, waarbij sommigen tot een half uur wachtten om te vertrekken. Ongeveer 1000 mensen namen zelfs de tijd om hun computers uit te schakelen en andere kantooractiviteiten af te ronden, een strategie om normale activiteiten voort te zetten tijdens een onbekende situatie.

_Uit ["De bevroren kalmte van normaliteitbias"](https://gizmodo.com/the-frozen-calm-of-normality-bias-486764924)_

Een ander voorbeeld hiervan is de ramp met de Challenger-ruimteveer in 1986.
Roger Boisjoly was een ingenieur die voorspelde dat het zou exploderen, maar niemand van zijn managers wilde geloven dat het mogelijk was:

> We wisten allemaal dat als de afdichtingen faalden, de shuttle zou exploderen.
> Ik vocht als de hel om die lancering te stoppen. Ik ben zo verscheurd van binnen dat ik er nauwelijks over kan praten, zelfs nu.
> We praatten met de juiste mensen, we praatten met de mensen die de macht hadden om die lancering te stoppen.

_Uit ["Herinneringen aan Roger Boisjoly"](https://www.npr.org/sections/thetwo-way/2012/02/06/146490064/remembering-roger-boisjoly-he-tried-to-stop-shuttle-challenger-launch)_

Een verklaring voor waarom onze hersenen weigeren te geloven dat gevaar ons kan overkomen, is cognitieve dissonantie.

### Cognitieve dissonantie {#cognitive-dissonance}

Wanneer we worden geconfronteerd met nieuwe informatie, zal ons brein proberen om het te laten passen in wat we al weten.
Ideëen die al overeenkomen met bestaande overtuigingen worden gemakkelijk toegevoegd aan ons wereldbeeld.
Ideëen die te verschillend zijn van wat we al geloven, zullen _cognitieve dissonantie_ veroorzaken - we zullen ons oncomfortabel voelen en proberen de ideëen af te wijzen of alternatieve verklaringen te vinden voor wat we horen.

Veel overtuigingen die de meeste mensen hebben, zullen worden uitgedaagd door het idee van existentiële risico's:

- Technologie is er om ons te dienen en kan gemakkelijk worden gecontroleerd
- Er zijn slimme mensen aan de leiding die ervoor zullen zorgen dat alles in orde komt
- Ik zal waarschijnlijk oud worden, en mijn kinderen ook

Veel van deze gedachten zullen worden uitgedaagd door het idee dat AI een existentiële bedreiging vormt.
Onze hersenen zullen naar alternatieve verklaringen zoeken voor waarom wetenschappers [waarschuwen over dit onderwerp](/quotes):

- Ze worden betaald door big tech
- Ze zijn onderdeel van een of andere samenzwering of cult
- Ze willen alleen maar aandacht of macht

Het internaliseren van het feit dat _wetenschappers ons waarschuwen omdat ze geloven dat we in gevaar zijn_ , komt in conflict met onze bestaande overtuigingen, het veroorzaakt te veel cognitieve dissonantie.

### Het einde van de wereld is nooit gebeurd {#the-end-of-the-world-has-never-happened}

Zien is geloven (zie: [_Beschikbaarheidsheuristiek_](https://nl.wikipedia.org/wiki/Beschikbaarheidsheuristiek)).
Dat is een probleem voor uitroeiingsrisico's omdat we het nooit zullen kunnen zien voordat het te laat is.

Aan de andere kant hebben we veel bewijs voor het tegendeel.
Het einde der tijden is voorspeld door veel mensen, en elke keer is het onjuist gebleken.

Dus wanneer mensen horen over existentiële risico's, zullen ze denken dat het gewoon weer een van die doemdagvoorspellingen is.
Probeer begrip te hebben voor dit standpunt, en wees niet te hard voor mensen die zo denken.
Ze hebben waarschijnlijk niet dezelfde informatie gekregen als jij.

### We willen graag denken dat we speciaal zijn {#we-like-to-think-that-we-are-special}

Zowel op collectief als op individueel niveau willen we graag geloven dat we speciaal zijn.

Op collectief niveau willen we graag denken dat mensen heel anders zijn dan dieren - Darwins idee dat we evolueerden uit apen was bijna ondenkbaar voor de meesten.
De meeste religies hebben verhalen over de hemel of reïncarnatie, waarin mensen (of tenminste de gelovigen) op de een of andere manier voor altijd zullen leven.
Het idee dat de mensheid op een dag kan ophouden te bestaan, is heel verontrustend en moeilijk te internaliseren.
We willen graag geloven dat we _plot armor_ hebben - dat we de hoofdpersonages zijn in een verhaal, en dat het verhaal een gelukkig einde zal hebben.
Mensen kunnen het rationeel overwegen, maar ze zullen het niet _voelen_.
Een video van Robert Miles met de titel ["Er is geen regel die zegt dat we het zullen redden"](https://www.youtube.com/watch?v=JD_iA7imAPs) legt dit heel goed uit.

Op individueel niveau zijn we trots op de unieke intellectuele vermogens die we hebben.
Veel mensen wilden nooit geloven dat een AI op een dag in staat zou zijn om kunst te creëren, boeken te schrijven of zelfs ons te verslaan in schaken.
De gedachte dat onze eigen intelligentie slechts een product is van evolutie en dat het kan worden gerepliceerd door een machine, is iets dat veel mensen moeilijk kunnen accepteren.
Dit maakt het moeilijk om te accepteren dat een AI intelligenter kan zijn dan wij.

### Fictie heeft ons geleerd om een gelukkig einde te verwachten {#fiction-has-conditioned-us-to-expect-a-happy-ending}

Het meeste van wat we weten over existentiële risico's komt uit fictie.
Dit helpt waarschijnlijk niet, omdat fictieve verhalen niet worden geschreven om realistisch te zijn: ze worden geschreven om entertainend te zijn.

In fictie is er vaak een held, conflict, hoop en uiteindelijk een gelukkig einde.
We zijn geconditioneerd om een strijd te verwachten waarin we kunnen vechten en winnen.
In sciencefiction worden AI's vaak heel antropomorf afgebeeld - als slecht, als menselijk willen zijn, als hun doelen veranderen.
Al deze dingen komen niet overeen met waar AI-veiligheidsexperts zich zorgen over maken.

En in de meeste verhalen wint de held.
De AI maakt een domme fout en de held vindt een manier om de zaak die veel slimmer is dan hij, te slim af te zijn.
De held wordt beschermd door plot armor.
In meer realistische AI-doomscenario's is er geen held, geen plot armor, geen strijd, geen mensen die een superintelligentie slim af zijn, en geen gelukkig einde.

### Vooruitgang is altijd (meestal) goed geweest {#progress-has-always-been-mostly-good}

Veel van de technologieën die in onze samenleving zijn geïntroduceerd, zijn overwegend gunstig geweest voor de mensheid.
We hebben ziektes genezen, onze levensverwachting verhoogd en ons leven comfortabeler gemaakt.
En elke keer dat we dit hebben gedaan, waren er mensen die zich tegen deze innovaties verzetten en waarschuwden voor de gevaren.
De Luddieten vernietigden de machines die hun banen afnamen, en mensen waren bang voor de eerste treinen en auto's.
Deze mensen hebben altijd ongelijk gehad.

### We willen niet denken aan onze dood {#we-dont-like-to-think-about-our-death}

De menselijke geest houdt er niet van om slecht nieuws te ontvangen, en heeft verschillende copingmechanismen om ermee om te gaan.
De belangrijkste hiervan zijn [ontkenning](https://nl.wikipedia.org/wiki/Cognitieve_dissonantie) en [compartimentering](<https://nl.wikipedia.org/wiki/Compartimentering_(psychologie)>).
Wanneer het gaat om onze eigen dood, zijn we heel vatbaar voor ontkenning.
Er zijn boeken geschreven over de [ontkenning van de dood](https://nl.wikipedia.org/wiki/The_Denial_of_Death).

Deze copingmechanismen beschermen ons tegen de pijn van het accepteren dat de wereld niet is zoals we dachten dat hij was.
Echter, ze kunnen ons ook weerhouden van adequaat reageren op een bedreiging.

Wanneer je merkt dat iemand deze copingmechanismen gebruikt, probeer dan empathisch te zijn.
Ze doen het niet expres, en ze zijn niet dom.
Het is een natuurlijke reactie op slecht nieuws, en we doen het allemaal tot op zekere hoogte.

### Het erkennen dat je werk gevaarlijk is, is moeilijk {#admitting-your-work-is-dangerous-is-hard}

Voor degenen die aan AI-capaciteiten hebben gewerkt, is het erkennen van de gevaren nog moeilijker.

Neem Yoshua Bengio als voorbeeld.
Yoshua Bengio heeft een briljante geest en is een van de pioniers op het gebied van AI.
AI-veiligheidsexperts waarschuwen al jaren voor de potentiële gevaren van AI, maar het duurde nog steeds lang voordat hij hun waarschuwingen serieus nam.
In een [interview](https://youtu.be/0RknkWgd6Ck?t%25253D949) gaf hij de volgende verklaring:

> "Waarom dacht ik er niet eerder aan? Waarom dacht Geoffrey Hinton er niet eerder aan? [...] Ik geloof dat er een psychologisch effect is dat nog steeds een rol kan spelen voor veel mensen. [...] Het is heel moeilijk, in termen van je ego en je goed voelen over wat je doet, om te accepteren dat het ding waar je decennialang aan hebt gewerkt, heel gevaarlijk kan zijn voor de mensheid. [...] Ik denk dat ik er niet te veel over wilde nadenken, en dat is waarschijnlijk het geval voor anderen."

Het zou niemand moeten verbazen dat sommige van de felste AI-risico-ontkenners AI-onderzoekers zelf zijn.

### Gemakkelijk af te doen als complot of cult {#easy-to-dismiss-as-conspiracy-or-cult}

In het afgelopen jaar werd het merendeel van de bevolking geïntroduceerd in het concept van existentiële risico's van AI.
Wanneer mensen hierover horen, zullen ze naar een verklaring zoeken.
De juiste verklaring is dat AI in feite gevaarlijk is, maar dit geloven is moeilijk en eng: het zal veel cognitieve wrijving veroorzaken.
Dus mensen zullen bijna direct naar een andere manier zoeken om hun observaties te verklaren.
Er zijn twee alternatieve verklaringen die veel gemakkelijker te geloven zijn:

1. **Het is allemaal een groot complot**. AI-bedrijven hypen AI op om meer financiering te krijgen, en AI-veiligheidsexperts zijn onderdeel van deze hype-machine. Deze narratief past bij verschillende observaties: bedrijven liegen vaak, veel AI-veiligheidsexperts worden betaald door AI-bedrijven, en er zijn een aantal miljardairs die AI-veiligheidsonderzoek financieren. Echter, we kunnen ook aanwijzen waarom dit complotverhaal gewoon niet waar is. Veel van de "alarmisten" zijn wetenschappers die niets te winnen hebben. De bedrijven kunnen op een bepaalde manier profiteren, maar tot voor kort (mei 2023) hebben ze bijna volledig gezwegen over AI-risico's. Dit is logisch, aangezien bedrijven meestal niet profiteren van mensen die bang zijn voor hun product of dienst. We hebben buiten Microsoft en OpenAI geprotesteerd, deels _omdat_ we wilden dat ze de risico's erkenden.
2. **Het is een cult**. De groep die in AI-veiligheid gelooft, is gewoon een stelletje gekke religieuze extremisten die in het einde van de wereld geloven. Dit lijkt ook te passen, aangezien mensen in de AI-veiligheidsgemeenschap vaak heel gepassioneerd zijn over het onderwerp en allerlei ingroepjargon gebruiken. Echter, het valt uit elkaar wanneer je erop wijst dat de mensen die waarschuwen voor AI-risico's geen enkele organisatie zijn. Het is een grote, diverse groep mensen, er is geen enkele leider, er zijn geen rituelen, en er is geen dogma.

Wat deze verklaringen zo overtuigend maakt, is niet alleen dat ze gemakkelijk te begrijpen zijn, of dat ze alle observaties perfect verklaren - de primaire reden is dat ze geruststellend zijn.
Geloven dat mensen waarschuwen over AI _omdat er een reële bedreiging is_ , is eng en moeilijk te accepteren.

## Moeilijk te begrijpen {#difficult-to-understand}

De argumenten voor AI-existentiële risico's zijn vaak heel technisch, en we zijn heel vatbaar voor het antropomorfiseren van AI-systemen.

### AI-alignering is verrassend moeilijk {#ai-alignment-is-surprisingly-hard}

Mensen kunnen intuïtief het gevoel hebben dat ze het AI-aligneringsprobleem kunnen oplossen.
Waarom geen [stopknop](https://www.youtube.com/watch?v=3TYT1QfdfsM&list=PLfHsskCxi_g-c62a_dmsNuHynaXsRQm40&index=10) toevoegen? Waarom geen [AI opvoeden als een kind](https://www.youtube.com/watch?v=eaYIU6YXr3w)? Waarom geen [drie wetten van Asimov](https://www.youtube.com/watch?v=7PKx3kS7f4A)?
In tegenstelling tot de meeste soorten technische problemen, zullen mensen een mening hebben over hoe ze het AI-aligneringsprobleem kunnen oplossen en de moeilijkheid ervan onderschatten.
Het begrijpen van de daadwerkelijke moeilijkheid ervan kost veel tijd en moeite.

### We antropomorfiseren {#we-anthropomorphize}

We zien gezichten in wolken, en we zien menselijke kwaliteiten in AI-systemen.
Miljoenen jaren evolutie hebben ons tot zeer sociale wezens gemaakt, maar deze instincten zijn niet altijd nuttig.
We hebben de neiging om AI's te zien als menselijke doelen en motivaties, in staat om emoties te voelen en een gevoel van moraal te hebben.
We verwachten dat een zeer intelligente AI ook heel wijs en vriendelijk zal zijn.
Dit is een van de redenen waarom mensen intuïtief denken dat AI-alignering gemakkelijk is, en waarom de [orthogonaliteitsthesis](https://www.youtube.com/watch?v=hEUO6pjwFOo) zo tegenintuïtief kan zijn.

### AI-veiligheid gebruikt complexe taal {#ai-safety-uses-complex-language}

Het AI-veiligheidsveld bestaat voornamelijk uit een kleine groep (slimme) mensen die hun eigen jargon hebben ontwikkeld.
Het lezen van LessWrong-berichten kan voelen als het lezen van een vreemde taal.
Veel berichten gaan ervan uit dat de lezer al bekend is met wiskundige concepten, verschillende technische concepten en het jargon van het veld.

## Moeilijk om actie te ondernemen {#difficult-to-act-on}

Zelfs als mensen de argumenten begrijpen, is het nog steeds moeilijk om actie te ondernemen.
De impact is te groot, we hebben copingmechanismen die de risico's bagatelliseren, en als we de ernst van de situatie voelen, kunnen we ons machteloos voelen.

### Gebrek aan aangeboren angstreactie {#lack-of-innate-fear-response}

Onze hersenen zijn geëvolueerd om dingen te vrezen die gevaarlijk zijn.
We zijn instinctief bang voor hoogtes, grote dieren met scherpe tanden, plotselinge harde geluiden en dingen die in een S-vorm bewegen.
Een superintelligente AI activeert geen van onze primaire angsten.
Bovendien hebben we een sterke angst voor sociale afwijzing of verlies van sociale status, wat betekent dat mensen bang zijn om over AI-risico's te spreken.

### Scope-insensitiviteit {#scope-insensitivity}

> "Een enkele dood is een tragedie; een miljoen doden is een statistiek." - Jozef Stalin

Scope-insensitiviteit is de menselijke neiging om de impact van grote aantallen te onderschatten.
We geven niet 10 keer zoveel om 1000 mensen die doodgaan als om 100 mensen die doodgaan.
Existentiële risico's betekenen de dood van alle 8 miljard mensen op aarde (niet tellend hun nakomelingen).

Zelfs als er een kans van 1% is dat dit gebeurt, is het nog steeds een heel groot probleem.
Rationeel gezien zouden we deze kans van 1% op 8 miljard doden net zo belangrijk moeten vinden als de zekere dood van 80 miljoen mensen.

Als iemand denkt dat het einde van de wereld niet zo'n groot probleem is (je zou verbaasd zijn over hoe vaak dit gebeurt), kun je proberen om dingen persoonlijker te maken.
De mensheid is niet zomaar een abstract concept, het zijn je vrienden, je familie en jezelf.
Alle mensen om wie je geeft, zullen doodgaan.

### Ons gedrag wordt gevormd door onze omgeving en primitieve geesten {#our-behavior-is-shaped-by-our-environment-and-primitive-minds}

Onze acties worden geconditioneerd door wat als normaal, goed en redelijk wordt gezien.
Hoeveel we ook willen handelen in een situatie die om actie vraagt, als die acties ongewoon zijn, vrezen we vaak bewust of onbewust dat we door de maatschappij worden uitgesloten. En wat normaal is, wordt in onze geest gepusht door ons te omringen met dingen in onze naaste sociale kringen en online feeds.
Mensen die gewoon dingen doen en praten over dingen die niets te maken hebben met waar we ons eigenlijk zorgen over maken, zullen wat we in ons hoofd hebben overschrijven en ons motiveren om andere dingen te doen in ons dagelijks leven.

Uitroeiingsrisico's verdienen veel meer van onze tijd, energie en aandacht. Onze reacties op hen zouden meer moeten zijn als levens-of-doodsituaties die ons vullen met adrenaline. Maar vanwege de abstracte aard van de problemen en onze slecht aangepaste geesten, gaan de meeste mensen die over hen leren gewoon door met hun dag alsof ze niets hebben geleerd.

### Copingmechanismen (die actie voorkomen) {#coping-mechanisms-preventing-action}

Dezelfde copingmechanismen die mensen ervan weerhouden om _te geloven_ in existentiële risico's, voorkomen ook dat ze _actie ondernemen_.
Als je in ontkenning bent of compartimenteert, zul je je niet geroepen voelen om iets te doen.

### Stress en angst {#stress-and-anxiety}

Terwijl ik dit schrijf, voel ik me gestrest en angstig.
Het is niet alleen omdat ik bang ben voor het einde van de wereld, maar ook omdat ik het gevoel heb dat ik er iets aan moet doen.
Er is veel druk om te handelen, en het kan overweldigend zijn.
Deze stress kan een goede motivator zijn, maar het kan ook verlammend zijn.

### Wanhoop en machteloosheid {#hopelessness-and-powerlessness}

Wanneer mensen het onderwerp serieus nemen en de volle omvang van de situatie tot hen doordringt, kunnen ze het gevoel hebben dat alle hoop verloren is.
Het kan voelen als een kankerdiagnose: je gaat eerder dood dan je wilde, en er is niets wat je eraan kunt doen.
Het probleem is te groot om aan te pakken, en je bent te klein.
De meeste mensen zijn geen AI-veiligheidsexperts of ervaren lobbyisten, dus hoe kunnen ze in hemelsnaam iets doen?

## Maar je kunt helpen! {#but-you-can-help}

Er zijn veel [dingen die je kunt doen](/action).
Een brief schrijven, naar een protest gaan, wat geld doneren of lid worden van een gemeenschap is niet zo moeilijk!
En deze acties hebben een echte impact.
Zelfs als we worden geconfronteerd met het einde van de wereld, kan er nog steeds hoop en zeer lonend werk zijn.
[Word lid van PauseAI](/join) en word onderdeel van onze beweging.
