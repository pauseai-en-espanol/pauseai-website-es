---
title: PauseAI in Australië
slug: australia
description: de Australische afdeling van PauseAI
---

**Een boodschap van PauseAI-vrijwilligers in Australië:**

Tegen 2030 kan kunstmatige intelligentie volledig geautomatiseerd, zelfverbeterend en **slimmer dan mensen in bijna alle opzichten** zijn. Dit is geen sciencefiction - het is de inschatting van toonaangevende AI-bedrijven en onderzoekers. Wanneer dit gebeurt, zal elk aspect van het leven voorgoed veranderen.

**[Word lid van onze gemeenschap](/join)** | [E-mail ons](mailto:australia@pauseai.info) | [Verbind op Facebook](https://www.facebook.com/groups/571590459293618) | [YouTube-kanaal](https://www.youtube.com/channel/UCjjMieiOlSFf7jud0yhHQSg) | [Evenementen](https://lu.ma/PauseAIAustralia)

### Welke risico's lopen we? {#what-risks-are-we-facing}

Kunstmatige intelligentie ontwikkelt zich [in een razend tempo](/urgency). Sommige experts, zoals [Sam Altman](https://time.com/7205596/sam-altman-superintelligence-agi/), [Dario Amodei](https://arstechnica.com/ai/2025/01/anthropic-chief-says-ai-could-surpass-almost-all-humans-at-almost-everything-shortly-after-2027/) en [Geoffrey Hinton](https://en.wikipedia.org/wiki/Artificial_general_intelligence), waarschuwen dat **AI de menselijke intelligentie binnen vijf jaar kan overtreffen**. Zonder internationale samenwerking kan dit leiden tot economische chaos, oorlog en zelfs [menselijke uitsterving](/xrisk).

> "Naarmate algemene AI-capaciteiten toenemen, komen er geleidelijk aanwijzingen voor extra risico's naar voren. Deze omvatten risico's zoals grootschalige arbeidsmarktimpact, AI-gefaciliteerde hacking of biologische aanvallen, en de maatschappij die de controle over algemene AI verliest."
>
> – [Internationaal AI-veiligheidsrapport (2025)](https://assets.publishing.service.gov.uk/media/679a0c48a77d250007d313ee/International_AI_Safety_Report_2025_accessible_f.pdf), mede geschreven door 96 experts uit 30 landen, waaronder Australië.

### Willen we niet de voordelen van AI? {#dont-we-want-ais-benefits}

Jawel, natuurlijk willen we die. Kunstmatige intelligentie heeft al het potentieel om een krachtig hulpmiddel te zijn. Als AI onder controle blijft, kan het worden gebruikt om ziekten te genezen, wetenschappelijke doorbraken te stimuleren en kansen en welzijn te verspreiden. Maar het zou tragisch zijn om deze vooruitgang te bereiken en vervolgens [de controle te verliezen](/ai-takeover) en catastrofale verliezen te lijden.

Nieuwe technologieën hebben altijd veranderingen met zich meegebracht, maar mensen hebben tijd nodig om zich aan te passen, veiligheidsmaatregelen te treffen en voor de toekomst te plannen. Voor elke andere technologie - of het nu vliegtuigen, wolkenkrabbers of nieuwe medicijnen zijn - eisen we deskundig ontworpen veiligheidsmaatregelen voordat we het publiek aan risico's blootstellen. Dit gebeurt niet met AI.

AI-bedrijven zijn in een race verwikkeld, gestimuleerd door miljarden dollars aan investeringen, om als eerste supermenselijke AI te ontwikkelen. Wanneer één bedrijf succes heeft, zal uw leven en dat van uw dierbaren radicaal veranderen, en u zult geen enkele zeggenschap hebben over wat deze toekomst inhoudt. Dit is niet alleen een technisch probleem - het zal iedereen treffen.

### Wat kan worden gedaan? {#what-can-be-done}

PauseAI [stelt voor](/proposal) een internationaal verdrag om de ontwikkeling van slimmere-dan-menselijke algemene AI te pauzeren totdat er een geloofwaardig plan is om ervoor te zorgen dat het veilig is. Het is in het belang van Australië om hiervoor te pleiten.

> "Wie zal leiderschap tonen bij de onderhandelingen over een AI-niet-verspreidingsverdrag? Het is een collectieve verantwoordelijkheid en zeker een waarbij Australië een bijdrage kan leveren."
>
> – Alan Finkel, Chief Scientist van Australië (2016-2020)
>
> [Sydney Morning Herald](https://www.smh.com.au/technology/the-ai-horse-has-bolted-it-s-time-for-the-nuclear-option-20230807-p5duel.html)

De geschiedenis laat zien dat kleinere landen een groot verschil kunnen maken bij het oplossen van mondiale problemen. Neem de ban op walvisjacht in 1982 en het akkoord van 1987 om de ozonlaag te beschermen. Australië, dat vroeger zelf walvissen jaagde, werd een leider in de bescherming van het zeeleven door de ban te steunen en zelfs Japan voor de rechter te dagen vanwege zijn walvisjacht. Australië hielp ook de ozonlaag te beschermen door zich snel aan te sluiten bij het akkoord om het gebruik van chemicaliën die de ozonlaag beschadigen, te stoppen. Deze verhalen laten zien dat landen als Australië echte veranderingen kunnen bewerkstelligen door actie te ondernemen en samen te werken met andere naties.

### Zijn er geen belangrijkere kwesties? {#arent-there-more-important-issues}

We zijn het erover eens dat er veel belangrijke kwesties zijn die Australië onder ogen moet zien, maar we zullen ze niet kunnen oplossen in een wereld met ongecontroleerde AI. Australië moet tegelijkertijd pleiten voor een internationaal verdrag en werken aan andere kwesties.

### Waarom wordt er nog niets gedaan? {#why-isnt-anything-being-done-already}

Australische politici hebben naar sommige van de kleinere risico's van AI gekeken, maar niet naar de grote. Sinds de laatste verkiezingen [hebben de grote partijen geen duidelijk plan](https://www.australiansforaisafety.com.au/scorecard).

We erkennen dat niet iedereen het eens is over het risico van een AI-catastrofe. We behandelen enkele van de gebruikelijke bezwaren [hier](/faq). We beweren niet 100% zeker te zijn, maar we denken dat de waarschijnlijkheid van zeer slechte uitkomsten hoog genoeg is om een pauze te rechtvaardigen.

Het is [psychologisch lastig](/psychology-of-x-risk) om na te denken over potentiële catastrofes. Veel mensen gaan ervan uit dat de risico's buiten hun controle liggen en daarom niet de moeite waard zijn om zich zorgen over te maken. Toch kan iedereen nu actie ondernemen door zijn stem te laten horen. We denken dat het beter is om te handelen dan om ons alleen maar zorgen te maken.

### Hoe kan ik helpen in Australië? {#how-can-i-help-in-australia}

U kunt een verschil maken. Vrijwilligers in Australië vergroten het bewustzijn, protesteren, lobbyen en steunen de wereldwijde PauseAI-beweging.

- [Word lid van onze gemeenschap](/join)
- [Bezoek onze volgende Australische online- of fysieke bijeenkomst](https://lu.ma/PauseAIAustralia)
- Teken de open brief van Australians for AI Safety [open brief](https://www.australiansforaisafety.com.au/letters)
- [Neem contact op met politici](/writing-a-letter)
- Praat met uw vrienden en familie over het risico van AI
