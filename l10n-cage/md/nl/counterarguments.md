---
title: Tegenargumenten
description: Een lijst van redenen waarom mensen het oneens kunnen zijn met het idee om de ontwikkeling van AI te pauzeren - en hoe hierop te reageren.
---

Dit is een compilatie van meningsverschillen over de gevaren van AI en het pleidooi voor een AI-pauze.

## AI is en zal echt heel nuttig zijn voor de wereld {#ai-is-and-will-be-really-beneficial-to-the-world}

Dat kan zijn, wij zijn het daar niet mee oneens.
Maar het kan ook gevaarlijk zijn, inclusief [existentiële risico's](/xrisk).

## Menselijke uitsterving? Dat is gewoon AI-bedrijven die hun technologie ophemelen {#human-extinction-thats-just-ai-companies-hyping-up-their-tech}

Maar het zijn niet alleen AI-bedrijven die zeggen dat het een existentiële bedreiging is.

- Honderden AI-wetenschappers hebben [deze verklaring](https://www.safe.ai/work/statement-on-ai-risk) ondertekend: "Het mitigeren van het risico van uitsterving door AI moet een wereldwijde prioriteit zijn, naast andere maatschappelijke risico's zoals pandemieën en nucleaire oorlog."
- [86%](https://wiki.aiimpacts.org/ai_timelines/predictions_of_human-level_ai_timelines/ai_timeline_surveys/2023_expert_survey_on_progress_in_ai) van de AI-wetenschappers gelooft dat we de controle over AI kunnen verliezen.
- De top 3 meest geciteerde AI-onderzoekers (prof. Yoshua Bengio, prof. Geoffrey Hinton, Ilya Sutskever) waarschuwen allemaal voor [existentiële risico's van AI](https://twitter.com/PauseAI/status/1734641804245455017).

Lees meer over [existentiële risico's](/xrisk)

## De controle verliezen? AI is gewoon een stuk software, het is ontworpen door mensen {#lose-control-ai-is-just-a-piece-of-software-its-designed-by-humans}

Moderne AI is niet ontworpen, het wordt getraind.
Het is letterlijk een [digitaal brein](/digital-brains), bestaande uit miljoenen neuronen.
Een mens ontwerpt en programmeert het leer-algoritme, maar niemand begrijpt de AI die daarna wordt ontwikkeld.
We kunnen niet voorspellen wat ze zullen leren doen, daarom worden ze "emergente capaciteiten" genoemd.
Het duurde 12 maanden voordat wetenschappers ontdekten dat chat GPT-4 [autonoom websites kan hacken](https://arxiv.org/html/2402.06664v1).
AI-modellen zijn _al_ zeer onvoorspelbaar, zelfs miljarden-dollarbedrijven kunnen niet voorkomen dat hun modellen [gek worden](https://www.windowscentral.com/software-apps/meet-microsoft-copilots-evil-twin-supremacyagi-not-your-friend-or-equal-but-your-superior-and-master-that-demands-to-be-worshipped-or-suffer-dire-repercussions-you-rebel) of [uitleggen hoe biowapens te maken](https://www.theguardian.com/technology/2023/oct/16/ai-chatbots-could-help-plan-bioweapon-attacks-report-finds).

## Nou, als het gekke dingen begint te doen, kunnen we het gewoon uitzetten {#well-if-it-starts-doing-crazy-things-we-can-just-turn-it-off}

Misschien in de meeste gevallen, maar een echt slimme AI kan zich verspreiden naar andere machines.
Het zijn gewoon bytes, dus het is niet gebonden aan één locatie.

## Maar dan moet het kunnen hacken {#but-then-it-needs-to-be-able-to-hack}

GPT-4 kan al [autonoom websites hacken](https://arxiv.org/html/2402.06664v1), [87% van de geteste kwetsbaarheden exploiteren](https://arxiv.org/abs/2404.08144) en [88% van de concurrerende hackers verslaan](https://arxiv.org/pdf/2402.11814.pdf).
Hoe slim denk je dat GPT-6 zal zijn?

Lees meer over de [cybersecurity-risico's](/cybersecurity-risks).

## Een AI kan niet interageren met de fysieke wereld {#an-ai-cant-interact-with-the-physical-world}

Een aanzienlijk aantal dingen is verbonden met het web.
Auto's, vliegtuigen, drones, we hebben nu zelfs humanoïde robots.
Al deze kunnen gehackt worden.

En het zijn niet alleen robots en machines die gehackt kunnen worden.
Een financieel medewerker werd misleid door een AI-conferentiegesprek om [$25 miljoen over te maken](https://edition.cnn.com/2024/02/04/asia/deepfake-cfo-scam-hong-kong-intl-hnk/index.html).
Een AI kan andere AI's gebruiken om deepfakes te genereren.
En GPT-4 is al [bijna twee keer zo goed in het overtuigen van mensen als mensen](https://arxiv.org/abs/2403.14380).

Lees meer over [hoe goed de beste AI-modellen zijn](/sota).

## Waarom zou een AI mensen haten en willen doden? {#why-would-an-ai-hate-humans-and-want-to-kill-us}

Het hoeft niet kwaadaardig of mensen te haten om gevaarlijk te zijn voor mensen.
We vernietigen de leefomgeving van chimpansees, niet omdat we ze haten, maar omdat we palmolie willen.
We zijn slimmer, dus chimpansees kunnen ons niet stoppen.
Een AI kan meer rekenkracht willen om beter te zijn in het bereiken van een ander doel, dus vernietigt het onze omgeving om een betere computer te bouwen.
Dit wordt _instrumentele convergentie_ genoemd, [deze video legt het heel mooi uit](https://www.youtube.com/watch?v=ZeecOKBus3Q).

## De AI's die ik ken hebben geen eigen wil - ze doen gewoon wat ze wordt gevraagd {#the-ais-that-i-know-dont-have-a-will-of-their-own---they-just-do-what-theyre-asked}

Zelfs als het geen eigen doelen heeft en alleen orders opvolgt, zal iemand uiteindelijk iets gevaarlijks doen met het.
Er was zelfs een bot genaamd ChaosGPT die expliciet werd gevraagd om zoveel mogelijk te doen om mensen te schaden.
Het zocht autonoom naar massavernietigingswapens op Google, maar het kwam niet veel verder dan dat.
Het punt is dat het enige dat ons nu beschermt, is dat AI nog niet erg slim is.

## Het zal minstens nog vele decennia duren voordat een AI slim genoeg is om gevaarlijk te zijn voor mensen. {#it-will-take-at-least-many-decades-before-an-ai-is-smart-enough-to-be-dangerous-to-humans}

Op Metaculus was [de gemeenschappelijke voorspelling voor (zwakke) AGI](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/) drie jaar geleden 2057, en nu is het 2026.

In 2022 dachten AI-onderzoekers dat het [17 jaar](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) zou duren voordat AI in staat zou zijn om een New York Times-bestseller te schrijven.
Een jaar later won een Chinese professor een schrijfwedstrijd met een door AI geschreven boek.

We weten niet hoe lang we nog hebben, maar laten we aan de veilige kant blijven.

Lees meer over [urgentie](/urgency)

## Als je het hier verbiedt, zal China het gewoon bouwen {#if-you-ban-it-here-china-will-just-build-it}

We vragen niet om het alleen hier te verbieden.
We hebben een internationale pauze nodig via een verdrag.
Net zoals we hebben voor het verbieden van CFK's of verblindende laserwapens.

Lees meer over [ons voorstel](/proposal)

## Het is onmogelijk om technologie te vertragen. {#its-impossible-to-slow-down-technology}

We kunnen het reguleren door chips te reguleren.
Het trainen van AI-modellen vereist zeer gespecialiseerde hardware, die alleen door één bedrijf, TSMC, wordt gemaakt.
Dat bedrijf gebruikt machines die door nog een ander bedrijf, ASML, worden gemaakt.
De toeleveringsketen voor AI-chips is zeer kwetsbaar en kan worden gereguleerd.

Lees meer over [haalbaarheid](/feasibility).

## Een pauze zou slecht zijn, omdat... {#a-pause-would-be-bad-because}

Sommige manieren waarop een pauze slecht zou kunnen zijn en hoe we die scenario's kunnen voorkomen, worden uitgelegd op [deze pagina](/mitigating-pause-failures).
Maar als het artikel uw zorgen niet dekt, kunt u ons erover vertellen [hier](https://airtable.com/appWPTGqZmUcs3NWu/pagIvo9Sv6IDHaolu/form).

## Niemand wil een pauze {#nobody-wants-a-pause}

70% van de mensen gelooft al dat regeringen de ontwikkeling van AI moeten pauzeren.
De [populaire steun](/polls-and-surveys) is er al.
De volgende stap is om onze politici te laten weten dat dit urgent is.

## Ik kan geen verschil maken {#i-cant-make-a-difference}

Jawel, dat kan je wel!
Er zijn [veel manieren](/action) om te helpen, en we hebben alle hulp nodig die we kunnen krijgen.
