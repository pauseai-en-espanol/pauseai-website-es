---
title: De haalbaarheid van een pauze
description: Is een pauze in AI-ontwikkeling mogelijk?
---

<!-- einde van frontmatter metadata, streepjes hierboven moeten blijven -->
<!-- Ik had bijna geen bronnen toegevoegd, hopelijk verandert dat binnenkort -->

Een pauze in AI-ontwikkeling is niet onmogelijk.
Het vaststellen van een rode lijn die bepaalt welke technologieën en acties kunnen worden ontwikkeld en uitgevoerd, is iets wat we voortdurend doen.

## Politieke haalbaarheid van een pauze {#political-feasibility-of-a-pause}

Sommigen noemen de pauze "radicaal" of "extreem", maar dat is niet hoe het publiek erover denkt.
Verschillende [peilingen en enquêtes](/polls-and-surveys) hebben aangetoond dat:

- Mensen erg bezorgd zijn over AI (vooral vanwege veiligheid)
- De overgrote meerderheid (bijna 70%) [steunt een pauze in AI-ontwikkeling](https://www.sentienceinstitute.org/aims-survey-supplement-2023)
- De overgrote meerderheid (>60%) [steunt een internationaal verdrag om AGI te verbieden](https://www.sentienceinstitute.org/aims-survey-supplement-2023)

## Technische afdwingbaarheid van een pauze {#technical-enforceability-of-a-pause}

De gemakkelijkste manier om grensverleggende modellen te reguleren, op een afdwingbare manier, is door [rekenkracht te reguleren](https://www.governance.ai/post/computing-power-and-the-governance-of-ai).
We kunnen [GPU's volgen](https://arxiv.org/abs/2303.11341) zoals we elementen volgen die worden gebruikt bij de ontwikkeling van kernwapens.
Gelukkig voor ons heeft de rekenkrachttoeleveringsketen verschillende knelpunten.
De hardware die nodig is om de grootste modellen te trainen (gespecialiseerde GPU's) wordt geproduceerd door [slechts 1 of 3 bedrijven](https://assets-global.website-files.com/614b70a71b9f71c9c240c7a7/65cb86a0341180453f268f38_SpwF1cBT0AS-m_n20TBXzCF6YprIVM4YRb9PMYWURseU1KtVkSAZJ735esGxNenwVO4Q4wlSUP-_MV3E-SEKp4SIgo1-oNe14CeDHtrb3PLXpJMym5qpWEDbXcf3maEi4yQYfQ-3NP7XgUmkO_4Zekw.jpeg).
Er zijn meerdere monopolies in de toeleveringsketen voor AI-trainingshardware:

- ASML is het enige bedrijf dat EUV-lithografiemachines produceert
- TSMC is het enige bedrijf dat de meest geavanceerde chips kan produceren
- NVidia is het enige bedrijf dat de meest geavanceerde GPU's ontwerpt

## Macht over bedrijven {#power-over-companies}

Als wat je vreest vooral bedrijven of organisaties zijn, kunnen we ze controleren via 1) wetten, regels en verdragen, of 2) publieke opinie die hen dwingt om zichzelf te reguleren.

Natuurlijk is de eerste methode de beste, maar reputatie, die klanten, investeerders, werknemersmoraal en werving beïnvloedt, is een reden waarom we protesten organiseren voor sommige AI-labs.
Ook is het belangrijk om te onthouden dat regels bedrijven op lange termijn kunnen helpen, vanwege regelgevende capture, geen consumenten verliezen als de gevaren zich realiseren, en concurrenten benadelen.
Dus we moeten ervoor zorgen dat we niet alleen een pauze krijgen, maar dat deze niet wordt opgeheven totdat het daadwerkelijk veilig is om grensverleggende AI te blijven ontwikkelen.

## Macht over overheden {#power-over-governments}

Als je vreest dat overheden je veiligheid niet serieus nemen, is dat een ingewikkelder probleem.
Maar over het algemeen geven politici om niet te veel politieke steun te verliezen.
En, belangrijker nog, ze kunnen ook bezorgd zijn over de risico's zonder de enorme vooringenomenheid en wettelijke verplichtingen die sommige individuen van bedrijven hebben om winst te maximaliseren.

<!-- Ook kunnen buitenlandse staten overheden onder druk zetten... vervolg? -->

Als je denkt dat we regulering van één overheid kunnen krijgen, maar geen multilateraal verdrag, moet je beseffen dat als overheden kunnen erkennen dat sommige oncontroleerbare technologieën een gevaar vormen voor hun bevolking en kunnen ontstaan uit andere landen, de nieuwe technologieën een nationaal veiligheidsprobleem worden, en de overheden geïnvesteerd raken in het stoppen van andere landen om ze ook te ontwikkelen.
Bovendien is het belangrijk om te beseffen dat we niet echt veel landen nodig hebben om een pauze te ondersteunen.
In werkelijkheid kun je een pauze in de ontwikkeling van grensverleggende modellen krijgen door het alleen maar in de VS (en zelfs alleen in Californië) te verbieden.
China en de rest van de wereld lijken nog ver achter te liggen, en we moeten ons geen zorgen maken als hun toetreding tot een verdrag wat later gebeurt.

## Soortgelijke historische gevallen {#similar-historical-cases}

Hoewel elk bewijs van incompetentie of kwaadwilligheid van onze overheden, bedrijven en systemen ons kan verleiden tot defaitistisch denken, waarbij coördinatie te moeilijk is, de belangen van de mensen niet goed worden vertegenwoordigd,
en/of worden vertegenwoordigd maar dom zijn, vergeten we soms successen die we als beschaving door de geschiedenis heen hebben behaald.

Voor empirisch bewijs van waarom een verdrag als dit mogelijk is, moeten we kijken naar eerdere mondiale overeenkomsten.
Of het nu informele of formele overeenkomsten zijn, ze zijn vrij gebruikelijk geweest door de geschiedenis heen, vooral om geschillen op te lossen en mensenrechten te bevorderen.
Veel eerdere successen, zoals de afschaffing van de slavernij, hadden ook sterke, kortetermijn-economische prikkels tegen hen.
Maar dat weerhield hen niet.

Als we zoeken naar soortgelijke moderne voorbeelden van mondiale overeenkomsten tegen nieuwe technologieën, kunnen we er veel vinden. Sommige van de belangrijkste waren:

- Het [Montreal-protocol](https://nl.wikipedia.org/wiki/Montrealprotocol), dat de productie van CFK's in alle 197 landen verbood en als gevolg daarvan de mondiale uitstoot van ozonafbrekende stoffen met meer dan 99% deed afnemen sinds 1986. Dankzij het protocol geneest het ozongat nu, en dat is waarom we er niet meer over horen.
- Het [Biologisch Wapenverdrag](https://nl.wikipedia.org/wiki/Biologisch_Wapenverdrag), dat biologische en gifwapens verbood en door 185 staten werd ondertekend.
- Het [Chemisch Wapenverdrag](https://nl.wikipedia.org/wiki/Chemisch_Wapenverdrag), dat chemische wapens verbood en door 193 staten werd ondertekend.
- Het [Milieumodificatieverdrag](https://nl.wikipedia.org/wiki/Verdrag_inzake_de_verbodsbepaling_van_milieumodificatie_te_oorlogvoeringsdoeleinden), dat weerkrijg verbood en door 78 staten werd ondertekend.
- Het [Verdrag inzake de ruimtevaart](https://nl.wikipedia.org/wiki/Verdrag_inzake_de_ruimtevaart), dat het stationeren van massavernietigingswapens in de ruimte verbood, militaire activiteiten op hemellichamen verbood, de vreedzame verkenning en het gebruik van de ruimte wettelijk verplicht stelde, en door 114 landen werd ondertekend.
- Het [Non-proliferatieverdrag](https://nl.wikipedia.org/wiki/Verdrag_inzake_de_niet-verspreiding_van_kernwapens) en een aantal andere internationale overeenkomsten, die essentieel zijn geweest in het voorkomen van de verspreiding van kernwapens en het bevorderen van het doel van nucleaire ontwapening. Dankzij hen hebben we veel landen ervan weerhouden kernwapenprogramma's na te streven, de hoeveelheid kernwapens sinds de jaren 90 verminderd, en een nucleaire oorlog gedurende vele decennia voorkomen. Allemaal ongelooflijke prestaties.
- De [Internationale Organisatie voor Atoomenergie](https://nl.wikipedia.org/wiki/Internationale_Organisatie_voor_Atoomenergie), die een intergouvernementele organisatie is bestaande uit 178 lidstaten die streeft naar de vreedzame toepassing van kernenergie en het gebruik ervan voor militaire doeleinden wil voorkomen. Ongeacht of je denkt dat kernenergie te streng gereguleerd is of niet, de IAEA wordt beschouwd als een goed voorbeeld van een internationaal instrument dat we zouden kunnen hebben om de veiligheid van de grootste AI-modellen te evalueren.
- En de [Verklaring van de Verenigde Naties over menselijke klonen](https://nl.wikipedia.org/wiki/Verklaring_van_de_Verenigde_Naties_over_menselijke_klonen), die de lidstaten opriep om menselijke klonen te verbieden in 2005 en veel van hen ertoe bracht dit te doen. Het is een interessant geval omdat nu, bijna 20 jaar later en zonder een formeel akkoord, 60 landen het hebben verboden, hetzij volledig of gedeeltelijk, en er geen enkel (geverifieerd) geval van een gekloond mens is geweest. Dus op een bepaalde manier suggereert het de mogelijkheid dat veel unilaterale regelingen voldoende zijn om te voorkomen dat andere gevaarlijke technologieën ook worden ontwikkeld.

Als je denkt dat AI eigenlijk lijkt op andere gevallen waarin we internationaal geen goede verdragen hebben kunnen sluiten: alles wat ooit is gebeurd, had een eerste keer.
Er waren bijzonderheden die ze de eerste keer maakten en dat is een reden om de [bijzonderheden van AI](#ai-particular-case) aan te pakken.

### Impact van protesten {#impact-of-protests}

Het is vrij gebruikelijk dat mensen de effectiviteit van protesten en sociale bewegingen in het algemeen in twijfel trekken.
Natuurlijk zijn er veel gevallen waarin demonstraties geen resultaten opleveren, maar er zijn ook situaties waarin de eisen van de demonstranten worden ingewilligd en het waarschijnlijk lijkt dat die resultaten [zijn veroorzaakt door de protesten](https://www.socialchangelab.org/_files/ugd/503ba4_052959e2ee8d4924934b7efe3916981e.pdf).
En [er zijn redenen om aan te nemen dat AI-activisme soortgelijke resultaten kan behalen](https://forum.effectivealtruism.org/posts/WfodoyjePTTuaTjLe/efficacy-of-ai-activism-have-we-ever-said-no).

Als je toch niet van het idee van protesteren houdt, nemen we ook [andere acties](/action), zoals rechtstreeks contact opnemen met [regeringen](/lobby-tips).

## Bijzonder geval van AI {#ai-particular-case}

Als je denkt dat AI verschillend genoeg is van deze gevallen (of zelfs als je dat niet denkt), is het nuttig om de bijzondere situatie van AI te analyseren.
De dingen die AI anders maken, hoeven niet noodzakelijkerwijs te betekenen dat het minder reguleerbaar is.
Bijvoorbeeld, we proberen [geen bestaande producten en diensten te reguleren die mensen al gebruiken en regelmatig genieten](/proposal), en we gaan niet tegen veel bedrijven in die kunnen lobbyen of werknemers die hun baan zouden verliezen als we succesvol zijn. Bijna het tegenovergestelde.

Een ander punt in ons voordeel is dat het publiek niet partijdig of politiek verdeeld is, maar [verenigd in steun voor regulering](https://drive.google.com/file/d/1n0pXDBuIcb01tW4TQdP1Mb5aAiFDvWk0/view).
Toch moeten we ervoor zorgen dat we hen niet afschrikken, hun perspectieven horen, en zien op welke manieren ze kunnen worden geholpen door een pauze op basis van waar ze om geven. Aangezien veel mensen nog geen beslissing hebben genomen over welk type regulering ze steunen.

Als het gaat om AI-risico's, lijken het publiek en de experts [bezorgd over de risico's en geïnteresseerd in regulering](/polls-and-surveys).
De politici, gebaseerd op de [beleidsmaatregelen die worden aangenomen en uitgevoerd](https://www.bloomberg.com/news/articles/2024-03-13/regulate-ai-how-us-eu-and-china-are-going-about-it), de [topconferenties die ze organiseren](/summit), en de [verklaringen die ze afleggen](/quotes), lijken ook behoorlijk bezorgd.
Zelfs een recent [door de Amerikaanse regering in opdracht gegeven rapport](https://time.com/6898967/ai-extinction-national-security-risks-report/) beveelt, naast meerdere voorstellen, verschillende soorten pauzes in AI-ontwikkeling aan om risico's voor de nationale veiligheid en de mensheid als geheel te voorkomen.

Dit alles gebeurt terwijl PauseAI nog vrij jong is en de meeste mensen nog niet hebben gehoord van de meeste risico's.
Als we het bewustzijn en de consensus over existentiële risico's zouden verhogen, zouden we de kans hebben om meer mainstream te worden, aangezien vrijwel niemand wil sterven of dat de wereld eindigt.
Dat is niet iets wat in het belang is van de meest egoïstische bedrijven, overheden en mensen.

Zelfs als het tijd kost, zal de manifestatie van de problemen die AI's in de komende jaren zullen veroorzaken, het bewustzijn ervan potentieel vergroten en uiteindelijk meer en meer regulering triggeren.
In het geval dat we geen pauze krijgen zo snel als we zouden willen, kunnen massale werkloosheid en allerlei incidenten de meeste mensen op dezelfde pagina zetten, hetzij progressief of plotseling, en de mensen die geen pauze serieus zouden hebben overwogen, ertoe brengen dit daadwerkelijk te doen.
Daarom is het belangrijk om ons potentieel om te slagen niet te baseren op korte-termijnresultaten, maar altijd voorbereid te zijn op nieuwe aanhangers en bondgenoten, en klaar te zijn om politici te leiden bij de implementatie van onze voorstellen in het geval een waarschuwingsschot plaatsvindt.

## Nevenvoordelen {#collateral-benefits}

Pleiten voor een pauze heeft andere positieve gevolgen buiten het bereiken ervan.
Het informeren van het publiek, techneuten en politici over de risico's helpt andere interventies die erop gericht zijn om veilige AI's en AI's veilig te maken.
Het zorgt ervoor dat mensen meer belang hechten aan het technische, politieke en communicatieve werk dat in AI-veiligheid en AI-ethiek gaat, wat uiteindelijk betekent dat er meer financiering en banen in gaan, met betere resultaten.

Het zou niet alleen nieuwe mensen en middelen naar nieuwe interventies brengen, maar zou ook helpen om gematigde technische en beleidsinitiatieven "redelijker" te laten lijken en hun kansen op steun te vergroten.

Bovendien zou het mensen enigszins kunnen voorbereiden op de gevaren, hen leren hoe ze AI ethischer kunnen gebruiken, en hen zelfs overtuigen om niet te investeren of te werken aan grensverleggende en onveilige projecten.

## Geef niet toe aan pessimisme {#dont-give-in-to-pessimism}

We begrijpen waar de pessimistische overtuigingen over sterke regulering vandaan komen en dat het niet gemakkelijk zal zijn.
Maar het is ook niet gemakkelijk om de toekomst te voorspellen, en dit artikel zoekt te argumenteren tegen het overtuigde gevoel van onze machteloosheid, aangezien het enige wat het kan doen, is dienen als een self-fulfilling prophecy.

Het enige gemakkelijke om te doen is opgeven, [het is de gemakkelijke uitweg](/psychology-of-x-risk#difficult-to-act-on).
Want als er niets is dat we kunnen doen, is er niets dat we moeten doen.
Maar we moeten niet opgeven zonder het zelfs maar te proberen.
Dit is eigenlijk onze beste kans om een impact te hebben op de wereld en de toekomst van onze beschaving.

## Beslissingstheorie zegt: probeer het toch {#decision-theory-says-try-it-anyways}

Zelfs als je denkt dat een pauze vrij onwaarschijnlijk is en je je niet druk maakt om de andere voordelen, tenzij je niet gelooft in de grootste risico's of betere strategieën in gedachten hebt, raden we je aan om [je aan te sluiten](/join). Begraaf je hoofd niet in het zand en wacht niet tot je dood of gered wordt, je kunt ons helpen dit te bereiken!
