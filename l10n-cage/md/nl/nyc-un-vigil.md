---
title: PauseAI kaarsenwake bij het VN-hoofdkwartier in NYC, 3 juni
---

- Kaarsenwake om aandacht te vragen voor het existentiële risico van AI.
- 3 juni, 19:30-21:00 uur. Zonsondergang om 20:15 uur.
- Hoofdkwartier van de Verenigde Naties in New York City.
- [Meld je aan](https://forms.gle/hsVetUDx3R1w6yj59)

## Persbericht {#press-release-3}

Op zaterdag 3 juni, bij zonsondergang, vindt een kaarsenwake plaats voor het hoofdkwartier van de Verenigde Naties.
De wake is een symbool van hoop, zodat mensen samen kunnen komen om actie te ondernemen tegen een groeiende existentiële dreiging.
Vrijwilligers van de nieuwe [PauseAI](http://pauseai.info)-beweging zullen daar bijeenkomen om regeringen op te roepen een top te organiseren om de ontwikkeling van deze gevaarlijke technologie te stoppen.

De helft van de AI-onderzoekers [denkt](https://aiimpacts.org/2022-expert-survey-on-progress-in-ai/) dat er een kans van 10% of meer is dat de uitvinding van superintelligente AI het einde van de mensheid betekent. Zou je in een vliegtuig stappen als de helft van de vliegtuigingenieurs dacht dat er een kans van 10% was dat het zou neerstorten?

Prominente voorbeelden van mensen die waarschuwen voor de gevaren van AI zijn prof. [Geoffrey Hinton](https://www.reuters.com/technology/ai-pioneer-says-its-threat-world-may-be-more-urgent-than-climate-change-2023-05-05/) en prof. [Yoshua Bengio](https://yoshuabengio.org/2023/05/22/how-rogue-ais-may-arise/), beide winnaars van de Turing Award en pioniers van de meest succesvolle AI-methoden van vandaag. Niet alleen wetenschappers, maar ook leiders van AI-bedrijven zelf zijn bezorgd over dit gevaar:

- Sam Altman (CEO van OpenAI, het bedrijf achter ChatGPT): ["De ontwikkeling van superintelligente machine-intelligentie is waarschijnlijk de grootste dreiging voor het voortbestaan van de mensheid."](https://blog.samaltman.com/machine-intelligence-part-1)
- Elon Musk (mede-oprichter van OpenAI): ["AI heeft het potentieel om beschavingen te vernietigen."](https://www.inc.com/ben-sherry/elon-musk-ai-has-the-potential-of-civilizational-destruction.html)
- Bill Gates (mede-oprichter van Microsoft, eigenaar van 50% van OpenAI): ["AI kan besluiten dat mensen een dreiging vormen."](https://www.denisonforum.org/daily-article/bill-gates-ai-humans-threat/)
- Jaan Tallinn (leidende investeerder bij Anthropic, bouwers van Claude): ["Ik heb niemand in AI-labs ontmoet die zegt dat het risico [van het trainen van een next-gen model] minder dan 1% is om de planeet op te blazen. Het is belangrijk dat mensen weten dat levens op het spel staan."](https://twitter.com/liron/status/1656929936639430657)

De vooruitgang in het AI-landschap heeft de verwachtingen overtroffen. In 2020 werd geschat dat een AI-systeem pas in 2050 universitaire toelatingsexamens zou halen. Dit doel werd in maart 2023 bereikt door OpenAI's GPT-4. Deze AI heeft een [verbale IQ van 155](https://bgr.com/tech/chatgpt-took-an-iq-test-and-its-score-was-sky-high/), spreekt 23 talen, kan programmeren en [kan mensen misleiden](https://www.theinsaneapp.com/2023/03/gpt4-passed-captcha-test.html). Gelukkig heeft GPT-4 nog steeds beperkingen. Bijvoorbeeld, het kan niet effectief [hacken of computervirussen schrijven](https://pauseai.info/cybersecurity-risks), maar het is mogelijk dat deze vaardigheden slechts een paar innovaties verwijderd zijn. Gezien het huidige tempo van AI-investeringen nadert dit punt [snel](https://pauseai.info/urgency).

Deze enorme en onverwachte sprongen in capaciteiten hebben veel experts ertoe gebracht om een pauze in de ontwikkeling van AI te vragen via een [open brief](https://futureoflife.org/open-letter/pause-giant-ai-experiments/) gericht aan grote AI-bedrijven. De brief is meer dan 27.000 keer ondertekend, voornamelijk door AI-onderzoekers en tech-luminairs. Een pauze is nodig om te werken aan AI-wetgeving, om te werken aan het AI-aligneringsprobleem en om als samenleving aan te passen aan deze nieuwe technologie. Een [recente enquête](https://forum.effectivealtruism.org/posts/EoqeJCBiuJbMTKfPZ/unveiling-the-american-public-opinion-on-ai-moratorium-and) in de Verenigde Staten laat zien dat er significante steun is voor een pauze, met meer dan 60% van het publiek voor. Helaas lijkt het erop dat bedrijven niet bereid zijn om vrijwillig hun concurrentiepositie in gevaar te brengen door te stoppen. Deze AI-bedrijven zijn verwikkeld in een race naar de bodem, waarbij veiligheid steeds meer een achterbank krijgt ten opzichte van het verbeteren van capaciteiten. Daarom moet de pauze worden opgelegd door regeringen. Het implementeren van een nationale pauze is ook een uitdaging, aangezien landen redenen hebben om niet de eerste te zijn die pauzeert. Daarom is een internationale oplossing nodig: een top. PauseAI roept onze regeringen op om die top te organiseren.

Voor meer informatie, bezoek [PauseAI.info](http://pauseai.info).
