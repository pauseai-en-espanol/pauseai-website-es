---
title: PauseAI protest @ Den Haag, Nederland - 11 augustus
description: Wij organiseren een protest om een pauze te eisen in de ontwikkeling van gevaarlijke AI.
---

<script>
    import WidgetConsent from '$lib/components/widget-consent/WidgetConsent.svelte'
</script>

<WidgetConsent>
<div>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">We protested in The Hague, Netherlands to ask our government to prioritise mitigation of AI risks. We had a few speeches, talked to people on the streets, handed out flyers and had a good time!<br><br>Check out the press release (EN + NL) for more information: <a href="https://t.co/Dd7CXHlajc">https://t.co/Dd7CXHlajc</a> <a href="https://t.co/T306vZD974">pic.twitter.com/T306vZD974</a></p>&mdash; PauseAI ‚è∏ü§ñ (@PauseAI) <a href="https://twitter.com/PauseAI/status/1690290512643719168?ref_src=twsrc%5Etfw">August 12, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
</WidgetConsent>

- PauseAI protest
- Waar: Wijnhaven, Den Haag
- Wanneer: 11 augustus 2023, 16:00 - 17:00

## Waarom wij protesteren {#why-we-protest}

Kunstmatige intelligentie (AI) wordt steeds krachtiger, veel sneller dan de meeste AI-wetenschappers hadden voorspeld.
Miljarden worden ge√Ønvesteerd in AI-capaciteiten, en de resultaten zijn verbluffend.
Nieuwe modellen presteren [beter dan mensen](/sota) in veel domeinen.
Naarmate de capaciteiten toenemen, nemen ook de [risico's](/risks) toe.
Wetenschappers waarschuwen zelfs dat AI [het einde van de mensheid](/xrisk) zou kunnen betekenen.

Onze politici nemen dit onderwerp niet serieus genoeg.
Wij hebben onze leiders nodig om naar deze waarschuwingen te luisteren.
Wij hebben hen nodig om actie te ondernemen en een [pauze in te lassen](/proposal) om deze zelfmoordrace te stoppen.

Wij willen dat de Nederlandse regering:

- AI-veiligheidsexperts uitnodigt om het parlement te informeren over deze risico's
- Een debat inroostert over de existenti√´le risico's van AI
- Voorbereidingen op de AI-veiligheidstop later dit jaar prioriteit geeft en een leidende rol neemt in het werken aan effectief beleid
- Internationaal samenwerkt om voldoende veiligheidsmaatregelen op mondiale schaal toe te passen

## Agenda {#agenda}

- 12:00 - 16:00 Voorbereiden van borden in de werkplaats (alleen voor de echte enthousiastelingen, neem contact met ons op als je wilt komen!)
- 16:00 Toespraken + protest + flyeren
- 17:00 Borrel @ nabijgelegen caf√©

## Contact {#contact-6}

- Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io))

## Persbericht (EN): PauseAI roept Nederlandse regering op tot het voorkomen van mensbedreigende, AI-gerelateerde rampen {#press-release-en-pauseai-calls-on-dutch-government-to-prevent-human-threatening-ai-related-disasters}

Op vrijdag 11 augustus om 16.00 uur komt een groep bezorgde individuen samen bij het Ministerie van Binnenlandse Zaken onder de naam [PauseAI](http://pauseai.info) om de ontwikkelingen in het gebied van (generatieve) AI aan te kaarten. Zij roepen de regering op om actie te ondernemen om de ontwikkeling van krachtige en mogelijk gevaarlijke kunstmatige intelligentie te pauzeren.

Tot nu toe heeft de Nederlandse regering geen actie ondernomen tegen de existenti√´le bedreiging van AI. Er is nog niet gereageerd op waarschuwingen en uitspraken van onder meer de [VN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), de premier van het [Verenigd Koninkrijk](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (waar in het najaar een top wordt georganiseerd over dit onderwerp) en [experts op het gebied van AI](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie).

"Wetenschappers trekken aan de bel: AI kan het einde betekenen van de mensheid. Experts geven dit gemiddeld zelfs [30% kans](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results). AI-bedrijven racen vooruit en gokken met al onze levens, terwijl regulering hopeloos achter blijft." - Joep Meindertsma, directeur van softwarebedrijf Ontola en oprichter van PauseAI.

De zorgen over de risico's die kleven aan AI zijn mondiaal snel aan het groeien. Deze week nog publiceerde onderzoeksbureau Axios de resultaten van een opiniepeiling onder inwoners van de Verenigde Staten, waaruit bleek dat 86% zich zorgen maakt over catastrofale risico's van AI.

"De VS heeft senaatshoorzittingen waarbij AI-experts vertellen over hoe AI het einde kan vormen van de mensheid. Waarom wordt dit onderwerp genegeerd in de Nederlandse politiek? En dat terwijl Nederland een sleutelrol speelt in de chip supply chain, dankzij ASML. Hierom kan het √≥√≥k een sleutelrol spelen in AI compute governance. Alle levens staan op het spel!" - Joep Meindertsma

PauseAI wil dat de Nederlandse regering:

- AI-veiligheidsexperts uitnodigt om het parlement te informeren over deze risico's
- Een parlementair debat inroostert over de existenti√´le risico's van geavanceerde kunstmatige intelligentie
- Voorbereidingen op de voorgestelde AI-top in het Verenigd Koninkrijk van later dit jaar voorrang geeft en een leidende rol neemt inzake effectief beleid. De actievoerders hebben concrete [voorstellen](https://pauseai.info/summit) en [beleidsidee√´n](https://pauseai.info/proposal) voor de te houden AI-top.
- Internationaal samenwerkt om een toereikende set maatregelen op mondiale schaal toegepast te krijgen, waaronder een zogenoemde AI-pauze.

Voor meer info, bezoek [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io)) & Ruben Dieleman ([email](mailto:ruben@existentialriskobservatory.org))

## Persbericht (NL): PauseAI roept overheid op tot het voorkomen van mensbedreigende, AI-gerelateerde rampen {#press-release-nl-pauseai-roept-overheid-op-tot-het-voorkomen-van-mensbedreigende-ai-gerelateerde-rampen}

Op vrijdag 11 augustus om 16.00 uur komt een groep mensen samen die zich zorgen maken over de ontwikkelingen op het gebied van (generatieve) AI bij het Ministerie van Binnenlandse Zaken onder de naam [PauseAI](http://pauseai.info). Zij roepen de regering op zich in te spannen voor een pauze van de ontwikkeling van krachtige en mogelijk gevaarlijke kunstmatige intelligentie.

Tot nu toe heeft de Nederlandse regering echter geen actie ondernomen tegen de existenti√´le bedreiging van AI. Er is nog niet gereageerd op waarschuwingen en uitspraken van onder meer de [VN](https://www.linkedin.com/feed/update/urn:li:activity:7075767810336923648), de premier van het [Verenigd Koninkrijk](https://www.theguardian.com/technology/2023/may/25/no-10-acknowledges-existential-risk-ai-first-time-rishi-sunak?) (waar in het najaar een top wordt georganiseerd over dit onderwerp) en [experts op het gebied van AI](https://nos.nl/op3/artikel/2012979-wetenschappers-waarschuwen-voor-kunstmatige-intelligentie). Ook niet nadat eerder dit jaar een [motie](https://www.parlementairemonitor.nl/9353000/1/j9vvij5epmj1ey0/vm1rshv2ulz5) in de Tweede Kamer daartoe aanspoorde.

"Wetenschappers trekken aan de bel: AI kan het einde betekenen van de mensheid. Experts geven dit gemiddeld zelfs [30% kans](https://forum.effectivealtruism.org/posts/8CM9vZ2nnQsWJNsHx/existential-risk-from-ai-survey-results). AI-bedrijven racen vooruit en gokken met al onze levens, terwijl regulering hopeloos achter blijft." - Joep Meindertsma, directeur van softwarebedrijf Ontola en oprichter van PauseAI.

De zorgen over de risico's die kleven aan AI zijn mondiaal snel aan het groeien. Deze week nog publiceerde onderzoeksbureau Axios de resultaten van een opiniepeiling onder inwoners van de Verenigde Staten, waaruit bleek dat 86% zich zorgen maakt over catastrofale risico's van AI.

"De VS heeft senaatshoorzittingen waarbij AI-experts vertellen over hoe AI het einde kan vormen van de mensheid. Waarom wordt dit onderwerp genegeerd in de Nederlandse politiek? En dat terwijl Nederland een sleutelrol speelt in de chip supply chain, dankzij ASML. Hierom kan het √≥√≥k een sleutelrol spelen in AI compute governance. Alle levens staan op het spel!" - Joep Meindertsma

PauseAI wil dat de Nederlandse regering:

- AI-veiligheidsexperts uitnodigt om het parlement te informeren over deze risico's
- Een parlementair debat inroostert over de existenti√´le risico's van geavanceerde kunstmatige intelligentie
- Voorbereidingen op de voorgestelde AI-top in het Verenigd Koninkrijk van later dit jaar voorrang geeft en een leidende rol neemt inzake effectief beleid. De actievoerders hebben concrete [voorstellen](https://pauseai.info/summit) en [beleidsidee√´n](https://pauseai.info/proposal) voor de te houden AI-top.
- Internationaal samenwerkt om een toereikende set maatregelen op mondiale schaal toegepast te krijgen, waaronder een zogenoemde AI-pauze.

Voor meer info, bezoek [PauseAI.info](http://pauseai.info). Contact: Joep Meindertsma ([twitter](https://twitter.com/joepmeindertsma), [email](mailto:joep@ontola.io)) & Ruben Dieleman ([email](mailto:ruben@existentialriskobservatory.org))
