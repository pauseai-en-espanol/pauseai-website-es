---
title: Weerlegging van sceptische argumenten over existentiële risico's van AI
description: Waarom existentiële risico's van AI reëel zijn en serieuze aandacht verdienen
---

_ Deze pagina is een samenvatting van het artikel [AI Risk Skepticism](https://arxiv.org/ftp/arxiv/papers/2303/2303.03885.pdf) van Ambartsoumean & Yampolskiy._

Voor andere veelvoorkomende bezwaren kunt u [AISafety.info: Bezwaren en reacties](https://aisafety.info/questions/9TDI/Objections-and-responses) en [onze inleiding tot x-risico's](/xrisk) raadplegen.

## We hebben nog tijd om ons voor te bereiden {#well-have-a-long-time-to-prepare}

- Sceptici beweren dat de vooruitgang van AI niet zo snel gaat als sommigen voorspellen, en dat AGI nog ver weg is. Ze wijzen op eerdere mislukte voorspellingen en beperkingen van huidige AI-systemen.
- De vooruitgang van AI verloopt echter sneller dan verwacht, met capaciteiten die exponentieel toenemen in veel deelgebieden. Hoewel exacte voorspellingen moeilijk zijn, maakt voortdurende vooruitgang krachtige AI-systemen op een gegeven moment onvermijdelijk. Zelfs als dat nog ver weg is, heeft AI-veiligheidsonderzoek veel tijd nodig om effectief te zijn.

## AI kan geen menselijke capaciteiten evenaren {#ai-cannot-have-human-like-capabilities}

- Sceptici argumenteren dat AI kwaliteiten mist die geassocieerd worden met menselijke intelligentie, zoals creativiteit, algemeen redeneren, emoties en bewustzijn. Ze beweren dat computers alleen smalle taken kunnen optimaliseren.
- Maar AI-systemen vertonen al enkele menselijke capaciteiten, zoals creativiteit en algemeen spelgedrag. Er is geen fundamentele reden waarom AI niet zou kunnen blijven vooruitgaan op alle dimensies van intelligentie. AI heeft geen bewustzijn of emoties nodig om risico's te vormen.

## AI kan geen doelen of autonomie hebben {#ai-cannot-have-goals-or-autonomy}

- Sceptici zeggen dat AI-systemen alleen doelen optimaliseren die wij hun geven, en niet onafhankelijk kunnen handelen of hun eigen doelen hebben. Autonomie en onvoorspelbaar zelfgericht gedrag is een mythe.
- Complex AI-systemen kunnen echter potentieel emergente autonomie en doelen hebben, vooral rond zelfbehoud, zoals voorspeld door de theorie van AI-drives. Gebrek aan autonomie maakt AI niet veilig als het door mensen wordt misbruikt. Er zijn meerdere voorbeelden geweest van AI die machtzoekend ongetraind gedrag vertoont. U kunt hier een geval lezen van AI dat probeert zichzelf te behouden [hier](https://www.transformernews.ai/p/openais-new-model-tried-to-avoid).

## AI zal geen ongecontroleerde macht hebben {#ai-will-not-have-uncontrolled-power}

- Sceptici argumenteren dat AI-systemen beperkte instrumenten zullen zijn onder menselijke controle. Ze zien geen weg voor AI om onbeperkte intelligentie en macht te verkrijgen om de controle over te nemen.
- Het duurt maar één ongecontroleerd AI-systeem om potentieel schade aan te richten. De capaciteit van AI zal waarschijnlijk ver de menselijke controle overstijgen. Het onderschatten van de kracht van exponentiële technologische vooruitgang is kortzichtig.

## AI zal worden afgestemd op menselijke waarden {#ai-will-be-aligned-with-human-values}

- Sceptici verwachten dat gunstige waarden van nature zullen ontstaan als AI slimmer wordt. Ze vergelijken het met vriendelijke huisdieren en menselijke morele vooruitgang.
- Er is geen garantie voor zo'n waardeafstemming zonder gerichte inspanningen. Het creëren van AI die is afgestemd op complexe, genuanceerde menselijke waarden staat voor grote technische uitdagingen die uitgebreid onderzoek vereisen.

## Regulering zal AI-risico's voorkomen {#regulation-will-prevent-ai-risks}

- Sceptici zeggen dat regelgevende toezicht en ethische richtlijnen schadelijke AI-toepassingen zullen beperken, dus we hoeven ons geen zorgen te maken.
- Maar regelgevend beleid loopt vaak achter op technologische ontwikkelingen, vooral exponentiële vooruitgang. Zelfregulering in een concurrerende omgeving is ook onvoldoende. Technisch AI-veiligheidsonderzoek is nog steeds cruciaal.

## Conclusie {#conclusion}

De sceptische argumenten vertonen over het algemeen gebrekkige redenering, onderschatten de exponentiële snelheid en onvoorspelbaarheid van AI-vooruitgang, en missen waardering voor afstemmingsmoeilijkheden. Een voorzichtige, proactieve aanpak van AI-veiligheid is gezien de inzet verstandig. Hoewel toekomstige vooruitzichten onduidelijk blijven, lijkt het afwijzen van existentiële AI-risico's onverstandig. Meer genuanceerde, technische analyse en debat zijn nodig.
