---
title: State-of-the-art AI-capaciteiten vs mensen
description: Hoe slim zijn de nieuwste AI-modellen in vergelijking met mensen?
---

Hoe slim zijn de nieuwste AI-modellen in vergelijking met mensen?
Laten we eens kijken hoe de meest geavanceerde AI-systemen zich verhouden tot mensen in verschillende domeinen.
De onderstaande lijst wordt regelmatig bijgewerkt om de nieuwste ontwikkelingen weer te geven.

_Laatste update: 2024-09-16_

## Beter dan alle mensen {#superhuman-better-than-all-humans}

- **Spellen**: Voor veel spellen ([Schaken, Go](https://en.wikipedia.org/wiki/AlphaGo_Zero), Starcraft, Dota, [Gran Turismo](https://www.technologyreview.com/2022/07/19/1056176/sonys-racing-ai-destroyed-its-human-competitors-by-being-nice-and-fast/) etc.) is de beste AI beter dan de beste mens.
- **Werkgeheugen**: Een gemiddelde mens kan ongeveer 7 items (zoals nummers) tegelijk onthouden. Gemini 1.5 Pro [kan 99% van 7 miljoen woorden lezen en onthouden](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#sundar-note).
- **Leessnelheid**: Een model als Gemini 1.5 Pro kan een heel boek in 30 seconden lezen. Het kan een hele nieuwe taal leren en teksten vertalen in een half uur.
- **Schrijfsnelheid**: AI-modellen kunnen schrijven met snelheden die ver boven die van mensen liggen, hele computerprogramma's in seconden schrijven.
- **Kennis**: Moderne LLM's weten veel meer dan enig mens, hun kennis strekt zich uit over vrijwel elk domein. Er is geen mens wiens kennisbreedte hierbij in de buurt komt.

## Beter dan de meeste mensen {#better-than-most-humans}

- **Programmeren**: o3 verslaat [99,9% van de menselijke programmeurs](https://arxiv.org/abs/2502.06807) in de zeer uitdagende Codeforces-competitie. Het weet 71,7% van de programmeerproblemen in de SWE-benchmark op te lossen, wat aantoont dat het ook zeer effectief echte software-engineeringproblemen kan oplossen.
- **Schrijven**: In december 2023 won een door AI geschreven roman een prijs in een [nationale sciencefictionwedstrijd](https://www.scmp.com/news/china/science/article/3245725/chinese-professor-used-ai-write-science-fiction-novel-then-it-won-national-award?campaign=3245725&module=perpetual_scroll_0&pgtype=article). De professor die de AI gebruikte, maakte het verhaal van een ontwerp van 43.000 tekens dat in slechts drie uur met 66 prompts was gegenereerd. De beste taalmodellen hebben een supermenselijke woordenschat en kunnen in veel verschillende stijlen schrijven.
- **Vertalen**: En ze kunnen vloeiend reageren en vertalen in alle belangrijke talen.
- **Creativiteit**: Beter dan 99% van de mensen in de [Torrance Tests of Creative Thinking](https://neurosciencenews.com/ai-creativity-23585/) waarbij relevante en nuttige ideeÃ«n moeten worden gegenereerd. De tests waren echter relatief klein en voor grotere projecten (bijv. het opzetten van een nieuw bedrijf) is AI nog niet autonoom genoeg.
- **Domeinexpertise**: o3 [beantwoordt 87,7%](https://openai.com/index/learning-to-reason-with-llms/) van de GPQA-diamantvragen correct, waarmee het menselijke domeinexperts (PhD's) overtreft die slechts 69,7% behalen.
- **Visuele redenering**: o3 behaalde een score van [87,5% op de ARC-AGI-benchmark](https://arcprize.org/blog/oai-o3-pub-breakthrough) (het menselijke gemiddelde is 60%), die specifiek was ontworpen om moeilijk te zijn voor grote taalmodellen.
- **Wiskunde**: o3 scoort onder de top 500 studenten in de VS in een kwalificatieronde voor de USA Math Olympiad (AIME).
- **Overtuigingskracht**: GPT-4 met toegang tot persoonlijke informatie kon de instemming van deelnemers met de argumenten van hun tegenstanders met [81,7 procent](https://arxiv.org/abs/2403.14380) verhogen in vergelijking met debatten tussen mensen - bijna twee keer zo overtuigend als de menselijke debaters.
- **IQ-tests**: Bij verbale IQ-tests overtreffen LLM's al enige tijd 95 tot 99% van de mensen (score tussen [125](https://medium.com/@soltrinox/the-i-q-of-gpt4-is-124-approx-2a29b7e5821e) en [155](https://www.scientificamerican.com/article/i-gave-chatgpt-an-iq-test-heres-what-i-discovered/)). Bij non-verbale (patroonherkenning) IQ-tests scoorde het 2024 o1-preview-model [120 op de Mensa-test](https://www.maximumtruth.org/p/massive-breakthrough-in-ai-intelligence), waarmee het 91% van de mensen overtrof.
- **Gespecialiseerde kennis**: GPT-4 scoort 75% in het [Medical Knowledge Self-Assessment Program](https://openai.com/research/gpt-4), mensen gemiddeld tussen [65 en 75%](https://pubmed.ncbi.nlm.nih.gov/420438/). Het scoort beter dan [68](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4441311) tot [90%](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/) van de rechtenstudenten op het advocaatsexamen.
- **Kunst**: Beeldgeneratiemodellen hebben [kunst](https://dataconomy.com/2022/09/26/ai-artwork-wins-art-competition) en zelfs [fotowedstrijden](https://www.artnews.com/art-news/news/ai-generated-image-world-photography-organization-contest-artist-declines-award-1234664549) gewonnen.
- **Onderzoek**: GPT-4 kan [autonoom chemisch onderzoek](https://www.nature.com/articles/s41586-023-06792-0) doen en DeepMind heeft een AI gebouwd die een [oplossing heeft gevonden voor een open wiskundig probleem](https://www.nature.com/articles/s41586-023-06924-6). Deze architectuur vereist echter veel menselijke engineering en is niet algemeen.
- **Hacking**: GPT-4 kan [autonoom websites hacken](https://arxiv.org/html/2402.06664v1) en [verslaat 89% van de hackers](https://arxiv.org/pdf/2402.11814.pdf) in een Capture-the-Flag-competitie.

## Slechter dan de meeste mensen {#worse-than-most-humans}

- **"Ik weet het niet" zeggen**. Bijna alle grote taalmodellen hebben dit probleem van 'hallucinatie', het verzinnen van informatie in plaats van te zeggen dat ze het niet weten. Dit is een belangrijk tekortkoming, omdat het LLM's onbetrouwbaar maakt en hun toepasbaarheid beperkt. Uit onderzoek [blijkt](https://arxiv.org/html/2403.04307v1) dat grotere modellen minder hallucineren dan kleinere.
- **Een overtuigende mens zijn**. GPT-4 kan [overtuigen](https://arxiv.org/abs/2405.08007) 54% van de mensen dat het een mens is, maar mensen kunnen dit 67% van de tijd. Met andere woorden, GPT-4 slaagt nog niet consistent voor de Turing-test.
- **Behendige beweging**. Geen enkele robot kan zich bewegen zoals een mens, maar we komen dichterbij. De [Atlas-robot kan lopen, voorwerpen gooien en salto's maken](https://www.youtube.com/watch?v=-e1_QhJ1EhQ). Google's [RT-2](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) kan doelstellingen omzetten in acties in de echte wereld, zoals "verplaats de beker naar de wijnfles". Tesla's Optimus-robot kan [kleren vouwen](https://electrek.co/2024/01/15/tesla-optimus-robot-cant-build-cars-folding-clothes/) en Figure's biped kan [koffie zetten](https://www.youtube.com/watch?v=Q5MKo7Idsok).
- **Zelfreplicatie**. Alle levensvormen op aarde kunnen zichzelf repliceren. AI-modellen kunnen zich van computer naar computer via het internet verspreiden, maar dit vereist een set vaardigheden die AI-modellen nog niet bezitten. Uit een [onderzoek uit 2023](https://arxiv.org/abs/2312.11671) blijkt dat een set van 12 taken nodig is voor zelfreplicatie, waarvan geteste modellen er 4 voltooiden. In december 2024 liet een [onderzoek](https://github.com/WhitzardIndex/self-replication-research/blob/main/AI-self-replication-fudan.pdf) zien dat verschillende open source-modellen zichzelf kunnen repliceren op een machine, mits enige tooling. Een AI die zichzelf succesvol repliceert, kan leiden tot [een AI-overname](/ai-takeover).
- **Continue leren**. Huidige SOTA LLM's scheiden leren ('training') van doen ('inference'). Hoewel LLM's kunnen leren met behulp van hun _context_, kunnen ze hun gewichten niet bijwerken terwijl ze worden gebruikt. Mensen leren en doen tegelijkertijd. Er zijn echter meerdere [mogelijke benaderingen voor dit probleem](https://arxiv.org/abs/2302.00487). Uit een [onderzoek uit 2024](https://arxiv.org/html/2402.01364v2) blijkt dat enkele recente benaderingen voor continue leren in LLM's veelbelovend zijn.
- **Doelen bereiken** waarvoor ze niet zijn getraind en die niet over het uitvoeren van tekst, afbeeldingen of audio gaan. Als je een LLM met controle over een computer of een robot vraagt om niet-super-eenvoudige acties uit te voeren of doelen te bereiken in virtuele of echte omgevingen ver van zijn trainingsverdeling, zal het waarschijnlijk falen.
- **Planning**. LLM's zijn [nog niet erg goed in planning (bijv. redeneren over hoe blokken op een tafel te stapelen)](https://openreview.net/pdf?id=YXogl4uQUO). Grotere modellen presteren echter beter dan kleinere.

## Het eindpunt {#the-endpoint}

Naarmate de tijd vordert en de capaciteiten verbeteren, verplaatsen we items van lagere secties naar de bovenste sectie.
Wanneer sommige specifieke [gevaarlijke capaciteiten](/dangerous-capabilities) worden bereikt, zal AI nieuwe risico's met zich meebrengen.
Op een gegeven moment zal AI elke mens overtreffen in elke denkbare maatstaf.
Wanneer we deze superintelligentie hebben gebouwd, [zullen we waarschijnlijk snel dood zijn](/ai-takeover).
Laten we [een pauze implementeren](/proposal) om ervoor te zorgen dat we daar niet komen.
