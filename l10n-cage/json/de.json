{
	"$schema": "https://inlang.com/schema/inlang-message-format",
	"header__instructions": "Alle Übersetzungen, die mit 'header_' beginnen, sollten so kurz wie möglich sein, um in das Layout zu passen. Versuchen Sie, sie auf ein Wort zu beschränken, während sie immer noch als Links zu den Seiten nützlich sind.",
	"header_action__instructions": "Deutsch: Handeln",
	"header_action": "Handeln",
	"header_donate": "Spenden",
	"header_events__instructions": "In einigen Sprachen könnten 'Kalender' oder 'Termine' bessere Formulierungen sein, um das Ziel einer kurzen Übersetzung zu erreichen. (Deutsch: Termine)",
	"header_events": "Termine",
	"header_faq": "FAQ",
	"header_join__instructions": "In einigen Sprachen könnte 'mitmachen' eine bessere Übersetzung sein, wenn die Übersetzung nicht aus zwei Wörtern besteht.",
	"header_join": "Mitmachen",
	"header_learn": "Lernen",
	"header_proposal": "Vorschlag",
	"home_action_c2a": "Handeln Sie jetzt",
	"home_action_content": "Zu wenige Menschen sind sich der potenziellen Risiken von KI bewusst. Informieren Sie andere und helfen Sie, dieses Rennen zum Untergang zu stoppen.",
	"home_action_title": "<u>SIE</u> KÖNNEN HELFEN",
	"home_hero__instructions": "Dies ist an den Leser gerichtet, übersetzen Sie es informell.",
	"home_hero": "LASSEN SIE NICHT ZU, DASS KI-UNTERNEHMEN UNSERE ZUKUNFT SPIELEN",
	"home_proposal_c2a": "Lesen Sie den Vorschlag",
	"home_proposal_content__instructions": "'Stoppen' ist nicht an den Leser gerichtet.",
	"home_proposal_content": "Die Entwicklung der leistungsfähigsten allgemeinen KI-Systeme sollte gestoppt werden, bis wir wissen, wie wir sie sicher machen können. Dies muss auf internationaler Ebene geschehen, und es muss bald geschehen.",
	"home_proposal_title": "Wir brauchen eine <u>Pause</u>",
	"home_quotes_all": "Alle Zitate anzeigen",
	"home_quotes_bengio_text": "KI-Schurken könnten für die gesamte Menschheit gefährlich sein. Ein Verbot leistungsfähiger KI-Systeme, die Autonomie und Handlungsfähigkeit erhalten, wäre ein guter Anfang.",
	"home_quotes_bengio_title": "KI-Turing-Preisträger",
	"home_quotes_cais_text": "Die Minderung des Risikos des Aussterbens durch KI sollte eine globale Priorität neben anderen gesellschaftlichen Risiken wie Pandemien und Atomkrieg sein.",
	"home_quotes_cais_author": "Erklärung zum KI-Risiko",
	"home_quotes_cais_title": "Unterzeichnet von Hunderten von Experten, einschließlich der Top-KI-Labors und Wissenschaftler",
	"home_quotes_hawking_text": "Die Entwicklung einer vollständigen künstlichen Intelligenz könnte das Ende der menschlichen Rasse bedeuten.",
	"home_quotes_hawking_title": "Theoretischer Physiker und Kosmologe",
	"home_quotes_hinton_text": "Wenn Sie das existenzielle Risiko ernst nehmen, wie ich es jetzt tue, könnte es durchaus sinnvoll sein, die Entwicklung dieser Dinge einfach zu stoppen.",
	"home_quotes_hinton_title": "Nobelpreisträger und 'Gottvater der KI'",
	"home_quotes_russell_text": "Wenn wir unseren aktuellen Ansatz verfolgen, werden wir schließlich die Kontrolle über die Maschinen verlieren",
	"home_quotes_russell_title": "Autor des KI-Lehrbuchs",
	"home_quotes_turing_text": "... wir sollten damit rechnen, dass die Maschinen die Kontrolle übernehmen.",
	"home_quotes_turing_title": "Erfinder des modernen Computers",
	"home_risks_c2a": "Lesen Sie über die Risiken",
	"home_risks_content": "KI kann erstaunliche Vorteile haben, aber sie könnte auch unsere Demokratie untergraben, unsere Wirtschaft destabilisieren und könnte zur Schaffung leistungsfähiger Cyberwaffen verwendet werden.",
	"home_risks_title": "Wir riskieren, <u>die Kontrolle zu verlieren</u>",
	"home_stats_2025": "Chance, dass wir 2025 AGI erreichen",
	"home_stats_alignment": "von KI-Wissenschaftlern glauben, dass das Alignment-Problem real und wichtig ist",
	"home_stats_citizens": "von Bürgern wollen, dass KI von unseren Regierungen verlangsamt wird",
	"home_urgency_c2a": "Wie viel Zeit haben wir noch?",
	"home_urgency_content": "Im Jahr 2020 dachten Experten, wir hätten mehr als 35 Jahre Zeit, bis AGI. Jüngste Durchbrüche zeigen, dass wir fast da sind. Superintelligenz könnte nur eine Innovation entfernt sein, also sollten wir vorsichtig sein.",
	"home_urgency_title": "WIR MÜSSEN <u>JETZT</u> HANDELN",
	"home_xrisk_c2a": "Wie und warum KI uns töten könnte",
	"home_xrisk_content": "Viele KI-Labors und Experten stimmen überein: KI könnte die Menschheit auslöschen.",
	"home_xrisk_title": "Wir riskieren <u>das Aussterben der Menschheit</u>",
	"simpletoc_heading": "Inhaltsverzeichnis",
	"footer_join": "PauseAI beitreten >",
	"footer_info": "Info",
	"footer_info_faq": "FAQ",
	"footer_info_proposal": "Vorschlag",
	"footer_info_learn": "Lernen",
	"footer_info_press": "Presse / Medien",
	"footer_info_people": "Menschen",
	"footer_info_teams": "Teams",
	"footer_info_partnerships": "Partnerschaften",
	"footer_info_privacy": "Datenschutzbestimmungen",
	"footer_info_legal": "Rechtliche Informationen",
	"footer_info_legal_foundation": "Stichting PauseAI",
	"footer_info_legal_kvk": "(kvk 92951031)",
	"footer_risks": "Risiken",
	"footer_risks_overview": "Risiken-Übersicht",
	"footer_risks_outcomes": "KI-Ergebnisse",
	"footer_risks_xrisk": "Existenzielles Risiko",
	"footer_risks_psychology": "Psychologie des existenziellen Risikos",
	"footer_risks_takeover": "KI-Übernahme",
	"footer_risks_cybersecurity": "Cybersicherheit",
	"footer_risks_capabilities": "Gefährliche Fähigkeiten",
	"footer_risks_sota": "Stand der Technik",
	"footer_risks_urgency": "Dringlichkeit",
	"footer_action": "Handeln",
	"footer_action_join": "PauseAI beitreten",
	"footer_action_help": "Wie Sie helfen können",
	"footer_action_communities": "Lokale Gemeinschaften",
	"footer_action_donate": "Spenden",
	"footer_action_merchandise": "Merchandise",
	"footer_action_events": "Veranstaltungen",
	"footer_action_vacancies": "Stellenangebote",
	"footer_action_email": "E-Mail-Builder",
	"footer_action_lobby": "Lobby-Tipps",
	"footer_other": "Sonstiges",
	"footer_other_pages": "Alle Seiten",
	"footer_other_rss": "RSS",
	"footer_other_license": "Lizenz: CC-BY 4.0",
	"footer_other_feedback": "Feedback einreichen",
	"footer_other_edit": "Original-Englisch-Inhalt bearbeiten",
	"footer_other_l10n": "Übersetzungsverbesserung vorschlagen",
	"newsletter_heading": "Abonnieren Sie unseren Newsletter",
	"newsletter_description": "Bleiben Sie auf dem Laufenden über unsere Bemühungen, KI-Sicherheit zu fördern.",
	"newsletter_disclaimer": "Unser Newsletter ist völlig kostenlos. Kein bezahltes Abonnement erforderlich. Sie können Substack nach der Anmeldung schließen.",
	"newsletter_email_placeholder": "Ihre E-Mail",
	"newsletter_button": "Abonnieren",
	"newsletter_success": "Vielen Dank für Ihre Anmeldung!",
	"newsletter_error_default": "Anmeldung fehlgeschlagen. Bitte versuchen Sie es erneut.",
	"newsletter_error_network": "Netzwerkfehler. Bitte versuchen Sie es später erneut.",
	"newsletter_loading": "Laden..."
}
